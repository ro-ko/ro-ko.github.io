---
title: "Natural Language Processing Tasks"
permalink: /nlp/
date: 2020-10-25T00:00-00:00
excerpt: An one-page overview of standard tasks in NLP
classes: wide
---

An one-page overview of 134 standard tasks in NLP.



[**Acoustic Classification**](#acoustic-classification) (1)|[**Adversarial**](#adversarial) (1)|[**Automatic Image Captioning**](#automatic-image-captioning) (6)|[**Biased Text Neutralization**](#biased-text-neutralization) (1)|[**Clarification Question Generation**](#clarification-question-generation) (1)|[**Classification**](#classification) (33)|
[**Clone Detection**](#clone-detection) (2)|[**Cloze-Test**](#cloze-test) (2)|[**Clustering**](#clustering) (7)|[**Code Line Completion**](#code-line-completion) (1)|[**Code Refinement**](#code-refinement) (1)|[**Code Search**](#code-search) (2)|
[**Code Token Completion**](#code-token-completion) (1)|[**Code Translation**](#code-translation) (1)|[**Commonsense**](#commonsense) (18)|[**Commonsense Inference**](#commonsense-inference) (1)|[**Commonsense Reasoning**](#commonsense-reasoning) (4)|[**Compositional Learning**](#compositional-learning) (1)|
[**Constituency**](#constituency) (1)|[**Coreference Resolution**](#coreference-resolution) (5)|[**Credibility**](#credibility) (1)|[**Cross-Lingual Summarization**](#cross-lingual-summarization) (1)|[**Data-to-Text**](#data-to-text) (3)|[**Defect Detection**](#defect-detection) (1)|
[**Definition Extraction**](#definition-extraction) (1)|[**Dialogue**](#dialogue) (53)|[**Dialogue Act Classification**](#dialogue-act-classification) (1)|[**Dialogue State Tracking**](#dialogue-state-tracking) (1)|[**Discriminating between similar languages**](#discriminating-between-similar-languages) (1)|[**Document Classification**](#document-classification) (1)|
[**Document Layout Analysis**](#document-layout-analysis) (1)|[**Document Ranking**](#document-ranking) (1)|[**Embeddings**](#embeddings) (2)|[**Emotion Classification**](#emotion-classification) (7)|[**Emotion Recognition**](#emotion-recognition) (2)|[**Entailment**](#entailment) (6)|
[**Entity Extraction**](#entity-extraction) (2)|[**Entity Linking**](#entity-linking) (1)|[**Entity Ranking**](#entity-ranking) (1)|[**Entity Retrieval**](#entity-retrieval) (1)|[**Event Extraction**](#event-extraction) (6)|[**Events**](#events) (5)|
[**Explainability**](#explainability) (1)|[**Gender Identification**](#gender-identification) (1)|[**Grammatical Acceptability**](#grammatical-acceptability) (1)|[**Graph Analysis**](#graph-analysis) (3)|[**Grounded Language Learning**](#grounded-language-learning) (2)|[**Hate Speech Detection**](#hate-speech-detection) (2)|
[**Headline Generation**](#headline-generation) (1)|[**Idiomatic Expressions**](#idiomatic-expressions) (1)|[**Image Description Generation**](#image-description-generation) (1)|[**Information Extraction**](#information-extraction) (20)|[**Information Retrieval**](#information-retrieval) (5)|[**Intent Detection**](#intent-detection) (2)|
[**Keyphrase Extraction**](#keyphrase-extraction) (1)|[**Knowledge Base**](#knowledge-base) (21)|[**Knowledge Graph**](#knowledge-graph) (8)|[**Language Detection**](#language-detection) (2)|[**Language Model Evaluation**](#language-model-evaluation) (1)|[**Language Modeling**](#language-modeling) (6)|
[**Lexical Inference/Entailment**](#lexical-inferenceentailment) (1)|[**Link Prediction**](#link-prediction) (1)|[**Machine Translation**](#machine-translation) (41)|[**Mathematical Reasoning**](#mathematical-reasoning) (1)|[**Missing Elements**](#missing-elements) (1)|[**Multi-Modal**](#multi-modal) (2)|
[**Multi-Modal Hate Speech Detection**](#multi-modal-hate-speech-detection) (1)|[**Multi-Modal Learning**](#multi-modal-learning) (13)|[**NLU**](#nlu) (1)|[**Named Entity Recognition**](#named-entity-recognition) (1)|[**Named Entity Recognition (NER)**](#named-entity-recognition-ner) (21)|[**Natural Language Inference (NLI)**](#natural-language-inference-nli) (13)|
[**Natural Language Understanding**](#natural-language-understanding) (1)|[**Natural Question Understanding (NQU)**](#natural-question-understanding-nqu) (1)|[**Node Classification**](#node-classification) (1)|[**Numeric Fused-Head**](#numeric-fused-head) (1)|[**Open Link Prediction**](#open-link-prediction) (1)|[**PCA**](#pca) (1)|
[**Paraphrase Generation**](#paraphrase-generation) (2)|[**Paraphrase Identification**](#paraphrase-identification) (1)|[**Paraphrasing Identification**](#paraphrasing-identification) (4)|[**Part of Speech (POS)**](#part-of-speech-pos) (4)|[**Phonetic Typology**](#phonetic-typology) (1)|[**Post-Modifier Generation**](#post-modifier-generation) (1)|
[**Question Answering**](#question-answering) (113)|[**Question Clarification**](#question-clarification) (1)|[**Question Generation**](#question-generation) (1)|[**Reading Comprehension**](#reading-comprehension) (79)|[**Regression**](#regression) (1)|[**Relation**](#relation) (1)|
[**Relation Extraction**](#relation-extraction) (14)|[**Relation Link Prediction**](#relation-link-prediction) (1)|[**Relation Prediction**](#relation-prediction) (2)|[**SQL-to-Text**](#sql-to-text) (3)|[**Sarcasm Detection**](#sarcasm-detection) (1)|[**Scene Text Detection**](#scene-text-detection) (1)|
[**Scene Text Recognition**](#scene-text-recognition) (1)|[**Scoring Classification**](#scoring-classification) (2)|[**Semantic Parse Correction**](#semantic-parse-correction) (1)|[**Semantic Parsing**](#semantic-parsing) (14)|[**Semantic Role Labeling**](#semantic-role-labeling) (3)|[**Semantic Textual Similarity**](#semantic-textual-similarity) (9)|
[**Sentence Fusion**](#sentence-fusion) (1)|[**Sentence Level Cloze Completion**](#sentence-level-cloze-completion) (1)|[**Sentence Simplification**](#sentence-simplification) (2)|[**Sentiment Analysis**](#sentiment-analysis) (10)|[**Speech Corpora**](#speech-corpora) (5)|[**Speech Question Answering**](#speech-question-answering) (1)|
[**Speech Recognition**](#speech-recognition) (12)|[**Speech Seperation**](#speech-seperation) (2)|[**Speech Translation**](#speech-translation) (4)|[**Speech-To-Text**](#speech-to-text) (2)|[**Stance Detection**](#stance-detection) (2)|[**Suggestion Mining**](#suggestion-mining) (2)|
[**Summarization**](#summarization) (25)|[**Syntactic Parsing**](#syntactic-parsing) (1)|[**Table Segmentation**](#table-segmentation) (1)|[**Table Type Classification**](#table-type-classification) (1)|[**Table-to-Text**](#table-to-text) (1)|[**Text Classification**](#text-classification) (9)|
[**Text Corpora**](#text-corpora) (74)|[**Text Generation**](#text-generation) (5)|[**Text-to-Code Generation**](#text-to-code-generation) (1)|[**Text-to-Image**](#text-to-image) (1)|[**Text-to-SQL**](#text-to-sql) (7)|[**Text-to-Speech**](#text-to-speech) (3)|
[**Topic Extraction**](#topic-extraction) (1)|[**Translation**](#translation) (1)|[**Triple Classification**](#triple-classification) (1)|[**Video Question Answering**](#video-question-answering) (4)|[**Visual**](#visual) (19)|[**Visual Question Answering**](#visual-question-answering) (4)|
[**Visualization**](#visualization) (1)|[**Word Sense Disambiguation**](#word-sense-disambiguation) (5)|

## Acoustic Classification

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[UrbanSound & UrbanSound8K](https://urbansounddataset.weebly.com/ "UrbanSound: Dataset contains 1,302 labeled sound recordings. Each recording is labeled with the start and end times of sound events from 10 classes: air_conditioner, car_horn, children_playing, dog_bark, drilling, enginge_idling, gun_shot, jackhammer, siren, and street_music. UrbanSound8K: Dataset contains 8,732 labeled sound excerpts (<=4s) of urban sounds from 10 classes: air_conditioner, car_horn,Â children_playing, dog_bark, drilling, enginge_idling, gun_shot, jackhammer, siren, and street_music.")|10,034|Wav, JSON, CSV|[2014](http://www.justinsalamon.com/uploads/4/3/9/4/4394963/salamon_urbansound_acmmm14.pdf)|-||

## Adversarial

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[DailyDialog++](https://github.com/iitmnlp/Dialogue-Evaluation-with-BERT "DailyDialog++ is an open-domain dialogue evaluation dataset consisting of 19k contexts with five relevant responses for each context. Additionally for 11k contexts, it includes five adversarial irrelevant responses which are specifically crafted to have lexical or semantic overlap with the context but are still unacceptable as valid responses.")|19k|JSON|[2020](https://arxiv.org/abs/2009.11321)|English|<a target="_blank" href="https://paperswithcode.com/paper/improving-dialog-evaluation-with-a-multi" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Automatic Image Captioning

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Common Objects in Context (COCO)](http://cocodataset.org/ "COCO is a large-scale object detection, segmentation, and captioning dataset. Dataset contains 330K images (>200K labeled) 1.5 million object instances, 80 object categories, 91 stuff categories, 5 captions per image.")|330k|JSON, JPG|[2014](https://arxiv.org/abs/1405.0312)|English|<a target="_blank" href="https://paperswithcode.com/paper/microsoft-coco-common-objects-in-context" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Flickr30K Entities](https://github.com/BryanPlummer/flickr30k_entities "Dataset contains 244k coreference chains and 276k manually annotated bounding boxes for each of the 31,783 images and 158,915 English captions (five per image) in the original dataset.")|31,783|Text, XML|[2017](https://arxiv.org/abs/1505.04870)|English|<a target="_blank" href="https://paperswithcode.com/paper/flickr30k-entities-collecting-region-to" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Open Images V6](https://storage.googleapis.com/openimages/web/download.html "Dataset containing millions of images that have been annotated with image-level labels and object bounding boxes.")|9,178,275|TSV, CSV|[2018](https://arxiv.org/abs/1811.00982)|English|<a target="_blank" href="https://paperswithcode.com/paper/the-open-images-dataset-v4-unified-image" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Conceptual Captions](https://ai.google.com/research/ConceptualCaptions/download "Dataset contains ~3.3M images annotated with captions to be used for the task of automatically producing a natural-language description for an image.")|3,318,333|TSV|[2018](https://www.aclweb.org/anthology/P18-1238.pdf)|English||
|[Vietnamese Image Captioning Dataset (UIT-ViIC)](https://sites.google.com/uit.edu.vn/uit-nlp/datasets-projects#h.p_Uj6Wqs5dCpc4 "Dataset consists of 19,250 captions for 3,850 images on sport-ball. [requires contacting author for corpus]")|3,850|-|[2020](https://arxiv.org/abs/2002.00175)|Vietnamese|<a target="_blank" href="https://paperswithcode.com/paper/uit-viic-a-dataset-for-the-first-evaluation" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Textual Visual Semantic Dataset](https://github.com/ahmedssabir/dataset "A dataset consisting of detecting and recognizing text appearing in images (e.g. signboards, traffic signals or brands in clothing or objects). Around 82,000 images.")|82k|JPG, CSV|[2020](https://arxiv.org/abs/2004.10349)|English|<a target="_blank" href="https://paperswithcode.com/paper/textual-visual-semantic-dataset-for-text" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Biased Text Neutralization

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Neutralizing Biased Text](https://github.com/rpryzant/neutralizing-bias "A parallel corpus of 180,000+ sentence pairs where one sentence is biased and the other is neutralized. The data were obtained from debiasing wikipedia edits.")|180k|-|[2019](https://arxiv.org/abs/1911.09709)|English|<a target="_blank" href="https://paperswithcode.com/paper/automatically-neutralizing-subjective-bias-in" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Clarification Question Generation

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[ClarQ](https://github.com/vaibhav4595/ClarQ "Dataset consists of â¼2M question/post tuples distributed across 173 domains of stackexchange.")|~2M|JSON|[2020]()|English||

## Classification

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Reuters-21578 Benchmark Corpus](https://www.kaggle.com/nltkdata/reuters "Dataset is a collection of 10,788 documents from the Reuters financial newswire service, partitioned into a training set with 7769 documents and a test set with 3019 documents.")|10,788|TSV|[1997]()|English|<a href="https://huggingface.co/nlp/viewer/?dataset=reuters21578" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Ohsumed Dataset](http://davis.wpi.edu/xmdv/datasets/ohsumed.html "Dataset containing references from MEDLINE, the on-line medical information database, consisting of titles and/or abstracts from 270 medical journals over a five-year period (1987-1991).")|-|OKC|[1997](http://www.cs.cornell.edu/people/tj/publications/joachims_97b.pdf)|English||
|[Car Evaluation Dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/car/ "Car properties and their overall acceptability.")|1,728|Text|[1997](https://pdfs.semanticscholar.org/df46/10614ccb66a8cd8914d0ea6d191e100e1bd2.pdf?_ga=2.50792299.354477249.1582324561-958501894.1582324561)|English||
|[Spambase Dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/ "Dataset contains spam emails.")|4,601|Text|[1999]()|English||
|[Ling-Spam Dataset](https://aclweb.org/aclwiki/Spam_filtering_datasets "Corpus contains both legitimate andÂ spamÂ emails.")|-|Text|[2000](http://www2.aueb.gr/users/ion/docs/ir_memory_based_antispam_filtering.pdf)|English||
|[DEXTER Dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/dexter/ "Task given is to determine, from features given, which articles are about corporate acquisitions.")|2,600|Text|[2008](http://clopinet.com/isabelle/Projects/NIPS2003/Slides/NIPS2003-Datasets.pdf)|English||
|[The EUR-Lex Dataset](http://www.ke.tu-darmstadt.de/resources/eurlex "Dataset is a collection of documents about European Union law.â It contains many different types of documents, including treaties, legislation, case-law and legislative proposals, which are indexed with almost 4,000 labels.")|-|HMTL|[2010]()|Multi-Lingual||
|[SMS Spam Collection Dataset](https://www.kaggle.com/uciml/sms-spam-collection-dataset "Dataset contains SMS spam messages.")|5,574|Text|[2011](http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/)|English||
|[YouTube Comedy Slam Preference Dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/00223/ "User vote data for pairs of videos shown on YouTube. Users voted on funnier videos.")|1,138,562|Text|[2012](https://ai.googleblog.com/2012/02/quantifying-comedy-on-youtube-why.html)|English||
|[Legal Case Reports](https://archive.ics.uci.edu/ml/machine-learning-databases/00239/ "Federal Court of AustraliaÂ cases from 2006 to 2009.")|4k|Text|[2012](https://www.aclweb.org/anthology/W12-0515.pdf)|English||
|[ClueWeb Corpora](http://lemurproject.org/clueweb09/FACC1/ "Annotated web pages from the ClueWeb09Â andÂ ClueWeb12Â corpora.")|340,451,982|Text|[2013](http://lemurproject.org/clueweb09/)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=clue" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Buzz in Social Media Dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/00248/ "Data from Twitter and Tom's Hardware. This dataset focuses on specific buzz topics being discussed on those sites.")|140k|Text|[2013](https://hal.archives-ouvertes.fr/hal-00881395/document)|English||
|[Corporate Messaging Corpus](https://data.world/crowdflower/corporate-messaging "Dataset contains classifed statements as information, dialog (replies to users, etc.), or action (messages that ask for votes or ask users to click on links, etc.")|3,118|CSV|[2015]()|English||
|[Home Depot Product Search Relevance](https://www.kaggle.com/c/home-depot-product-search-relevance/data "Dataset containsÂ a number of products and real customer search terms from Home Depot's website.")|-|CSV|[2015]()|English||
|[AG News](http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html "Dataset contains more than 1 million news articles for topic classification. The 4 classes are: World, Sports, Business, and Sci/Tech.")|1M+|CSV|[2015](http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=ag_news" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Paraphrase and Semantic Similarity in Twitter (PIT)](https://github.com/cocoxu/SemEval-PIT2015 "Dataset focuses on whether tweets have (almost) same meaning/information or not.")|18,762|Text|[2015](https://www.aclweb.org/anthology/S15-2001.pdf)|English||
|[Arabic Violence Twitter Corpus](https://github.com/Alhelbawy/Arabic-Violence-Twitter "Annotated Arabic tweets which mention a violent act. Tweets were classifed into 8 classes: Crime, Accident, Crisis, Conflict, Human Rights Abuse, Violence, Opinion, or other. Requires using Twitter API to match IDs with tweets for retrieval.")|20k|Text|[2016](https://www.aclweb.org/anthology/L16-1257.pdf)|Arabic||
|[Hate Speech Identification Dataset](https://github.com/t-davidson/hate-speech-and-offensive-language "Dataset contains lexicons, notebooks containing content that is racist, sexist, homophobic, and offensive in general.")|-|CSV|[2017](https://arxiv.org/abs/1703.04009)|English|<a target="_blank" href="https://paperswithcode.com/paper/automated-hate-speech-detection-and-the" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Web of Science Dataset](https://data.mendeley.com/datasets/9rw3vkcfy4/6 "Hierarchical Datasets for Text Classification.")|46,985|Text|[2017](https://arxiv.org/abs/1709.08267)|English|<a target="_blank" href="https://paperswithcode.com/paper/hdltex-hierarchical-deep-learning-for-text" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=web_of_science" title="Open in Huggingface" target="_blank">ð¤</a>|
|[PubMed 200k RCT Dataset](https://github.com/Franck-Dernoncourt/pubmed-rct "Dataset is based on PubMed for sequential sentence classification. The dataset consists of approximately 200,000 abstracts of randomized controlled trials, totaling 2.3 million sentences.")|200k|Text|[2017](https://arxiv.org/abs/1710.06071)|English|<a target="_blank" href="https://paperswithcode.com/paper/pubmed-200k-rct-a-dataset-for-sequential" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[News Category Dataset](https://www.kaggle.com/rmisra/news-category-dataset "Dataset contains around 200k news headlines from the year 2012 to 2018 obtained fromÂ HuffPost.")|~200,000|JSON|[2018]()|English||
|[Dengue Dataset](https://github.com/jcblaisecruz02/Filipino-Text-Benchmarks "Dataset for multi-class (5) classification on tweets: 5 classes: absent, dengue, health, mosquito & sick.")|5,015|CSV|[2018]()|Filipino||
|[Social Media Mining for Health (SMM4H)](https://data.mendeley.com/datasets/rxwfb3tysd/2 "Dataset contains medication-related text classification and concept normalization from Twitter")|25,678|Text|[2018](https://www.aclweb.org/anthology/W18-5904.pdf)|English||
|[BARD Bangla Article Classifier](https://github.com/tanvirfahim15/BARD-Bangla-Article-Classifier "A large corpus of Bangla documents classified into 5 classes: sports, state, economy, entertainment, and international.")|376,226|Text|[2018](https://www.researchgate.net/publication/328214545_BARD_Bangla_Article_Classification_Using_a_New_Comprehensive_Dataset)|Bengali||
|[Civil Comments](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/data "Dataset contains the archive of the Civil Comments platform. Dataset was annotated for toxicity.")|-|CSV|[2019]()|English|<a href="https://huggingface.co/nlp/viewer/?dataset=civil_comments" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Cyberbullying Detection (CBD)](https://klejbenchmark.com/tasks/ "Dataset contains annotated tweets that identify harmful or non-harmful content.")|-|TSV|[2019]()|Polish||
|[Hate Speech Dataset](https://github.com/jcblaisecruz02/Filipino-Text-Benchmarks "Dataset contains tweets that are labeled as hate speech or non-hate speech. Collected during the 2016 Philippine Presidential Elections.")|18,464|CSV|[2019]()|Filipino||
|[SemEval-2019 Task 6Â ](https://github.com/ZeyadZanaty/offenseval "Dataset containing tweets as either offensive or not offensive (Sub-task A) and further classifies offensive tweets into categories (Sub-tasks B â C).")|14,100|TSV|[2019](https://arxiv.org/abs/1903.08983)|English|<a target="_blank" href="https://paperswithcode.com/paper/semeval-2019-task-6-identifying-and-1" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[SciCite](https://github.com/allenai/scicite "Dataset used for classifying citation intents in academic papers. The main citation intent label for each JSON object is specified with the label key while the citation context is specified in with a context key.")|11,020|JSON|[2019](https://arxiv.org/abs/1904.01608)|English|<a target="_blank" href="https://paperswithcode.com/paper/structural-scaffolds-for-citation-intent" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=scicite" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Humicroedit](https://www.cs.rochester.edu/u/nhossain/humicroedit.html "Dataset contains 15,095 edited news headlines and their numerically assessed humor.")|15,095|CSV|[2019](https://arxiv.org/abs/1906.00274)|English|<a target="_blank" href="https://paperswithcode.com/paper/190600274" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Korean Hate Speech Dataset](https://github.com/kocohub/korean-hate-speech "Dataset contains ~9,4K manually labeled entertainment news comments for identifying Korean toxic speech.")|9,381|Text|[2020](https://arxiv.org/abs/2005.12503)|Korean|<a target="_blank" href="https://paperswithcode.com/paper/beep-korean-corpus-of-online-news-comments" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Polusa](https://zenodo.org/record/3813664#.XvDMbWhKiUk "Dataset contains 0.9M articles covering policy topics published between Jan. 2017 and Aug. 2019 by 18 news outlets representing the political spectrum.")|0.9M|-|[2020](https://arxiv.org/ftp/arxiv/papers/2005/2005.14024.pdf)|English||
|[LEDGAR](https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A "LEDGAR is a multilabel corpus of legal provisions in contracts suited for text classification in the legal domain (legaltech). It features over 1.8M+ provisions and a set of 180K+ labels. A smaller, cleaned version of the corpus is also available.")|1.8M|JSON|[2020](https://www.aclweb.org/anthology/2020.lrec-1.155.pdf)|English||

## Clone Detection

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[CodeXGLUE: BigCloneBench Dataset](https://github.com/microsoft/CodeXGLUE/tree/main/Code-Code/Clone-detection-BigCloneBench "Given two codes as the input, the task is to do binary classification (0/1), where 1 stands for semantic equivalence and 0 for others.Â Models are evaluated by F1 score.")|1,731,860|JSON, Text|[2014](https://www.cs.usask.ca/faculty/croy/papers/2014/SvajlenkoICSME2014BigERA.pdf)|Coding Lang: Java||
|[CodeXGLUE: POJ-104](https://github.com/microsoft/CodeXGLUE/tree/main/Code-Code/Clone-detection-POJ-104 "Given a code and a collection of candidates as the input, the task is to return Top K codes with the same semantic. Models are evaluated by MAP score.")|52k|JSON|[2016](https://arxiv.org/abs/1409.5718)|Coding Lang: C/C++|<a target="_blank" href="https://paperswithcode.com/paper/convolutional-neural-networks-over-tree" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Cloze-Test

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[CodeXGLUE: CT-All](https://github.com/microsoft/CodeXGLUE/tree/main/Code-Code/ClozeTesting-all "The task is aimed to predict the answers for the blank with the context of the blank, which can be formulated as a multi-choice classification problem. Each instance in the dataset contains a masked code function, its docstring and the target word.")|176,115|JSON|[2019]()|Coding Lang: Python, Java, PHP, Javascript, Ruby, Go||
|[CodeXGLUE: CT-Max/Min](https://github.com/microsoft/CodeXGLUE/tree/main/Code-Code/ClozeTesting-maxmin "The difference between this dataset and CT-All is that this dataset only contains two words. The task is aimed to predict the answers for the blank with the context of the blank, which can be formulated as a multi-choice classification problem. Each instance in the dataset contains a masked code function, its docstring and the target word. ")|2,615|JSON|[2019]()|Coding Lang: Python, Java, PHP, Javascript, Ruby, Go||

## Clustering

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Yahoo! Music User Ratings of Musical Artists](https://webscope.sandbox.yahoo.com/catalog.php?datatype=r "Over 10M ratings of artists by Yahoo users. May be used to validate recommender systems or collaborative filtering algorithms.")|~10M|Text|[2004](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/ILAT5B)|English||
|[ASU Twitter Dataset](http://socialcomputing.asu.edu/datasets/Twitter "Twitter network data, not actual tweets. Shows connections between a large number of users.")|11,316,811 users, 85,331,846 connections|CSV|[2009]()|English||
|[SNAP Social Circles: Twitter Database](https://snap.stanford.edu/data/egonets-Twitter.html "Large Twitter network data.")|Nodes: 81,306, Edges:1,768,149|Text|[2012](http://i.stanford.edu/~julian/pdfs/nips2012.pdf)|English||
|[ExaminerÂ Pseudo-News Corpus](https://www.kaggle.com/therohk/examine-the-examiner "Clickbait, spam, crowd-sourced headlines from 2010 to 2015.")|3,089,781|CSV|[2017]()|English||
|[Worldwide News - Aggregate of 20KÂ Feeds](https://www.kaggle.com/therohk/global-news-week "One week snapshot of all online headlines in 20+ languages.")|1,398,431|CSV|[2017](https://pdfs.semanticscholar.org/48cd/042d645e60b125fd5b90f734900dae4211d8.pdf)|Multi-Lingual||
|[The Irish Times IRS](https://www.kaggle.com/therohk/ireland-historical-news "Dataset contains 23 years of events from Ireland.")|1,425,460|CSV|[2018]()|English||
|[News Headlines Dataset for Sarcasm Detection](https://www.kaggle.com/rmisra/news-headlines-dataset-for-sarcasm-detection "High quality dataset with Sarcastic and Non-sarcastic news headlines.")|26,709|JSON|[2018](https://arxiv.org/abs/1908.07414)|English|<a target="_blank" href="https://paperswithcode.com/paper/sarcasm-detection-using-hybrid-neural-network" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Code Line Completion

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[CodeXGLUE: PY 150/Java Corpus line](https://github.com/microsoft/CodeXGLUE/tree/main/Code-Code/CodeCompletion-line "Datasets used for code completion on the line level for Python and Java.")|13k|JSON|[2016](https://files.sri.inf.ethz.ch/website/papers/oopsla16-dt.pdf)|Coding Lang: Python, Java||

## Code Refinement

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[CodeXGLUE: Bugs2Fix](https://github.com/microsoft/CodeXGLUE/tree/main/Code-Code/code-refinement "Given a piece of Java code with bugs, the task is to remove the bugs to output the refined code. Models are evaluated by BLEU scores, accuracy (exactly match) and CodeBLEU.")|123,804|JSON|[2019](https://arxiv.org/abs/1812.08693)|Coding Lang: Java||

## Code Search

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[CodeXGLUE: NL Code Search WebQuery](https://github.com/microsoft/CodeXGLUE/tree/main/Text-Code/NL-code-search-WebQuery "Code Search is aimed to find a code snippet which best matches the demand of the query. This task is formulated in text-code classification.")|5,930|JSON|[2018]()|Coding Lang: Python||
|[CodeXGLUE: CodeSearchNet, AdvTest](https://github.com/microsoft/CodeXGLUE/tree/main/Text-Code/NL-code-search-Adv "Given a natural language prompt, the task is to search source code that matches the natural language. To test the generalization ability of a model, function names and variables in test sets are replaced by special tokens.")|280,634|JSON|[2019](https://arxiv.org/abs/1909.09436)|Coding Lang: Python|<a target="_blank" href="https://paperswithcode.com/paper/codesearchnet-challenge-evaluating-the-state" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Code Token Completion

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[CodeXGLUE: PY 150/Java Corpus token](https://github.com/microsoft/CodeXGLUE/tree/main/Code-Code/CodeCompletion-token "Datasets used for code completion on the token level for Python and Java.")|155k|JSON|[2016](https://files.sri.inf.ethz.ch/website/papers/oopsla16-dt.pdf)|Coding Lang: Python, Java||

## Code Translation

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[CodeXGLUE: CodeTrans](https://github.com/microsoft/CodeXGLUE/tree/main/Code-Code/code-to-code-trans "Given a piece of Java (C#) code, the task is to translate the code into C# (Java) version. Models are evaluated by BLEU scores, accuracy (exactly match), and CodeBLEU scores.")|11,800|Text|[2020]()|Coding Lang: Java, C#||

## Commonsense

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[ConceptNet](https://github.com/commonsense/conceptnet5 "A knowledge graph that connects words and phrases of natural language (terms) with labeled, weighted edges (assertions).")|21M+ edges and 8M+ nodes|JSON|[2017](https://arxiv.org/abs/1612.03975)|Multi-Lingual|<a target="_blank" href="https://paperswithcode.com/paper/conceptnet-55-an-open-multilingual-graph-of" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[DVQA](https://github.com/kushalkafle/DVQA_dataset "Dataset containing data visualizations and natural language questions.")|3,487,194|JSON, PNG|[2018](https://arxiv.org/abs/1801.08163)|English|<a target="_blank" href="https://paperswithcode.com/paper/dvqa-understanding-data-visualizations-via" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[CommonsenseQA](https://www.tau-nlp.org/commonsenseqa "Dataset contains multiple-choice question answering dataset that requires different types of commonsense knowledge to predict the correct answers . It contains 12,102 questions with one correct answer and four distractor answers.")|12,012|JSON|[2018](https://arxiv.org/abs/1811.00937)|English|<a target="_blank" href="https://paperswithcode.com/paper/commonsenseqa-a-question-answering-challenge" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=commonsense_qa" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Video Commonsense Reasoning (VCR)](https://visualcommonsense.com/download/ "Dataset contains 290K multiple-choice questions on 110K images.")|290k|JSON, JPG|[2018](https://arxiv.org/abs/1811.10830)|English|<a target="_blank" href="https://paperswithcode.com/paper/from-recognition-to-cognition-visual" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Atlas of Machine Commonsense (ATOMIC)](https://homes.cs.washington.edu/~msap/atomic/ "Dataset is a knowledge graph of 877K textual description triples of inferential knowledge.")|877k|CSV|[2018](https://homes.cs.washington.edu/~msap/atomic/data/sap2019atomic.pdf)|English||
|[Story Commonsense](https://uwnlp.github.io/storycommonsense/ "Dataset contains a total of 300k low-level annotations for motivation and emotion across15,000 stories (randomly selected from the ROC story training set). It covers over 150,000 character-line pairs, in which 56k character-line pairs have an annotated motivation and 105k have an annotated change in emotion (i.e. a label other than none).")|15k|CSV, JSON|[2018](https://uwnlp.github.io/storycommonsense/data/rashkin2018modeling.pdf)|English||
|[Social-IQ Dataset](https://github.com/A2Zadeh/Social-IQ "Dataset containing videos and natural language questions for visual reasoning.")|7,500|-|[2019](http://openaccess.thecvf.com/content_CVPR_2019/papers/Zadeh_Social-IQ_A_Question_Answering_Benchmark_for_Artificial_Social_Intelligence_CVPR_2019_paper.pdf)|English||
|[GQA](https://cs.stanford.edu/people/dorarad/gqa/download.html "Question answering on imageÂ scene graphs.")|22M|JSON, H5|[2019](https://arxiv.org/abs/1902.09506)|English|<a target="_blank" href="https://paperswithcode.com/paper/gqa-a-new-dataset-for-compositional-question" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[COmmonsense Dataset Adversarially-authored by Humans (CODAH)](https://github.com/Websail-NU/CODAH "Commonsense QA in the sentence completion style of SWAG. As opposed to other automatically generated NLI datasets, CODAH is adversarially constructed by humans who can view feedback from a pre-trained model and use this information to design challenging commonsense questions.")|2,776|TSV|[2019](https://arxiv.org/abs/1904.04365)|English|<a target="_blank" href="https://paperswithcode.com/paper/aqua-an-adversarially-authored-question" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[TextVQA](https://textvqa.org/dataset "TextVQA requires models to read and reason about text in images to answer questions about them. Specifically, models need to incorporate a new modality of text present in the images and reason over it to answer TextVQA questions.")|36,602|JSON, PNG|[2019](https://arxiv.org/abs/1904.08920)|English|<a target="_blank" href="https://paperswithcode.com/paper/towards-vqa-models-that-can-read" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Social IQA](https://leaderboard.allenai.org/socialiqa/submissions/get-started "Dataset used fo question-answering benchmark for testing social commonsense intelligence.")|37,000+|JSON|[2019](https://arxiv.org/abs/1904.09728)|English|<a target="_blank" href="https://paperswithcode.com/paper/socialiqa-commonsense-reasoning-about-social" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=social_i_qa" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Common Sense Explanations (CoS-E)](https://github.com/salesforce/cos-e "Dataset used to train language models to automatically generate explanations that can be used during training and inference in a novel Commonsense Auto-Generated Explanation (CAGE) framework.")|19,522|JSON|[2019](https://arxiv.org/abs/1906.02361)|English|<a target="_blank" href="https://paperswithcode.com/paper/explain-yourself-leveraging-language-models" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=cos_e" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Activitynet-QA](https://github.com/MILVLG/activitynet-qa "Dataset contains 58,000 human-annotated QA pairs on 5,800 videos derived from the popular ActivityNet dataset. The dataset provides a benckmark for testing the performance of VideoQA models on long-term spatio-temporal.")|58k|JSON|[2019](https://arxiv.org/abs/1906.02467)|English|<a target="_blank" href="https://paperswithcode.com/paper/activitynet-qa-a-dataset-for-understanding" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Cosmos QA](https://github.com/wilburOne/cosmosqa/tree/master/data/ "Dataset containing thousands ofÂ problems that requireÂ commonsense-based reading comprehension, formulated asÂ multiple-choiceÂ questions.")|35k|CSV|[2019](https://arxiv.org/abs/1909.00277)|English|<a target="_blank" href="https://paperswithcode.com/paper/cosmos-qa-machine-reading-comprehension-with" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=cosmos_qa" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Physical IQA](https://leaderboard.allenai.org/physicaliqa/submissions/get-started "Dataset is used for commonsense QA benchmark for naive physics reasoning focusing on how we interact with everyday objects in everyday situations. The dataset includes 20,000 QA pairs that are either multiple-choice or true/false questions.")|20k|JSON|[2019](https://arxiv.org/abs/1911.11641)|English|<a target="_blank" href="https://paperswithcode.com/paper/piqa-reasoning-about-physical-commonsense-in" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Numeric Fused-Heads](https://github.com/yanaiela/num_fh/tree/master/data/resolution/processed "Dataset contains annotated sentences of numeric-fused-heads, along with their "missing head". A number refers to an implicit (and not explicitly provided) reference. For example, in the sentence "I miss being 10", the number 10 refers to the age of 10, but is not explicitly said.")|9,412|JSON|[2019](https://www.mitpressjournals.org/doi/pdf/10.1162/tacl_a_00280)|English||
|[Visual Commonsense Graphs](https://visualcomet.xyz/dataset "Dataset consists of over 1.4 million textual descriptions of visual commonsense inferences carefully annotated over a diverse set of 59,000 images, each paired with short video summaries of before and after.")|59k|JSON, JPG|[2020](https://arxiv.org/abs/2004.10796)|English|<a target="_blank" href="https://paperswithcode.com/paper/visual-commonsense-graphs-reasoning-about-the" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[LogiQA](https://github.com/lgw863/LogiQA-dataset "Dataset consists of 8,678 QA instances, covering multiple types of deductive reasoning. Multiple-choice.")|8,678|Text|[2020](https://arxiv.org/abs/2007.08124)|English|<a target="_blank" href="https://paperswithcode.com/paper/logiqa-a-challenge-dataset-for-machine" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Commonsense Inference

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Event2Mind](https://uwnlp.github.io/event2mind/ "Dataset contains 25,000 events and free-form descriptions of their intents and reactions")|25k|CSV|[2018](https://arxiv.org/abs/1805.06939)|English|<a target="_blank" href="https://paperswithcode.com/paper/event2mind-commonsense-inference-on-events" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=event2Mind" title="Open in Huggingface" target="_blank">ð¤</a>|

## Commonsense Reasoning

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Choice of Plausible Alternatives (COPA)](http://people.ict.usc.edu/~gordon/copa.html "Dataset used for open-domain commonsense causal reasoning.")|1k|XML|[2011](http://commonsensereasoning.org/2011/papers/Roemmele.pdf)|English||
|[HellaSwag](https://rowanzellers.com/hellaswag/ "Dataset for studying grounded commonsense inference. It consists of 70k multiple choice questions about grounded situations: each question comes from one of two domains -- activitynet or wikihow -- with four answer choices about what might happen next in the scene.")|70k|JSON|[2019](https://arxiv.org/abs/1905.07830)|English|<a target="_blank" href="https://paperswithcode.com/paper/hellaswag-can-a-machine-really-finish-your" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=hellaswag" title="Open in Huggingface" target="_blank">ð¤</a>|
|[WinoGrande](https://leaderboard.allenai.org/winogrande/submissions/get-started "Formulated as a fill-in-a-blank task with binary options, the goal is to choose the right option for a given sentence which requires commonsense reasoning.")|44k|JSON|[2019](https://arxiv.org/abs/1907.10641)|English|<a target="_blank" href="https://paperswithcode.com/paper/winogrande-an-adversarial-winograd-schema" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=winogrande" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Cross-lingual Choice of Plausible Alternatives (XCOPA)](https://github.com/cambridgeltl/xcopa "Dataset is the translation and reannotation of the English COPA and covers 11 languages: Estonian, Haitian Creole, Indonesian, Italian, Quechua, Swahili, Tamil, Thai, Turkish, Vietnamese & Mandarin Chinese. The dataset requires both the command of world knowledge and the ability to generalise to new languages.")|-|JSON|[2020](https://arxiv.org/abs/2005.00333)|Multi-Lingual|<a target="_blank" href="https://paperswithcode.com/paper/xcopa-a-multilingual-dataset-for-causal" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=xcopa" title="Open in Huggingface" target="_blank">ð¤</a>|

## Compositional Learning

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Simplified Versions of the CommAI Navigation tasks (SCAN)](https://github.com/brendenlake/SCAN "Dataset used for for studying compositional learning and zero-shot generalization. SCAN consists of a set of commands and their corresponding action sequences.")|20,000+|Text|[2018](https://arxiv.org/abs/1711.00350)|English|<a target="_blank" href="https://paperswithcode.com/paper/generalization-without-systematicity-on-the" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=scan" title="Open in Huggingface" target="_blank">ð¤</a>|

## Constituency

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Genia](http://www.geniaproject.org/genia-corpus "Dataset contains 1,999 Medline abstracts, selected using a PubMed query for the three MeSH terms "human", "blood cells", and "transcription factors". The corpus has been annotated for part-of-speech, contituency syntactic, terms, events, relations, and coreference.")|1,999|Text, XML|[2003]()|English||

## Coreference Resolution

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Genia](http://www.geniaproject.org/genia-corpus "Dataset contains 1,999 Medline abstracts, selected using a PubMed query for the three MeSH terms "human", "blood cells", and "transcription factors". The corpus has been annotated for part-of-speech, contituency syntactic, terms, events, relations, and coreference.")|1,999|Text, XML|[2003]()|English||
|[The Winograd Schema Challenge](https://cs.nyu.edu/faculty/davise/papers/WinogradSchemas/WS.html "Dataset to determine the correct referrent of the pronoun from among the provided choices.")|150|XML|[2012](https://www.aaai.org/ocs/index.php/KR/KR12/paper/view/4492/4924)|Multi-Lingual||
|[Winogender Schemas](https://github.com/rudinger/winogender-schemas "Dataset with pairs of sentences that differ only by the gender of one pronoun in the sentence, designed to test for the presence of gender bias in automated coreference resolution systems.")|720|TSV|[2018](https://arxiv.org/abs/1804.09301)|English|<a target="_blank" href="https://paperswithcode.com/paper/gender-bias-in-coreference-resolution" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[GAP Coreference Dataset](https://github.com/google-research-datasets/gap-coreference "Dataset contains 8,908 gender-balanced coreference-labeled pairs of (ambiguous pronoun, antecedent name), sampled from Wikipedia.")|8,908|TSV|[2018](https://arxiv.org/abs/1810.05201)|English|<a target="_blank" href="https://paperswithcode.com/paper/mind-the-gap-a-balanced-corpus-of-gendered" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=gap" title="Open in Huggingface" target="_blank">ð¤</a>|
|[ParCorFull](https://lindat.mff.cuni.cz/repository/xmlui/handle/11372/LRT-2614 "A parallel corpus annotated for the task of translation of corefrence across languages.")|14,927|XML|[2018](https://www.aclweb.org/anthology/L18-1065.pdf)|German, English||

## Credibility

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Credbank](https://compsocial.github.io/CREDBANK-data/ "Dataset comprises more than 60M tweets grouped into 1,049 real-world events, each annotated by 30 human annotators.")|60M|-|[2015](http://comp.social.gatech.edu/papers/icwsm15.credbank.mitra.pdf)|English||

## Cross-Lingual Summarization

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[NCLS-Corpora](https://github.com/ZNLP/NCLS-Corpora "Contains two datasets for cross-lingual summarization: ZH2ENSUM and EN2ZHSUM. There exists 370,759 English-to-Chinese cross-lingual summarization (CLS) pairs from ENSUM and 1,699,713 Chinese-to-English CLS pairs.")|2M+|Text|[2019](https://arxiv.org/abs/1909.00156)|Chinese, English|<a target="_blank" href="https://paperswithcode.com/paper/ncls-neural-cross-lingual-summarization" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Data-to-Text

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Rotowire and SBNation Datasets](https://github.com/harvardnlp/boxscore-data "Dataset consists of (human-written) NBA basketball game summaries aligned with their corresponding box and line scores.")|~15,000|JSON|[2017](https://arxiv.org/abs/1707.08052)|English|<a target="_blank" href="https://paperswithcode.com/paper/challenges-in-data-to-document-generation" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[LogicNLG](https://github.com/wenhuchen/LogicNLG "Dataset is a table-based factchecking dataset with rich logical inferences in the annotated statements.")|37k|JSON|[2020](https://arxiv.org/abs/2004.10404)|English|<a target="_blank" href="https://paperswithcode.com/paper/logical-natural-language-generation-from-open" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Logic2Text](https://github.com/czyssrs/Logic2Text "Dataset contains 5,600 tables and 10,753 descriptions involving common logic types paired with the underlying logical forms.")|10,753|JSON|[2020](https://arxiv.org/abs/2004.14579)|English|<a target="_blank" href="https://paperswithcode.com/paper/logic2text-high-fidelity-natural-language" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Defect Detection

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[CodeXGLUE: Defect Detection Dataset](https://github.com/microsoft/CodeXGLUE/tree/main/Code-Code/Defect-detection "Given a source code, the task is to identify whether it is an insecure code that may attack software systems, such as resource leaks, use-after-free vulnerabilities and DoS attack. We treat the task as binary classification (0/1), where 1 stands for insecure code and 0 for secure code.")|27,318|JSON, Text|[2019](http://papers.nips.cc/paper/9209-devign-effective-vulnerability-identification-by-learning-comprehensive-program-semantics-via-graph-neural-networks.pdf)|Coding Lang: C||

## Definition Extraction

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Deft](https://github.com/adobe-research/deft_corpus "Dataset contains annotated content from two different data sources: 1) 2,443 sentences from various 2017 SEC contract filings from the publicly available US Securities and Exchange Commission EDGAR (SEC) database, and 2) 21,303 sentences from open source textbooks including topics in biology, history, physics, psychology, economics, sociology, and government. ")|23,746|Text|[2019](https://www.aclweb.org/anthology/W19-4015.pdf)|English||

## Dialogue

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[NPS Chat Corpus](https://www.kaggle.com/nltkdata/nps-chat "Posts from age-specific online chat rooms.")|~500,000|XML|[2007](https://core.ac.uk/download/pdf/36731948.pdf)|English||
|[Cornell Movie--Dialogs Corpus](http://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html "This corpus contains a large metadata-rich collection of fictional conversations extracted from raw movie scripts. 220,579 conversational exchanges between 10,292 pairs of movie characters, involves 9,035 characters from 617 moviesin. total 304,713 utterances.")|304,713|Text|[2011](https://arxiv.org/abs/1106.3077)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=cornell_movie_dialog" title="Open in Huggingface" target="_blank">ð¤</a>|
|[UseNet Corpus](https://www.psych.ualberta.ca/~westburylab/downloads/usenetcorpus.download.html "UseNet forum postings.")|7B|Text|[2011](https://www.psych.ualberta.ca/~westburylab/downloads/usenetcorpus.download.html)|English||
|[NUS SMS Corpus](https://www.kaggle.com/rtatman/the-national-university-of-singapore-sms-corpus "SMS messages collected between 2 users, with timing analysis.")|67,093|XML|[2013](https://link.springer.com/article/10.1007%2Fs10579-012-9197-9)|Mandarin, English||
|[Ubuntu Dialogue Corpus](https://www.kaggle.com/rtatman/ubuntu-dialogue-corpus "Dialogues extracted from Ubuntu chat stream on IRC.")|930,000Â |CSV|[2015](https://www.aclweb.org/anthology/W15-4640.pdf)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=ubuntu_dialogs_corpus" title="Open in Huggingface" target="_blank">ð¤</a>|
|[OpenSubtitles](http://opus.nlpl.eu/OpenSubtitles2018.php "Dataset of multi-lingual dialogs from movie scripts. Includes 62 languages.")|-|XML, XCES|[2016](http://www.lrec-conf.org/proceedings/lrec2016/pdf/947_Paper.pdf)|Multi-Lingual||
|[babI 6 Tasks Dialogue](https://research.fb.com/downloads/babi/ "Dataset contains 6 tasks for testing end-to-end dialog systems in the restaurant domain.")|3k|Text|[2017](https://arxiv.org/abs/1605.07683)|English|<a target="_blank" href="https://paperswithcode.com/paper/learning-end-to-end-goal-oriented-dialog" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[VisDial](https://visualdialog.org/data "Dataset contains images from COCO training set, and dialogues. Meant to be used for model to be trained in answering questions about images during conversation. Contains 1.2M dialog question-answers.")|1.2M|JSON|[2017](https://arxiv.org/abs/1703.06585)|English|<a target="_blank" href="https://paperswithcode.com/paper/learning-cooperative-visual-dialog-agents" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[MMD](https://amritasaha1812.github.io/MMD/ "Dataset contains over 150K conversation sessions between shoppers and sales agents.")|150,000+|JSON|[2017](https://arxiv.org/abs/1704.00200)|English|<a target="_blank" href="https://paperswithcode.com/paper/towards-building-large-scale-multimodal" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[MutualFriends](https://stanfordnlp.github.io/cocoa/ "Task where two agents must discover which friend of theirs is mutual based on the friend's attributes.")|-|JSON|[2017](https://arxiv.org/abs/1704.07130)|English|<a target="_blank" href="https://paperswithcode.com/paper/learning-symmetric-collaborative-dialogue" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Deal or No Deal? End-to-End Learning for Negotiation Dialogues](https://github.com/facebookresearch/end-to-end-negotiator "This dataset consists of 5,808 dialogues, based on 2,236 unique scenarios dealing with negotiations and complex communication.")|5,808|Text|[2017](https://arxiv.org/abs/1706.05125)|English|<a target="_blank" href="https://paperswithcode.com/paper/deal-or-no-deal-end-to-end-learning-for" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Personalized Dialog](https://github.com/chaitjo/personalized-dialog "Dataset of dialogs from movie scripts.")|12k|Text|[2017](https://arxiv.org/abs/1706.07503)|English|<a target="_blank" href="https://paperswithcode.com/paper/personalization-in-goal-oriented-dialog" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Twitter Chat Corpus](https://github.com/marsan-ma/chat_corpus "Dataset contains Twitter question-answer pairs.")|5M|Text|[2017](https://github.com/Marsan-Ma/chat_corpus)|English||
|[A Multi-Turn, Multi-Domain Dialogue Dataset (KVRET)](https://nlp.stanford.edu/blog/a-new-multi-turn-multi-domain-task-oriented-dialogue-dataset/ "Dataset contains 3,031 multi-turn dialogues in three distinct domains appropriate for an in-car assistant: calendar scheduling, weather information retrieval, and point-of-interest navigation.")|3,301|JSON|[2017](https://nlp.stanford.edu/pubs/eric2017kvret.pdf)|English||
|[Frames](https://www.microsoft.com/en-us/research/project/frames-dataset/ "Dataset contains 1,369 human-human dialogues with an average of 15 turns per dialogue. This corpus contains goal-oriented dialogues between users who are given some constraints to book a trip and assistants who search a database to find appropriate trips.")|1,369|JSON|[2017](https://www.aclweb.org/anthology/W17-5526v2.pdf)|English||
|[The Conversational Intelligence Challenge 2 (ConvAI2)](http://convai.io/data/ "A chit-chat dataset based on PersonaChat dataset.")|3,127|JSON|[2018]()|English||
|[Microsoft Information-Seeking Conversation (MISC) dataset](https://www.microsoft.com/en-us/download/details.aspx?id=55594 "Dataset contains recordings of information-seeking conversations between human âseekersâ and âintermediariesâ. It includes audio and video signals; transcripts of conversation; affectual and physiological signals; recordings of search and other computer use; and post-task surveys on emotion, success, and effort.")|-|various|[2018](https://arxiv.org/abs/1804.08759)|English|<a target="_blank" href="https://paperswithcode.com/paper/analyzing-and-characterizing-user-intent-in" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Code-Mixed-Dialog](https://github.com/sumanbanerjee1/Code-Mixed-Dialog "A goal-oriented dialog dataset containing code-mixed conversations. Specifically, text from the DSTC2 restaurant reservation dataset and create code-mixed versions of it in Hindi-English, Bengali-English, Gujarati-English and Tamil-English.")|49,167|Text|[2018](https://arxiv.org/abs/1806.05997)|Multi-Lingual|<a target="_blank" href="https://paperswithcode.com/paper/a-dataset-for-building-code-mixed-goal" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Talk the Walk](https://github.com/facebookresearch/talkthewalk "Dataset consists of over 10k crowd-sourced dialogues in which two human annotators collaborate to navigate to target locations in the virtual streets of NYC.")|10,000+|JSON, JPG|[2018](https://arxiv.org/abs/1807.03367)|English|<a target="_blank" href="https://paperswithcode.com/paper/talk-the-walk-navigating-new-york-city" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[CraigsListBargain](https://github.com/stanfordnlp/cocoa/tree/master/craigslistbargain "Dataset contains 6,682 human-human dialogues where 2 agents negotiate the sale/purchase of an item.")|6,682|JSON|[2018](https://arxiv.org/abs/1808.09637)|English|<a target="_blank" href="https://paperswithcode.com/paper/decoupling-strategy-and-generation-in" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Background Knowledge Dialogue Dataset](https://github.com/nikitacs16/Holl-E "Dataset containing movie chats wherein each response is explicitly generated by copying and/or modifying sentences from unstructured background knowledge such as plots, comments and reviews about the movie.")|90k|JSON|[2018](https://arxiv.org/abs/1809.08205)|English|<a target="_blank" href="https://paperswithcode.com/paper/towards-exploiting-background-knowledge-for" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Multi-Domain Wizard-of-Oz Dataset (MultiWoz)](https://www.repository.cam.ac.uk/handle/1810/280608 "Dataset of human-human written conversations spanning over multiple domains and topics. The dataset was collected based on the Wizard of Oz experiment on Amazon MTurk.")|10,438|JSON|[2018](https://arxiv.org/abs/1810.00278)|English|<a target="_blank" href="https://paperswithcode.com/paper/multiwoz-a-large-scale-multi-domain-wizard-of" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[AirDialogue](https://github.com/google/airdialogue "Dataset contains 402,038 goal-oriented conversations.")|402,038|JSON|[2018](https://www.aclweb.org/anthology/D18-1419.pdf)|English||
|[Soccer Dialogues](https://github.com/SmartDataAnalytics/KG-Copy_Network/tree/master/soccer_conversations "Dataset contains soccer dialogues over a knowledge graph")|2,890|JSON|[2019]()|English||
|[EmpatheticDialogues](https://github.com/facebookresearch/EmpatheticDialogues "Dataset of 25k conversations grounded in emotional situations.")|25k|CSV|[2019](https://arxiv.org/abs/1811.00207)|English|<a target="_blank" href="https://paperswithcode.com/paper/i-know-the-feeling-learning-to-converse-with" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=empathetic_dialogues" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Dialogue Natural Language Inference (NLI)](https://wellecks.github.io/dialogue_nli/ "Dataset used to improve the consistency of a dialogue model. It consists of sentence pairs labeled as entailment (E), neutral (N), or contradiction (C)."")|340,000+|JSON|[2019](https://arxiv.org/abs/1811.00671)|English|<a target="_blank" href="https://paperswithcode.com/paper/dialogue-natural-language-inference" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Audio Visual Scene-Aware Dialog (AVSD)](https://video-dialog.com/ "Dataset consists of text-based human conversations about short videos from the Charades dataset.")|11,816|JSON|[2019](https://arxiv.org/abs/1901.09107)|English|<a target="_blank" href="https://paperswithcode.com/paper/audio-visual-scene-aware-dialog" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Dialogue-Based Reading Comprehension Examination (DREAM)](https://dataset.org/dream/ "Dataset contains 10,197 multiple choice questions for 6,444 dialogues, collected from English-as-a-foreign-language examinations designed by human experts. DREAM is likely to present significant challenges for existing reading comprehension systems: 84% of answers are non-extractive, 85% of questions require reasoning beyond a single sentence, and 34% of questions also involve commonsense knowledge.")|6,444|JSON|[2019](https://arxiv.org/abs/1902.00164)|English|<a target="_blank" href="https://paperswithcode.com/paper/dream-a-challenge-dataset-and-models-for" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[DiaBLa](https://github.com/rbawden/DiaBLa-dataset "Parallel dataset of spontaneous, written, bilingual dialogues for the evaluation of Machine Translation, annotated for human judgments of translation quality.")|5,700+|JSON|[2019](https://arxiv.org/abs/1905.13354)|French, English|<a target="_blank" href="https://paperswithcode.com/paper/diabla-a-corpus-of-bilingual-spontaneous" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[OneCommon](https://github.com/Alab-NII/onecommon "Dataset contains 6,760 dialogues.")|6,760|JSON|[2019](https://arxiv.org/abs/1907.03399)|English|<a target="_blank" href="https://paperswithcode.com/paper/a-natural-language-corpus-of-common-grounding" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Meta-Learning Wizard-of-Oz (MetaLWOz)](https://www.microsoft.com/en-us/research/project/metalwoz/ "Dataset designed to help develop models capable of predicting user responses in unseen domains. It was created by crowdsourcing 37,884 goal-oriented dialogs, covering 227 tasks in 47 domains.")|37,884|Text|[2019](https://arxiv.org/abs/1908.05854)|English|<a target="_blank" href="https://paperswithcode.com/paper/few-shot-dialogue-generation-without" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Taskmaster-1](https://research.google/tools/datasets/taskmaster-1/ "Dataset contains 13,215 task-based dialogs, including 5,507 spoken and 7,708 written dialogs created with two distinct procedures. Each conversation falls into one of six domains: ordering pizza, creating auto repair appointments, setting up ride service, ordering movie tickets, ordering coffee drinks and making restaurant reservations.")|13,215|JSON|[2019](https://arxiv.org/abs/1909.05358)|English|<a target="_blank" href="https://paperswithcode.com/paper/taskmaster-1-toward-a-realistic-and-diverse" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Conversational Text-to-SQLÂ Systems (CoSQL)](https://yale-lily.github.io/cosql "Dataset consists of 30k+ turns plus 10k+ annotated SQL queries, obtained from aÂ Wizard-of-OzÂ collection of 3k dialogues querying 200 complex databases spanning 138 domains.It is the dilaogue version of the Spider and SParC tasks.")|3k|JSON, SQL|[2019](https://arxiv.org/abs/1909.05378)|English|<a target="_blank" href="https://paperswithcode.com/paper/cosql-a-conversational-text-to-sql-challenge" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Topical-Chat](https://github.com/alexa/alexa-prize-topical-chat-dataset "A knowledge-grounded human-human conversation dataset where the underlying knowledge spans 8 broad topics and conversation partners donât have explicitly defined roles.")|10,784|JSON|[2019](https://m.media-amazon.com/images/G/01/amazon.jobs/3079_Paper._CB1565131710_.pdf)|English||
|[OpenDialKG](https://github.com/facebookresearch/opendialkg "Dataset of conversations between two crowdsourcing agents engaging in a dialog about a given topic. Each dialog turn is paired with its corresponding âKG pathsâ that weave together the KG entities and relations that are mentioned in the dialog.")|15k|Text|[2019](https://www.aclweb.org/anthology/P19-1081.pdf)|English||
|[IRC Disentanglement](https://github.com/jkkummerfeld/irc-disentanglement/tree/master/data "Dataset contains 77,563 messages of internet relay chat (IRC). Almost all are from the Ubuntu IRC Logs.")|77,563|Text|[2019](https://www.aclweb.org/anthology/P19-1374.pdf)|English||
|[Coached Conversational Preference Elicitation](https://research.google/tools/datasets/coached-conversational-preference-elicitation/ "Dataset consisting of 502 English dialogs with 12,000 annotated utterances between a user and an assistant discussing movie preferences in natural language.")|12k|JSON|[2019](https://www.aclweb.org/anthology/W19-5941.pdf)|English||
|[Taskmaster -2 ](https://github.com/google-research-datasets/Taskmaster/tree/master/TM-2-2020 "Dataset consists of 17,289 dialogs in seven domains: restaurants (3276), food ordering (1050), movies (3047), hotels (2355), flights (2481), music (1602), and sports (3478). It consists entirely of spoken two-person dialogs.")|17,289|JSON|[2020]()|English||
|[Get it #OffMyChest](https://github.com/kj2013/claff-offmychest "Dataset is used for affective understanding of conversations focusing on the problem of how speakers use emotions to react to a situation and to each other. Posts were taken from the 2018 top reddit posts from /r/CasualConversations and /r/OffMyChest.")|437,860|CSV|[2020]()|English||
|[DoQa](http://ixa.eus/node/12931 "Dataset contains domain specific FAQs via conversational QA that contains 2,437 information-seeking question/answer dialogues (10,917 questions in total) on three different domains: cooking, travel and movies.")|10,917|JSON|[2020](http://ixa.eus/sites/default/files/dokumentuak/13030/DoQA_cameraready.pdf)|English||
|[Personal Events in Dialogue Corpus](http://www.artie.com/data/personaleventsindialogue/ "Dataset is a corpus containing annotated dialogue transcripts from fourteen episodes of the podcast This American Life. It contains 1,038 utterances, made up of 16,962 tokens, of which 3,664 represent events.")|1,038|Text|[2020](http://ml-corpora.artie.com/personal-events-in-dialogue-corpus/Eisenberg_NUSE_Personal_Event_Extraction_Paper.pdf)|English||
|[C3](https://github.com/nlpdata/c3 "Dataset is first free-form multipleChoice Chinese machine reading Comprehension dataset (C3), containing 13,369 documents (dialogues or more formally written mixed-genre texts) and their associated 19,577 multiple-choice free-form questions collected from Chinese-as-a-second language examinations.")|13,369|JSON|[2020](https://arxiv.org/abs/1904.09679)|Chinese|<a target="_blank" href="https://paperswithcode.com/paper/probing-prior-knowledge-needed-in-challenging" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[CrossWOZ](https://github.com/thu-coai/CrossWOZ "Dataset is a cross-domain wizard-of-oz task-oriented dataset. It containsÂ dialogue sessions andÂ utterances for 5 domains: hotel, restaurant, attraction, metro, and taxi.")|6k|JSON|[2020](https://arxiv.org/abs/2002.11893)|Chinese|<a target="_blank" href="https://paperswithcode.com/paper/crosswoz-a-large-scale-chinese-cross-domain" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[KdConv](https://github.com/thu-coai/KdConv "Dataset is a Chinese multi-domain dataset, grounding the topics in multi-turn conversations to knowledge graphs. KdConv contains 4.5K conversations from three domains (film, music, and travel), and 86K utterances with an average turn number of 19.0. ")|4,500|JSON|[2020](https://arxiv.org/abs/2004.04100)|Chinese|<a target="_blank" href="https://paperswithcode.com/paper/kdconv-a-chinese-multi-domain-dialogue" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[MuTual](https://github.com/Nealcly/MuTual "Retrieval-based dataset for multi-turn dialogue reasoning, which is modified from Chinese high school English listening comprehension test data.")|8,860|Text|[2020](https://arxiv.org/abs/2004.04494)|English|<a target="_blank" href="https://paperswithcode.com/paper/mutual-a-dataset-for-multi-turn-dialogue" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Gutenberg Dialogue](https://github.com/ricsinaruto/gutenberg-dialog "A dataset created by extracting dialogue from the Gutenberg book collection, comprising of ~60,000 books. Currently it supports English, German, Dutch, Spanish, Portuguese, Italian, and Hungarian.")|59,971|-|[2020](https://arxiv.org/abs/2004.12752)|Multi-Lingual|<a target="_blank" href="https://paperswithcode.com/paper/the-gutenberg-dialogue-dataset" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[DailyDialog++](https://github.com/iitmnlp/Dialogue-Evaluation-with-BERT "DailyDialog++ is an open-domain dialogue evaluation dataset consisting of 19k contexts with five relevant responses for each context. Additionally for 11k contexts, it includes five adversarial irrelevant responses which are specifically crafted to have lexical or semantic overlap with the context but are still unacceptable as valid responses.")|19k|JSON|[2020](https://arxiv.org/abs/2009.11321)|English|<a target="_blank" href="https://paperswithcode.com/paper/improving-dialog-evaluation-with-a-multi" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[ClariQ](https://github.com/aliannejadi/ClariQ "Dataset consists of single-turn conversations (initial_request, followed by clarifying question and answer). In addition, it comes with synthetic multi-turn conversations (up to three turns). ClariQ features approximately 18K single-turn conversations, as well as 1.8 million multi-turn conversations.")|1.8M|TSV, JSON|[2020](https://arxiv.org/abs/2009.11352)|English|<a target="_blank" href="https://paperswithcode.com/paper/convai3-generating-clarifying-questions-for" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[DialoGLUE](https://github.com/alexa/DialoGLUE/ "Benchmark for task oriented dialogue containing 7 datasets: Banking77 containing online banking queries, HWU64 containing popular personal assistant queries, CLINC150 containing popular personal assistant queries, Restaurant8k containing restaurant booking domain queries, DSTC8 SGD containing multi-domain, task-oriented conversations between a human and a virtual assistant, and TOP containing compositional queries for hierachical semantic representations, MultiWOZ 2.1 12K multi-domain dialogues with multiple turns.")|100k|JSON, CSV, Text|[2020](https://arxiv.org/abs/2009.13570)|English|<a target="_blank" href="https://paperswithcode.com/paper/dialoglue-a-natural-language-understanding" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[MedDG](https://github.com/lwgkzl/MedDG "Dataset contains more than 17K conversations collected from the online health consultation community relating to 12 types of common Gastrointestinal diseases. Five different categories of entities, including diseases, symptoms, attributes, tests, and medicines, are annotated in each conversation of MedDG as additional labels.")|17k|-|[2020](https://arxiv.org/abs/2010.07497)|Chinese|<a target="_blank" href="https://paperswithcode.com/paper/meddg-a-large-scale-medical-consultation" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[DialogRE](https://github.com/nlpdata/dialogre "Dataset contains human-annotated dialogue-based relation extraction containing 1,788 dialogues originating from the complete transcripts of a famous American television situation comedy "Friends". There are 36 possible relation types that exist between an argument pair in a dialogue.")|1,788|JSON|[2020](https://www.aclweb.org/anthology/2020.acl-main.444.pdf)|Chinese, English||
|[Critical Role Dungeons and Dragons Dataset (CRD3)](https://github.com/RevanthRameshkumar/CRD3 "Dataset is collected from 159 Critical Role episodes transcribed to text dialogues, consisting of 398,682 turns. It also includes corresponding abstractive summaries collected from the Fandom wiki. Critical Role is an unscripted, live-streamed show where a fixed group of people play Dungeons and Dragons.")|398,682|JSON|[2020](https://www.aclweb.org/anthology/2020.acl-main.459.pdf)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=crd3" title="Open in Huggingface" target="_blank">ð¤</a>|
|[SMCalFlow](https://microsoft.github.io/task_oriented_dialogue_as_dataflow_synthesis/ "Dataset contains natural conversations about tasks involving calendars, weather, places, and people. Each turn is annotated with an executable dataflow program featuring API calls, function composition, and complex constraints built from strings, numbers, dates and times.")|36,296|JSON|[2020](https://www.mitpressjournals.org/doi/pdf/10.1162/tacl_a_00333)|English||

## Dialogue Act Classification

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Switchboard Dialogue Act Corpus (SwDA)](http://compprag.christopherpotts.net/swda.html "A subset of the Switchboard-1 corpus consisting of 1,155 conversations and 42 tags")|1,155|UTT|[1997](https://web.stanford.edu/~jurafsky/ws97/asru97.pdf)|English||

## Dialogue State Tracking

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Schema-Guided Dialogue State Tracking (DSTC 8)](https://github.com/google-research-datasets/dstc8-schema-guided-dialogue "Dataset contains 18K dialogues between a virtual assistant and a user.")|~18,000|JSON|[2019](https://arxiv.org/abs/1909.05855)|English|<a target="_blank" href="https://paperswithcode.com/paper/towards-scalable-multi-domain-conversational" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Discriminating between similar languages

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[DSL Corpus Collection (DSLCC)](https://www.kaggle.com/vardial/dslcc "Dataset contains short excerpts of journalistic texts in similar languages and dialects.")|294k|Text|[2017](http://ttg.uni-saarland.de/resources/DSLCC/papers/bucc2014.pdf)|Multi-Lingual||

## Document Classification

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[HoC (Hallmarks of Cancer)](https://github.com/sb895/Hallmarks-of-Cancer "Dataset consists of 1,852 PubMed publication abstracts manually annotated by experts according to the Hallmarks of Cancer taxonomy. The taxonomy consists of 37 classes in a hierarchy.")|1,852|Text|[2016](https://academic.oup.com/bioinformatics/article/32/3/432/1743783)|English||

## Document Layout Analysis

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[DocBank](https://github.com/doc-analysis/DocBank "Dataset contains fine-grained token-level annotations for document layout analysis. It includes 5,053 documents and both the validation set and the test set include 100 documents.")|5,053|-|[2020](https://arxiv.org/abs/2006.01038)|English|<a target="_blank" href="https://paperswithcode.com/paper/docbank-a-benchmark-dataset-for-document" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Document Ranking

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Open Resource for Click Analysis in Search (ORCAS)](https://microsoft.github.io/TREC-2020-Deep-Learning/ORCAS "ORCAS is a click-based dataset associated with the TREC Deep Learning Track. It covers 1.4 million of the TREC DL documents, providing 18 million connections to 10 million distinct queries.")|10,405,342|TSV|[2020](https://arxiv.org/abs/2006.05324)|English|<a target="_blank" href="https://paperswithcode.com/paper/orcas-18-million-clicked-query-document-pairs" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Embeddings

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Tencent AI Lab Embedding Corpus](https://ai.tencent.com/ailab/nlp/embedding.html "Dataset provides 200-dimension vector representations, a.k.a. embeddings, for over 8 million Chinese words and phrases.")|8M|Text|[2018](https://www.aclweb.org/anthology/N18-2028.pdf)|Chinese||
|[Datasets Knowledge Embedding](https://github.com/simonepri/datasets-knowledge-embedding "Several datasets containing edges and nodes for knowledge base building.")|-|TSV|[2019]()|English||

## Emotion Classification

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Affective Text](https://github.com/sarnthil/unify-emotion-datasets/tree/master/datasets "Classification of emotions in 250 news headlines. Categories: anger, disgust, fear, joy, happiness, sadness, surprise.")|250|SGML, Text|[2007](https://web.eecs.umich.edu/~mihalcea/papers/strapparava.semeval07.pdf)|English||
|[Emotion-Stimulus](http://www.site.uottawa.ca/~diana/resources/emotion_stimulus_data/ "Dataset annotated with both the emotion and the stimulus using FrameNetâs emotions-directed frame. 820 sentences with both cause and emotion and 1594 sentences marked with their emotion tag. Categories: happiness, sadness, anger, fear, surprise, disgust and shame.")|2,414|XML|[2015](http://www.site.uottawa.ca/~diana/publications/90420152.pdf)|English||
|[The Emotion in Text](https://github.com/sarnthil/unify-emotion-datasets/tree/master/datasets "Dataset of tweets labelled with emotion. Categories: empty, sadness, enthusiasm, neutral, worry, sadness, love, fun, hate, happiness, relief, boredom, surprise, anger.")|40k|CSV|[2016](https://www.researchgate.net/publication/318740457_Emotion_Intensities_in_Tweets)|English||
|[DailyDialog](http://yanran.li/dailydialog.html "A manually labelled conversations dataset. Categories: no emotion, anger, disgust, fear, happiness, sadness, surprise.")|13,118|Text|[2017](https://www.aclweb.org/anthology/I17-1099.pdf)|English||
|[Classify Emotional Relationships of Fictional Characters](https://www.ims.uni-stuttgart.de/forschung/ressourcen/korpora/relationalemotions/ "Dataset contains 19 short stories that are shorter than 1,500 words, and depict at least four different characters.")|19|Text|[2019](https://arxiv.org/abs/1903.12453)|English|<a target="_blank" href="https://paperswithcode.com/paper/frowning-frodo-wincing-leia-and-a-seriously" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Event-focused Emotion Corpora for German and English](https://www.ims.uni-stuttgart.de/forschung/ressourcen/korpora/deisear/ "German and English emotion corpora for emotion classification, annotated with crowdsourcing in the style of the ISEAR resources.")|2,002|TSV|[2019](https://arxiv.org/abs/1905.13618)|German, English|<a target="_blank" href="https://paperswithcode.com/paper/crowdsourcing-and-validating-event-focused" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Vietnamese Social Media Emotion Corpus (UIT-VSMEC)](https://drive.google.com/drive/folders/1HooABJyrddVGzll7fgkJ6VzkG_XuWfRu "Dataset contains 6,927 human-annotated sentences with six emotion labels, contributing to emotion recognition research in Vietnamese.")|6,927|Excel|[2019](https://arxiv.org/abs/1911.09339)|Vietnamese|<a target="_blank" href="https://paperswithcode.com/paper/emotion-recognition-for-vietnamese-social" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Emotion Recognition

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Crema-D](https://github.com/CheyneyComputerScience/CREMA-D "Dataset consists of facial and vocal emotional expressions in sentences spoken in a range of basic emotional states (happy, sad, anger, fear, disgust, and neutral). 7,442 clips of 91 actors with diverse ethnic backgrounds were collected.")|7,438|Wav, MP3, Flash|[2014](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4313618/)|English||
|[CMU Multimodal Opinion Sentiment and Emotion Intensity (CMU-MOSEI)](https://github.com/A2Zadeh/CMU-MultimodalSDK "Dataset contains more than 23,500 sentence utterance videos from more than 1000 online YouTube speakers. The dataset is gender balanced. All the sentences utterance are randomly chosen from various topics and monologue videos.")|23,500|-|[2018](https://www.aclweb.org/anthology/P18-1208.pdf)|English||

## Entailment

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Recognizing Textual Entailment (RTE)](https://dl.fbaipublicfiles.com/glue/superglue/data/v2/RTE.zip "Datasets are combined and converted to two-class classification: entailment and not_entailment.")|-|JSON|[2006-2009](http://u.cs.biu.ac.il/~nlp/RTE2/Proceedings/01.pdf)|English||
|[Sentences Involving Compositional Knowledge (SICK)](https://zenodo.org/record/2787612 "Dataset contains sentence pairs, generated from two existing sets: theÂ 8K ImageFlickr data setÂ and theÂ SemEval 2012 STS MSR-Video Description.")|~10,000|Text|[2014](https://www.aclweb.org/anthology/S14-2001.pdf)|English||
|[MultiNLI Matched/Mismatched](http://www.nyu.edu/projects/bowman/multinli/ "Dataset contains sentence pairs annotated with textual entailment information.")|433k|JSON, Text|[2017](https://arxiv.org/abs/1707.08172)|English|<a target="_blank" href="https://paperswithcode.com/paper/the-repeval-2017-shared-task-multi-genre" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=multi_nli_mismatch" title="Open in Huggingface" target="_blank">ð¤</a>|
|[SciTail Dataset](http://data.allenai.org/scitail/ "Dataset is an entailment dataset created from multiple-choice science exams and web sentences. Each question and the correct answer choice are converted into an assertive statement to form the hypothesis.")|27,026|SNLI, TSV, DGEM|[2018](http://ai2-website.s3.amazonaws.com/publications/scitail-aaai-2018_cameraready.pdf)|English||
|[The Cross-lingual Natural Language Inference corpus (XNLI)](http://www.nyu.edu/projects/bowman/xnli/ "Dataset contains collection of 5,000 test and 2,500 dev pairs for theÂ MultiNLI corpus. The pairs are annotated with textual entailment and translated into 14 languages:Â French, Spanish, German, Greek, Bulgarian, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese, Hindi, Swahili and Urdu.")|112,500|JSON, Text|[2018](https://arxiv.org/abs/1809.05053)|Multi-Lingual|<a target="_blank" href="https://paperswithcode.com/paper/xnli-evaluating-cross-lingual-sentence" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=xnli" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Dialogue Natural Language Inference (NLI)](https://wellecks.github.io/dialogue_nli/ "Dataset used to improve the consistency of a dialogue model. It consists of sentence pairs labeled as entailment (E), neutral (N), or contradiction (C)."")|340,000+|JSON|[2019](https://arxiv.org/abs/1811.00671)|English|<a target="_blank" href="https://paperswithcode.com/paper/dialogue-natural-language-inference" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Entity Extraction

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[DNA Methylation Corpus](http://www.geniaproject.org/other-corpora/dna-methylation-corpus "Dataset contains 200 abstracts including a representative sample of all PubMed citations relevant to DNA methylation, and introduce manual annotation for nearly 3,000 gene/protein mentions and 1,500 DNA methylation and demethylation events.")|200|Text|[2010](https://jbiomedsem.biomedcentral.com/track/pdf/10.1186/2041-1480-2-S5-S2)|English||
|[mTOR Pathway Corpus](http://www.geniaproject.org/other-corpora/mtor-pathway-corpus "Dataset contains 1,300 annotated eventÂ instances of protein associations and dissociation reactions.")|1,300|Text|[2011](https://www.aclweb.org/anthology/W11-0214.pdf)|English||

## Entity Linking

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[BSNLP-2019](http://bsnlp.cs.helsinki.fi/shared_task.html "Dataset used to classify named entities in web documents in Slavic languages, their lemmatization, and cross-language matching. Dataset covers 4 languages: Bulgarian, Czech, Polish, and Russian.")|-|Text, OUT|[2019](http://bsnlp.cs.helsinki.fi/shared_task_BNSLP_2019.pdf)|Multi-Lingual||

## Entity Ranking

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[OpinRank Review Dataset](http://archive.ics.uci.edu/ml/machine-learning-databases/00205/ "Reviews of cars and hotels from Edmunds.com and TripAdvisor.")|Edmunds: 42,230, TripAdivsor: 259,000|Text|[2011](http://kavita-ganesan.com/opinion-based-entity-ranking/#.Xme-5KhKiUk)|English||

## Entity Retrieval

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[OpinRank Review Dataset](http://archive.ics.uci.edu/ml/machine-learning-databases/00205/ "Reviews of cars and hotels from Edmunds.com and TripAdvisor.")|Edmunds: 42,230, TripAdivsor: 259,000|Text|[2011](http://kavita-ganesan.com/opinion-based-entity-ranking/#.Xme-5KhKiUk)|English||

## Event Extraction

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[T4SS Event Corpus](http://www.geniaproject.org/other-corpora/t4ss-event-corpus "Dataset contains 27 full text publications totaling 15,143 pseudo-sentences (text sentences plus table rows, references, etc.) and 244,942 tokens covering 4 classes: Bacteria, Cellular components, Biological Processes, and Molecular functions.")|27|Text|[2010]()|English||
|[DNA Methylation Corpus](http://www.geniaproject.org/other-corpora/dna-methylation-corpus "Dataset contains 200 abstracts including a representative sample of all PubMed citations relevant to DNA methylation, and introduce manual annotation for nearly 3,000 gene/protein mentions and 1,500 DNA methylation and demethylation events.")|200|Text|[2010](https://jbiomedsem.biomedcentral.com/track/pdf/10.1186/2041-1480-2-S5-S2)|English||
|[PTM Event Corpus](http://www.geniaproject.org/other-corpora/ptm-event-corpus "Dataset contains 157 PubMed abstracts annotated for over 1,000 proteins and 400 post-translational modification events identifying the modified proteins and sites.")|157|Text|[2010](https://www.aclweb.org/anthology/W10-1903.pdf)|English||
|[mTOR Pathway Corpus](http://www.geniaproject.org/other-corpora/mtor-pathway-corpus "Dataset contains 1,300 annotated eventÂ instances of protein associations and dissociation reactions.")|1,300|Text|[2011](https://www.aclweb.org/anthology/W11-0214.pdf)|English||
|[Exhaustive PTM Corpus](http://www.geniaproject.org/other-corpora/exhaustive-ptm-corpus "Dataset contains 360 abstracts manually annotated in the BioNLP Shared Task event representation for over 4,500 mentions of proteins and 1,000 statements of modification events of nearly 40 different types. ")|360|Text|[2011](https://www.aclweb.org/anthology/W11-0215.pdf)|English||
|[Personal Events in Dialogue Corpus](http://www.artie.com/data/personaleventsindialogue/ "Dataset is a corpus containing annotated dialogue transcripts from fourteen episodes of the podcast This American Life. It contains 1,038 utterances, made up of 16,962 tokens, of which 3,664 represent events.")|1,038|Text|[2020](http://ml-corpora.artie.com/personal-events-in-dialogue-corpus/Eisenberg_NUSE_Personal_Event_Extraction_Paper.pdf)|English||

## Events

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Genia](http://www.geniaproject.org/genia-corpus "Dataset contains 1,999 Medline abstracts, selected using a PubMed query for the three MeSH terms "human", "blood cells", and "transcription factors". The corpus has been annotated for part-of-speech, contituency syntactic, terms, events, relations, and coreference.")|1,999|Text, XML|[2003]()|English||
|[ExaminerÂ Pseudo-News Corpus](https://www.kaggle.com/therohk/examine-the-examiner "Clickbait, spam, crowd-sourced headlines from 2010 to 2015.")|3,089,781|CSV|[2017]()|English||
|[Worldwide News - Aggregate of 20KÂ Feeds](https://www.kaggle.com/therohk/global-news-week "One week snapshot of all online headlines in 20+ languages.")|1,398,431|CSV|[2017](https://pdfs.semanticscholar.org/48cd/042d645e60b125fd5b90f734900dae4211d8.pdf)|Multi-Lingual||
|[The Irish Times IRS](https://www.kaggle.com/therohk/ireland-historical-news "Dataset contains 23 years of events from Ireland.")|1,425,460|CSV|[2018]()|English||
|[News Headlines Dataset for Sarcasm Detection](https://www.kaggle.com/rmisra/news-headlines-dataset-for-sarcasm-detection "High quality dataset with Sarcastic and Non-sarcastic news headlines.")|26,709|JSON|[2018](https://arxiv.org/abs/1908.07414)|English|<a target="_blank" href="https://paperswithcode.com/paper/sarcasm-detection-using-hybrid-neural-network" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Explainability

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[QED](https://github.com/google-research-datasets/QED "Given a question and a passage, QED represents an explanation of the answer as a combination of discrete, human-interpretable steps: sentence selection, referential equality, and predicate entailment. Dataset was built as a subset of the Natural Questions dataset.")|8,993|JSON|[2020](https://arxiv.org/abs/2009.06354)|English|<a target="_blank" href="https://paperswithcode.com/paper/qed-a-framework-and-dataset-for-explanations" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Gender Identification

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[The Arabic Parallel Gender Corpus](https://camel.abudhabi.nyu.edu/arabic-parallel-gender-corpus/ "Dataset is designed to support research on gender bias in natural language processing applications working on Arabic. Requires to submit application for approval.")|~12,000|-|[2019](https://www.aclweb.org/anthology/W19-3822.pdf)|Arabic||

## Grammatical Acceptability

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[The Corpus of Linguistic Acceptability (CoLa)](https://nyu-mll.github.io/CoLA/ "Dataset used to classifiy sentences as grammatical or not grammatical.")|10,657|TSV|[2018](https://arxiv.org/abs/1805.12471)|English|<a target="_blank" href="https://paperswithcode.com/paper/neural-network-acceptability-judgments" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=glue" title="Open in Huggingface" target="_blank">ð¤</a>|

## Graph Analysis

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[ASU Twitter Dataset](http://socialcomputing.asu.edu/datasets/Twitter "Twitter network data, not actual tweets. Shows connections between a large number of users.")|11,316,811 users, 85,331,846 connections|CSV|[2009]()|English||
|[SNAP Social Circles: Twitter Database](https://snap.stanford.edu/data/egonets-Twitter.html "Large Twitter network data.")|Nodes: 81,306, Edges:1,768,149|Text|[2012](http://i.stanford.edu/~julian/pdfs/nips2012.pdf)|English||
|[Microsoft Research Social Media Conversation Corpus](https://www.microsoft.com/en-us/download/details.aspx?id=52375 "A-B-A triples extracted from Twitter.")|4,232|Text|[2016](https://www.microsoft.com/en-us/research/wp-content/uploads/2015/06/N15-1020.pdf)|English||

## Grounded Language Learning

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Talk the Walk](https://github.com/facebookresearch/talkthewalk "Dataset consists of over 10k crowd-sourced dialogues in which two human annotators collaborate to navigate to target locations in the virtual streets of NYC.")|10,000+|JSON, JPG|[2018](https://arxiv.org/abs/1807.03367)|English|<a target="_blank" href="https://paperswithcode.com/paper/talk-the-walk-navigating-new-york-city" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[CompGuessWhat?!](https://compguesswhat.github.io/download/ "Dataset contains 65,700 dialogues based on GuessWhat?! dataset dialogues and enhanced by including object attributes coming from resources such as VISA attributes, VisualGenome and ImSitu.")|65,700|JSON|[2020](https://arxiv.org/abs/2006.02174)|English|<a target="_blank" href="https://paperswithcode.com/paper/compguesswhat-a-multi-task-evaluation" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=compguesswhat" title="Open in Huggingface" target="_blank">ð¤</a>|

## Hate Speech Detection

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[TalkDown](https://github.com/zijwang/talkdown "Dataset used for classifying condescending acts in context. Dataset was extracted from Reddit COMMENT and REPLY pairs in which the REPLY targets a specific quoted span (QUOTED) in the COMMENT as being condescending.")|-|JSON|[2019](https://www.aclweb.org/anthology/D19-1385.pdf)|English||
|[Offensive Language Identification Dataset (OLID)](https://sites.google.com/site/offensevalsharedtask/olid "Dataset contains a collection of 14,200 annotated English tweets using an annotation model that encompasses three levels: offensive language detection, categorization of offensive language, and offensive language target identification.")|14,200|TSV|[2019](https://www.aclweb.org/anthology/N19-1144.pdf)|English||

## Headline Generation

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[NewSHead](https://github.com/tensorflow/models/tree/master/official/nlp/nhnet "Dataset contains 369,940 English stories with 932,571 unique URLs, among which we have 359,940 stories for training, 5,000 for validation, and 5,000 for testing, respectively. Each news story contains at least three (and up to five) articles.")|369,940|JSON|[2020](https://arxiv.org/abs/2001.09386)|English|<a target="_blank" href="https://paperswithcode.com/paper/generating-representative-headlines-for-news" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Idiomatic Expressions

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[English Possible Idiomatic Expressions (EPIE)](https://github.com/prateeksaxena2809/EPIE_Corpus "Dataset containing 25,206 sentences labelled with lexical instances of 717 idiomatic expressions.")|25,506|Text|[2020](https://arxiv.org/abs/2006.09479)|English|<a target="_blank" href="https://paperswithcode.com/paper/epie-dataset-a-corpus-for-possible-idiomatic" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Image Description Generation

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Tumblr GIF (TGIF)](https://github.com/raingo/TGIF-Release "Dataset contains 100K animated GIFs and 120K sentences describing visual content of the animated GIFs.")|100k|TSV|[2016](https://arxiv.org/abs/1604.02748)|English|<a target="_blank" href="https://paperswithcode.com/paper/tgif-a-new-dataset-and-benchmark-on-animated" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Information Extraction

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[JNLPBA](http://www.geniaproject.org/shared-tasks/bionlp-jnlpba-shared-task-2004 "The BioNLP / JNLPBA Shared Task 2004 involves the identification and classification of technical terms referring to concepts of interest to biologists in the domain of molecular biology.Â ")|~2,000|Iob|[2004](https://www.aclweb.org/anthology/W04-1213.pdf)|English||
|[The New York Times Annotated Corpus](https://catalog.ldc.upenn.edu/LDC2008T19 "Dataset contains over 1.8 million articles written and published by the New York Times between January 1, 1987 and June 19, 2007 with article metadata provided by the New York Times Newsroom.")|1.8M|XML|[2008]()|English||
|[BioCreative II Gene Mention Recognition (BC2GM)](https://biocreative.bioinformatics.udel.edu/resources/corpora/biocreative-ii-corpus/ "Dataset contains data where participants are asked to identify a gene mention in a sentence by giving its start and end characters. The training set consists of a set of sentences, and for each sentence a set of gene mentions (GENE annotations). [registration required for access]")|20k|-|[2008](https://link.springer.com/content/pdf/10.1186/gb-2008-9-s2-s2.pdf)|English||
|[T4SS Event Corpus](http://www.geniaproject.org/other-corpora/t4ss-event-corpus "Dataset contains 27 full text publications totaling 15,143 pseudo-sentences (text sentences plus table rows, references, etc.) and 244,942 tokens covering 4 classes: Bacteria, Cellular components, Biological Processes, and Molecular functions.")|27|Text|[2010]()|English||
|[DNA Methylation Corpus](http://www.geniaproject.org/other-corpora/dna-methylation-corpus "Dataset contains 200 abstracts including a representative sample of all PubMed citations relevant to DNA methylation, and introduce manual annotation for nearly 3,000 gene/protein mentions and 1,500 DNA methylation and demethylation events.")|200|Text|[2010](https://jbiomedsem.biomedcentral.com/track/pdf/10.1186/2041-1480-2-S5-S2)|English||
|[PTM Event Corpus](http://www.geniaproject.org/other-corpora/ptm-event-corpus "Dataset contains 157 PubMed abstracts annotated for over 1,000 proteins and 400 post-translational modification events identifying the modified proteins and sites.")|157|Text|[2010](https://www.aclweb.org/anthology/W10-1903.pdf)|English||
|[mTOR Pathway Corpus](http://www.geniaproject.org/other-corpora/mtor-pathway-corpus "Dataset contains 1,300 annotated eventÂ instances of protein associations and dissociation reactions.")|1,300|Text|[2011](https://www.aclweb.org/anthology/W11-0214.pdf)|English||
|[Exhaustive PTM Corpus](http://www.geniaproject.org/other-corpora/exhaustive-ptm-corpus "Dataset contains 360 abstracts manually annotated in the BioNLP Shared Task event representation for over 4,500 mentions of proteins and 1,000 statements of modification events of nearly 40 different types. ")|360|Text|[2011](https://www.aclweb.org/anthology/W11-0215.pdf)|English||
|[Adverse Drug Effect (ADE) Corpus](https://github.com/trunghlt/AdverseDrugReaction/tree/master/ADE-Corpus-V2 "There's 3 different datasets: DRUG-AE.rel provides relations between drugs and adverse effects, DRUG-DOSE.rel provides relations between drugs and dosages and ADE-NEG.txt provides all sentences in the ADE corpus that DO NOT contain any drug-related adverse effects.")|2,972|Text|[2012]()|English||
|[NCBI Disease Corpus](https://www.ncbi.nlm.nih.gov/CBBresearch/Dogan/DISEASE/ "Dataset contains 6,892 disease mentions, which are mapped to 790 unique disease concepts. Of these, 88% link to a MeSH identifier, while the rest contain an OMIM identifier.")|6,892|Text|[2014](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3951655/pdf/nihms557856.pdf)|English||
|[BC5CDR Disease (BC5-Disease)](https://biocreative.bioinformatics.udel.edu/resources/corpora/biocreative-v-cdr-corpus/ "Dataset consists of three separate sets of articles with chemicals and their relations annotated. [registration required for access]")|1,500|-|[2015](https://biocreative.bioinformatics.udel.edu/media/store/files/2015/BC5CDRcorpus.pdf)|English||
|[BC5CDR Drug/Chemical (BC5-Chem)](https://biocreative.bioinformatics.udel.edu/resources/corpora/biocreative-v-cdr-corpus/ "Dataset consists of three separate sets of articles with chemicals and their relations annotated. [registration required for access]")|1,500|-|[2016](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4860626/pdf/baw068.pdf)|English||
|[An Open Information Extraction Corpus (OPIEC)](https://www.uni-mannheim.de/en/dws/research/resources/opiec/ "OPIEC is an Open Information Extraction (OIE) corpus, constructed from the entire English Wikipedia containing more than 341M triples.")|341M|AVRO|[2019](https://arxiv.org/abs/1904.12324)|English|<a target="_blank" href="https://paperswithcode.com/paper/opiec-an-open-information-extraction-corpus" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Evidence Inference](https://github.com/jayded/evidence-inference "Dataset contains 10,137 annotated prompts for 2,419 unique article with the task of inferring whether a given clinical treatment is effective with respect to a specified outcome. The dataset provides a prompt that specifies an intervention, a comparator, and an outcome, along with a fulltext article. The model is then used to infer the reported findings with respect to this prompt.")|10,137|Text, PubMed nxml|[2019](https://www.aclweb.org/anthology/N19-1371.pdf)|English||
|[Deft](https://github.com/adobe-research/deft_corpus "Dataset contains annotated content from two different data sources: 1) 2,443 sentences from various 2017 SEC contract filings from the publicly available US Securities and Exchange Commission EDGAR (SEC) database, and 2) 21,303 sentences from open source textbooks including topics in biology, history, physics, psychology, economics, sociology, and government. ")|23,746|Text|[2019](https://www.aclweb.org/anthology/W19-4015.pdf)|English||
|[Personal Events in Dialogue Corpus](http://www.artie.com/data/personaleventsindialogue/ "Dataset is a corpus containing annotated dialogue transcripts from fourteen episodes of the podcast This American Life. It contains 1,038 utterances, made up of 16,962 tokens, of which 3,664 represent events.")|1,038|Text|[2020](http://ml-corpora.artie.com/personal-events-in-dialogue-corpus/Eisenberg_NUSE_Personal_Event_Extraction_Paper.pdf)|English||
|[SciREX](https://github.com/allenai/SciREX "Dataset is fully annotated with entities, their mentions, their coreferences, and their document level relations.")|438|JSON|[2020](https://arxiv.org/abs/2005.00512)|English|<a target="_blank" href="https://paperswithcode.com/paper/scirex-a-challenge-dataset-for-document-level" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Quda](https://freenli.github.io/quda/ "Dataset contains 14,035 diverse user queries annotated with 10 low-level analytic tasks that assist in the deployment of state-of-the-art machine/deep learning techniques for parsing complex human language.")|14,035|Text|[2020](https://arxiv.org/abs/2005.03257)|English|<a target="_blank" href="https://paperswithcode.com/paper/quda-natural-language-queries-for-visual-data" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[PerKey](https://github.com/edoost/perkey "Dataset contains 553K news articles from six Persian news websites and agencies with author extracted keyphrases, which is then filtered and cleaned to achieve higher quality keyphrases.")|553,111|JSON|[2020](https://arxiv.org/abs/2009.12269)|Persian|<a target="_blank" href="https://paperswithcode.com/paper/perkey-a-persian-news-corpus-for-keyphrase" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Abstract Meaning Respresentation (AMR) Bank](https://catalog.ldc.upenn.edu/LDC2020T02 "Dataset contains a sembank (semantic treebank) of over 59,255 English natural language sentences from broadcast conversations, newswire, weblogs, web discussion forums, fiction and web text.")|59,255|Text|[2020](https://www.aclweb.org/anthology/C18-1313.pdf)|English||

## Information Retrieval

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Automatic Keyphrase Extraction](https://github.com/snkim/AutomaticKeyphraseExtraction "Multiple datasets for automatic keyphrase extraction.")|-|Multiple|[1999-2008](https://www.aclweb.org/anthology/P14-1119.pdf)|English||
|[OpinRank Review Dataset](http://archive.ics.uci.edu/ml/machine-learning-databases/00205/ "Reviews of cars and hotels from Edmunds.com and TripAdvisor.")|Edmunds: 42,230, TripAdivsor: 259,000|Text|[2011](http://kavita-ganesan.com/opinion-based-entity-ranking/#.Xme-5KhKiUk)|English||
|[OntoNotes 5.0](https://catalog.ldc.upenn.edu/LDC2013T19 "Dataset contains various genres of text (news, conversational telephone speech, weblogs, usenet newsgroups, broadcast, talk shows) in three languages (English, Chinese, and Arabic) with structural information (syntax and predicate argument structure) and shallow semantics (word sense linked to an ontology and coreference).")|-|Text, SQL|[2013](https://catalog.ldc.upenn.edu/docs/LDC2013T19/OntoNotes-Release-5.0.pdf)|Multi-Lingual||
|[ReVerb45k, Base and Ambiguous](https://github.com/malllabiisc/cesi "3 Datasets. In total, there are 91K triples.")|91k|JSON|[2018](https://malllabiisc.github.io/publications/papers/cesi_www18.pdf)|English||
|[Trec CAR Dataset](http://trec-car.cs.unh.edu/datareleases/index.html "Dataset contains topics, outlines, and paragraphs that are extracted from English Wikipedia (2016 XML dump). Wikipedia articles are split into the outline of sections and the contained paragraphs.")|~285,000|CBOR|[2019](http://trec-car.cs.unh.edu/)|English||

## Intent Detection

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Dataset for Intent Classification and Out-of-Scope Prediction](https://github.com/clinc/oos-eval/tree/master/data "Dataset is a benchmark for evaluating intent classification systems for dialog systems / chatbots in the presence of out-of-scope queries.")|23,000+|JSON|[2019](https://arxiv.org/abs/1909.02027)|English|<a target="_blank" href="https://paperswithcode.com/paper/an-evaluation-dataset-for-intent" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[HINT3](https://github.com/hellohaptik/HINT3 "In total there are three datasets: SOFMattress, Curekart and Powerplay11 with each containing diverse set of intents in a single domain - mattress products retail, fitness supplements retail and online gaming respectively. Each datasets spans multiple coarse and fine grain intents, with the test sets being drawn entirely from actual user queries on live systems at scale instead of being crowdsourced.")|-|CSV|[2020](https://arxiv.org/abs/2009.13833)|English|<a target="_blank" href="https://paperswithcode.com/paper/hint3-raising-the-bar-for-intent-detection-in" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Keyphrase Extraction

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[PerKey](https://github.com/edoost/perkey "Dataset contains 553K news articles from six Persian news websites and agencies with author extracted keyphrases, which is then filtered and cleaned to achieve higher quality keyphrases.")|553,111|JSON|[2020](https://arxiv.org/abs/2009.12269)|Persian|<a target="_blank" href="https://paperswithcode.com/paper/perkey-a-persian-news-corpus-for-keyphrase" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Knowledge Base

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[WordNet](https://wordnet.princeton.edu/ "Dataset is a large lexical database of English. Nouns, verbs, adjectives and adverbs are grouped into sets of cognitive synonyms (synsets), each expressing a distinct concept. Synsets are interlinked by means of conceptual-semantic and lexical relations.")|-|-|[2006](https://dl.acm.org/doi/pdf/10.1145/219717.219748)|English||
|[WebQuestions](https://worksheets.codalab.org/worksheets/0xba659fe363cb46e7a505c5b6a774dc8a "Dataset contains 6,642 question/answer pairs. The questions are supposed to be answerable byÂ Freebase, a large knowledge graph. The questions are mostly centered around a single named entity.")|6,642|JSON|[2013](https://cs.stanford.edu/~pliang/papers/freebase-emnlp2013.pdf)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=web_questions" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Dbpedia](https://wiki.dbpedia.org/develop/datasets "The English version of the DBpedia knowledge base currently describes 6.6M entities of which 4.9M have abstracts, 1.9M have geo coordinates and 1.7M depictions. In total, 5.5M resources are classified in a consistent ontology.")|6.6M|Multiple|[2016](http://svn.aksw.org/papers/2013/SWJ_DBpedia/public.pdf)|Multi-Lingual||
|[WikiReading](https://github.com/google-research-datasets/wiki-reading "The task is to predict textual values from the structured knowledge base Wikidata by reading the text of the corresponding Wikipedia articles. Includes English, Russian and Turkish.")|18M|JSON|[2016](https://arxiv.org/abs/1608.03542)|Multi-Lingual|<a target="_blank" href="https://paperswithcode.com/paper/wikireading-a-novel-large-scale-language" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Visual Genome](https://visualgenome.org/api/v0/api_home.html "Dataset contains over 100K images where each image has an average of 21 objects, 18 attributes, and 18 pairwise relationships between objects.")|100,000+|JSON|[2016](https://visualgenome.org/static/paper/Visual_Genome.pdf)|English||
|[Aristo Tuple KB](http://data.allenai.org/tuple-kb/ "Dataset contains a collection of high-precision, domain-targeted (subject,relation,object) tuples extracted from text using a high-precision extraction pipeline, and guided by domain vocabulary constraints.")|282,594|TSV|[2017](http://ai2-website.s3.amazonaws.com/publications/comprehensive_knowledge_extraction-final.pdf)|English||
|[TupleInf Open IE Dataset](http://data.allenai.org/tuple-ie/ "Dataset contains Open IE tuples extracted from 263K sentences that were used by the solver in "Answering Complex Questions Using Open Information Extraction" (referred as Tuple KB, T).")|263k|Text|[2017](https://arxiv.org/abs/1704.05572)|English|<a target="_blank" href="https://paperswithcode.com/paper/answering-complex-questions-using-open" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Wikidata NE dataset](https://event.ifi.uni-heidelberg.de/?page_id=532 "Dataset has 2 parts: the Named Entity files and the link files. The Named Entity files include the most important information about the entities, whereas the link files contain the links and ids in other databases.")|-|JSON|[2017](https://www.researchgate.net/publication/322281320_NECKAr_A_Named_Entity_Classifier_for_Wikidata)|German, English||
|[MoviE Text Audio QA (MetaQA)](https://github.com/yuyuz/MetaQA "Dataset contains more than 400K questions for both single and multi-hop reasoning, and provides more realistic text and audio versions. MetaQA serves as a comprehensive extension of WikiMovies.")|400,000+|Text, MP3|[2018](https://arxiv.org/abs/1709.04071)|English|<a target="_blank" href="https://paperswithcode.com/paper/variational-reasoning-for-question-answering" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Complex Sequential Question Answering (CSQA)](https://github.com/amritasaha1812/CSQA_Code "Dataset contains around 200K dialogs with a total of 1.6M turns. Further, unlike existing large scale QA datasets which contain simple questions that can be answered from a single tuple, the questions in the dialogs require a larger subgraph of the KG.")|200k|-|[2018](https://arxiv.org/abs/1801.10314)|English|<a target="_blank" href="https://paperswithcode.com/paper/complex-sequential-question-answering-towards" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[ReVerb45k, Base and Ambiguous](https://github.com/malllabiisc/cesi "3 Datasets. In total, there are 91K triples.")|91k|JSON|[2018](https://malllabiisc.github.io/publications/papers/cesi_www18.pdf)|English||
|[An Open Information Extraction Corpus (OPIEC)](https://www.uni-mannheim.de/en/dws/research/resources/opiec/ "OPIEC is an Open Information Extraction (OIE) corpus, constructed from the entire English Wikipedia containing more than 341M triples.")|341M|AVRO|[2019](https://arxiv.org/abs/1904.12324)|English|<a target="_blank" href="https://paperswithcode.com/paper/opiec-an-open-information-extraction-corpus" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[EventQA](https://github.com/tarcisiosouza/Event-QA "A dataset for answering Event-Centric questions over Knowledge Graphs (KGs). It contains 1,000 semantic queries and the corresponding verbalisations.")|1k|JSON|[2019](https://arxiv.org/abs/2004.11861)|English|<a target="_blank" href="https://paperswithcode.com/paper/event-qa-a-dataset-for-event-centric-question" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[KnowledgeNet](https://github.com/diffbot/knowledge-net "KnowledgeNet is a benchmark dataset for the task of automatically populating a knowledge base (Wikidata) with facts expressed in natural language text on the web.")|9k|JSON|[2019](https://pdfs.semanticscholar.org/d799/cd1a35278a4a8d863092f3f3a7914b719ec6.pdf?_ga=2.101541378.2044998952.1601476249-1179939496.1599584294)|English||
|[Kensho Derived Wikimedia Dataset (KDWD)](https://www.kaggle.com/kenshoresearch/kensho-derived-wikimedia-data "Dataset containsÂ two main components - a link annotated corpus of English Wikipedia pages and a compact sample of the Wikidata knowledge base.")|-|CSV, JSON|[2020]()|English||
|[Worldtree Corpus](http://cognitiveai.org/explanationbank/ "Dataset contains multi-hop question answering/explanations where questions require combining between 1 and 16 facts (average 6) to generate detailed explanations for question answering inference. Each explanation is represented as a lexically-connected âexplanation graphâ that combines an average of 6 facts drawn from a semi-structured knowledge base of 9,216 facts across 66 tables.")|5,114|Text, TSV|[2020](http://cognitiveai.org/wp-content/uploads/2020/05/xie_et_al_lrec2020_worldtree_v2_structured_explanations_and_inference_patterns_multihop_inference.pdf)|English||
|[The Semantic Scholar Open Research Corpus (S2ORC)](https://github.com/allenai/s2orc/ "Dataset contains 136M+ paper nodes with 12.7M+ full text papers and connected by 467M+ citation edges.")|467M edges, 136M nodes|JSON|[2020](https://arxiv.org/abs/1911.02782)|English|<a target="_blank" href="https://paperswithcode.com/paper/gorc-a-large-contextual-citation-graph-of" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[HybridQA](https://github.com/wenhuchen/HybridQA "Dataset contains over 70K question-answer pairs based on 13,000 tables, each table is in average linked to 44 passages.")|70k|JSON|[2020](https://arxiv.org/abs/2004.07347)|English|<a target="_blank" href="https://paperswithcode.com/paper/hybridqa-a-dataset-of-multi-hop-question" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[RuBQ](https://github.com/vladislavneon/RuBQ "Dataset consists of 1,500 Russian questions of varying complexity, their English machine translations, SPARQL queries to Wikidata, reference answers, as well as a Wikidata sample of triples containing entities with Russian labels.")|1,500|JSON|[2020](https://arxiv.org/abs/2005.10659)|Russian|<a target="_blank" href="https://paperswithcode.com/paper/rubq-a-russian-dataset-for-question-answering" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Compositional Freebase Questions (CFQ)](https://github.com/google-research/google-research/tree/master/cfq "Dataset contains questions and answers that also provides for each question a corresponding SPARQL query against the Freebase knowledge base.")|239,357|JSON|[2020](https://openreview.net/pdf?id=SygcCnNKwr)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=cfq" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Olpbench](https://www.uni-mannheim.de/dws/research/resources/olpbench/ "Dataset contains 30M open triples, 1M distinct open relations and 2.5M distinct mentions of approximately 800K entities. Dataset is used for open link prediction task.")|30M|Text|[2020](https://www.aclweb.org/anthology/2020.acl-main.209.pdf)|English||

## Knowledge Graph

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[LC-QuAD 2.0](http://lc-quad.sda.tech/ "Dataset contains questions and SPARQL queries. LC-QuAD usesÂ DBpedia v04.16Â as the target KB.")|30k|JSON|[2017](http://jens-lehmann.org/files/2019/iswc_lcquad2.pdf)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=lc_quad" title="Open in Huggingface" target="_blank">ð¤</a>|
|[ConceptNet](https://github.com/commonsense/conceptnet5 "A knowledge graph that connects words and phrases of natural language (terms) with labeled, weighted edges (assertions).")|21M+ edges and 8M+ nodes|JSON|[2017](https://arxiv.org/abs/1612.03975)|Multi-Lingual|<a target="_blank" href="https://paperswithcode.com/paper/conceptnet-55-an-open-multilingual-graph-of" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Atlas of Machine Commonsense (ATOMIC)](https://homes.cs.washington.edu/~msap/atomic/ "Dataset is a knowledge graph of 877K textual description triples of inferential knowledge.")|877k|CSV|[2018](https://homes.cs.washington.edu/~msap/atomic/data/sap2019atomic.pdf)|English||
|[Soccer Dialogues](https://github.com/SmartDataAnalytics/KG-Copy_Network/tree/master/soccer_conversations "Dataset contains soccer dialogues over a knowledge graph")|2,890|JSON|[2019]()|English||
|[Linked WikiText-2](https://rloganiv.github.io/linked-wikitext-2/#/ "Dataset contains over 2 million tokens from Wikipedia articles, along with annotations linking mentions to their corresponding entities and relations in Wikidata.")|2M|JSON|[2019](https://rloganiv.github.io/assets/projects/kglm.pdf)|English||
|[FreebaseQA](https://github.com/kelvin-jiang/FreebaseQA "Dataset contains 28,348 unique questions for open domain QA over the Freebase knowledge graph.")|28,348|JSON|[2019](https://www.aclweb.org/anthology/N19-1028.pdf)|English||
|[OpenDialKG](https://github.com/facebookresearch/opendialkg "Dataset of conversations between two crowdsourcing agents engaging in a dialog about a given topic. Each dialog turn is paired with its corresponding âKG pathsâ that weave together the KG entities and relations that are mentioned in the dialog.")|15k|Text|[2019](https://www.aclweb.org/anthology/P19-1081.pdf)|English||
|[KdConv](https://github.com/thu-coai/KdConv "Dataset is a Chinese multi-domain dataset, grounding the topics in multi-turn conversations to knowledge graphs. KdConv contains 4.5K conversations from three domains (film, music, and travel), and 86K utterances with an average turn number of 19.0. ")|4,500|JSON|[2020](https://arxiv.org/abs/2004.04100)|Chinese|<a target="_blank" href="https://paperswithcode.com/paper/kdconv-a-chinese-multi-domain-dialogue" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Language Detection

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[The Irish Times IRS](https://www.kaggle.com/therohk/ireland-historical-news "Dataset contains 23 years of events from Ireland.")|1,425,460|CSV|[2018]()|English||
|[News Headlines Dataset for Sarcasm Detection](https://www.kaggle.com/rmisra/news-headlines-dataset-for-sarcasm-detection "High quality dataset with Sarcastic and Non-sarcastic news headlines.")|26,709|JSON|[2018](https://arxiv.org/abs/1908.07414)|English|<a target="_blank" href="https://paperswithcode.com/paper/sarcasm-detection-using-hybrid-neural-network" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Language Model Evaluation

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[StereoSet](https://github.com/moinnadeem/stereoset "Dataset that measures stereotype bias in language models.Â StereoSetÂ consists of 17,000 sentences that measures model preferences across gender, race, religion, and profession.")|17k|JSON|[2020](https://arxiv.org/abs/2004.09456)|English|<a target="_blank" href="https://paperswithcode.com/paper/stereoset-measuring-stereotypical-bias-in" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Language Modeling

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[1 Billion Word Language Model Benchmark (lm1b)](https://github.com/ciprian-chelba/1-billion-word-language-modeling-benchmark "Dataset used for measuring progress in statistical language modeling.")|1.1B|-|[2013](https://www.isca-speech.org/archive/archive_papers/interspeech_2014/i14_2635.pdf)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=lm1b" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Language Modeling Broadened to Account for Discourse Aspects (LAMBADA)](https://zenodo.org/record/2630551 "Dataset contains narrative passages sharing the characteristic that human subjects are able to guess their last word if they are exposed to the whole passage, but not if they only see the last sentence preceding the target word.")|10,022|Text|[2016](https://arxiv.org/abs/1606.06031)|English|<a target="_blank" href="https://paperswithcode.com/paper/the-lambada-dataset-word-prediction-requiring" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[WikiText-103 & 2](https://blog.einstein.ai/the-wikitext-long-term-dependency-language-modeling-dataset/ "Dataset contains word and character level tokens extracted from Wikipedia")|100M+|TOKENS|[2016](https://arxiv.org/abs/1609.07843)|English|<a target="_blank" href="https://paperswithcode.com/paper/pointer-sentinel-mixture-models" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=wikitext" title="Open in Huggingface" target="_blank">ð¤</a>|
|[WikiText-TL-39](https://github.com/jcblaisecruz02/Filipino-Text-Benchmarks "Dataset is a large scale, unlabeled text dataset with 39M tokens in the training set.")|-|Text|[2019](https://arxiv.org/abs/1907.00409)|Filipino|<a target="_blank" href="https://paperswithcode.com/paper/evaluating-language-model-finetuning" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[PG-19](https://github.com/deepmind/pg19 "Dataset contains a set of books extracted rom the Project Gutenberg books library, that were published before 1919. It also contains metadata of book titles and publication dates.")|28,752|Text|[2019](https://arxiv.org/abs/1911.05507)|English|<a target="_blank" href="https://paperswithcode.com/paper/compressive-transformers-for-long-range-1" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=pg19" title="Open in Huggingface" target="_blank">ð¤</a>|
|[The Benchmark of Linguistic Minimal Pairs (BLiMP)](https://github.com/alexwarstadt/blimp "BLiMP is a challenge set for evaluating what language models (LMs) know about major grammatical phenomena in English.")|67 sub-datasets each with 1,000 minimal pairs|JSON|[2019](https://arxiv.org/abs/1912.00582)|English|<a target="_blank" href="https://paperswithcode.com/paper/blimp-a-benchmark-of-linguistic-minimal-pairs" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=blimp" title="Open in Huggingface" target="_blank">ð¤</a>|

## Lexical Inference/Entailment

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[SherLIiC](https://github.com/mnschmit/SherLIiC "Dataset contains manually annotated inference rule candidates (InfCands), accompanied by ~960k unlabeled InfCands, and  ~190k typed textual relations between Freebase entities extracted from the large entity-linked corpus ClueWeb09.")|~960,000|Text|[2019](https://arxiv.org/abs/1906.01393)|English|<a target="_blank" href="https://paperswithcode.com/paper/sherliic-a-typed-event-focused-lexical" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Link Prediction

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[CoDExÂ ](https://github.com/tsafavi/codex "Three graph datasets containing positive and hard negative triples, entity types, entity and relation descriptions, and Wikipedia page extracts for entities.")|1,156,222|JSON|[2020](https://arxiv.org/abs/2009.07810)|English|<a target="_blank" href="https://paperswithcode.com/paper/codex-a-comprehensive-knowledge-graph" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Machine Translation

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[European Parliament Proceedings (Europarl)](http://statmt.org/europarl/ "The Europarl parallel corpus is extracted from the proceedings of theÂ European Parliament. It includes versions in 21 European languages.")|10M+|XML|[2002](http://www.lrec-conf.org/proceedings/lrec2012/pdf/463_Paper.pdf)|Multi-Lingual||
|[Tanzil](http://opus.nlpl.eu/Tanzil.php "Dataset is a collection of Quran translations in 42 languages.")|1.01M|XML|[2012]()|Multi-Lingual||
|[CAPES](http://opus.nlpl.eu/CAPES.php "A parallel corpus of theses and dissertation abstracts in Portuguese and English from CAPES.")|2.32M|XML|[2012](http://www.lrec-conf.org/proceedings/lrec2012/pdf/463_Paper.pdf)|Portuguese, English||
|[DOGC](http://opus.nlpl.eu/DOGC.php "A collection of documents from the official journal of the Catalan Goverment in Catalan and Spanish.")|21.87M|XML|[2012](http://www.lrec-conf.org/proceedings/lrec2012/pdf/463_Paper.pdf)|Catalan, Spanish||
|[ECB Corpus](http://opus.nlpl.eu/ECB.php "Website and documentation from the European Central Bank. Contains 19 languages.")|30.55M|XML|[2012](http://www.lrec-conf.org/proceedings/lrec2012/pdf/463_Paper.pdf)|Multi-Lingual||
|[EMEA](http://opus.nlpl.eu/EMEA.php "A parallel corpus made out of PDF documents from the European Medicines Agency. Contains 22 languages.")|26.51M|XML|[2012](http://www.lrec-conf.org/proceedings/lrec2012/pdf/463_Paper.pdf)|Multi-Lingual||
|[Eubookshop](http://opus.nlpl.eu/EUbookshop.php "Corpus of documents from the EU bookshop. Contains 48 languages.")|173.20M|XML|[2012](http://www.lrec-conf.org/proceedings/lrec2012/pdf/463_Paper.pdf)|Multi-Lingual||
|[Finlex](http://opus.nlpl.eu/Finlex.php "Dataset is a collection of legislative and other judicial information of Finland, which is available in Finnish and Swedish.")|7.98M|XML|[2012](http://www.lrec-conf.org/proceedings/lrec2012/pdf/463_Paper.pdf)|Finnish, Swedish||
|[FiskmÃ¶](https://version.helsinki.fi/Helsinki-NLP/fiskmo "Dataset is a parallel corpus of Finnish and Swedish Languages.")|4.24M|XML|[2012](http://www.lrec-conf.org/proceedings/lrec2012/pdf/463_Paper.pdf)|Finnish, Swedish||
|[Books Corpus](http://opus.nlpl.eu/Books.php "Dataset contains a collection of copyright free books. Corpus consists of 16 languages and 0.91M sentence fragments and 19.50M tokens.")|0.91M|XCES, XML|[2012](http://www.lrec-conf.org/proceedings/lrec2012/pdf/463_Paper.pdf)|Multi-Lingual||
|[WebÂ Inventory ofÂ Transcribed andÂ TranslatedÂ Talks (WIT3)](https://wit3.fbk.eu/mono.php?release=XML_releases&tinfo=cleanedhtml_ted "Dataset contains a collection of transcribed and translated talks. The core of the dataset is from Ted Talks corpus. As of 2016, It holds 109 languages.")|-|XML|[2012](https://pdfs.semanticscholar.org/c64d/27b122d5b6ef0be135e63df05c3b24bd80c5.pdf?_ga=2.127716493.1668670113.1583626265-958501894.1582324561)|Multi-Lingual||
|[Bible Corpus](http://opus.nlpl.eu/bible-uedin.php "A parallel corpus created from translations of the Bible containing 102 languages.")|2.84M|XML|[2014](https://www.researchgate.net/publication/269334313_A_massively_parallel_corpus_the_Bible_in_100_languages)|Multi-Lingual||
|[Global Voices Parallel Corpus](http://casmacat.eu/corpus/global-voices.html "Dataset contains news articles from the web siteÂ Global Voices in multiple languages.")|-|Text|[2015](http://www.lrec-conf.org/proceedings/lrec2012/pdf/463_Paper.pdf)|Multi-Lingual||
|[IWSLT 15 English-Vietnamese](https://nlp.stanford.edu/projects/nmt/ "Sentence pairs for translation.")|133k|Text|[2015](https://nlp.stanford.edu/pubs/luong-manning-iwslt15.pdf)|Multi-Lingual||
|[WMT 14 English-German](https://nlp.stanford.edu/projects/nmt/ "Sentence pairs for translation.")|4.5M|Text|[2015](https://nlp.stanford.edu/pubs/luong-manning-iwslt15.pdf)|Multi-Lingual|<a href="https://huggingface.co/nlp/viewer/?dataset=wmt14" title="Open in Huggingface" target="_blank">ð¤</a>|
|[IWSLT'15 English-VietnameseÂ ](https://nlp.stanford.edu/projects/nmt/ "Parallel corpus used for machine translation English-Vietnamese.")|~130,000|Text|[2015](https://workshop2015.iwslt.org/downloads/IWSLT_2015_EP_3.pdf)|Multi-Lingual||
|[News Commentary Parallel Corpus](http://www.casmacat.eu/corpus/news-commentary.html "Dataset consists of parallel corpora consisting of political and economic commentary crawled from the web site Project Syndicate.")|-|Text|[2016]()|Multi-Lingual||
|[Multi30k](https://github.com/multi30k/dataset "Dataset of images paired with sentences in English and German. This dataset extends the Flickr30K dataset.")|31,014|-|[2016](https://arxiv.org/abs/1605.00459)|German, English|<a target="_blank" href="https://paperswithcode.com/paper/multi30k-multilingual-english-german-image" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[WMT 15 English-Czech](https://nlp.stanford.edu/projects/nmt/ "Sentence pairs for translation.")|15.8M|Text|[2016](https://nlp.stanford.edu/pubs/luong2016acl_hybrid.pdf)|Multi-Lingual|<a href="https://huggingface.co/nlp/viewer/?dataset=wmt15" title="Open in Huggingface" target="_blank">ð¤</a>|
|[United Nations Parallel Corpus](https://conferences.unite.un.org/UNCORPUS/ "Parallel corpus presented consists of manually translated UN documents from the last 25 years (1990 to 2014) for the six official UN languages: Arabic, Chinese, English, French, Russian, and Spanish.")|799,276|TEI, XML|[2016](https://www.aclweb.org/anthology/L16-1561.pdf)|Multi-Lingual||
|[Worldwide News - Aggregate of 20KÂ Feeds](https://www.kaggle.com/therohk/global-news-week "One week snapshot of all online headlines in 20+ languages.")|1,398,431|CSV|[2017](https://pdfs.semanticscholar.org/48cd/042d645e60b125fd5b90f734900dae4211d8.pdf)|Multi-Lingual||
|[Microsoft Speech Language Translation Corpus (MSLT)](https://www.microsoft.com/en-us/download/details.aspx?id=55951 "Dataset contains conversational, bilingual speech test and tuning data for English, Chinese, and Japanese. It includes audio data, transcripts, and translations; and allows end-to-end testing of spoken language translation systems on real-world data.")|-|Wav|[2017](https://workshop2016.iwslt.org/downloads/IWSLT_2016_paper_12.pdf)|Multi-Lingual||
|[Yoruba Text](https://github.com/Niger-Volta-LTI/yoruba-text "Multiple datasets scraped together for the Yoruba language.")|-|Text|[2018]()|Yoruba||
|[ParaCrawl Corpus](https://www.paracrawl.eu/index.php "Multiple parallel datasets of European languages for machine translation.")|-|Text|[2018]()|Multi-Lingual|<a href="https://huggingface.co/nlp/viewer/?dataset=para_crawl" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Bianet](https://d-ataman.github.io/bianet/ "Dataset is a parallel news corpus with 3,214 Turkish articles with their sentence-aligned Kurdish or English translations from the Bianet online newspaper. Requires a request submission for dataset.")|3,214|XML|[2018](http://lrec-conf.org/workshops/lrec2018/W19/pdf/6_W19.pdf)|Multi-Lingual||
|[IIT Bombay English-Hindi Corpus](http://www.cfilt.iitb.ac.in/iitb_parallel/ "Dataset contains parallel corpus for English-Hindi as well as monolingual Hindi corpus collected from a variety of existing sources.")|1.49M|-|[2018](https://arxiv.org/abs/1710.02855)|Hindi, English|<a target="_blank" href="https://paperswithcode.com/paper/the-iit-bombay-english-hindi-parallel-corpus" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[ParCorFull](https://lindat.mff.cuni.cz/repository/xmlui/handle/11372/LRT-2614 "A parallel corpus annotated for the task of translation of corefrence across languages.")|14,927|XML|[2018](https://www.aclweb.org/anthology/L18-1065.pdf)|German, English||
|[Indic Languages Multilingual Parallel Corpus](http://lotus.kuee.kyoto-u.ac.jp/WAT/indic-multilingual/index.html "Dataset contains several languages: Bengali, Hindi, Malayalam, Tamil, Telugu, Sinhalese, Urdu and English. The corpus has been collected fromÂ OPUSÂ and belongs to the spoken language (OpenSubtitles) domain.")|-|Tar|[2018](https://www.aclweb.org/anthology/Y18-3003.pdf)|Indian||
|[WMT 19 Multiple Datasets](http://www.statmt.org/wmt19/translation-task.html "Multiple text corpora in multiple languages.")|-|Text|[2019]()|Multi-Lingual|<a href="https://huggingface.co/nlp/viewer/?dataset=wmt19" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Igbo Text](https://github.com/Niger-Volta-LTI/igbo-text "Dataset is a parallel dataset for the Urhobo language.")|10.3M|Text, XML|[2019]()|Igbo, English||
|[Urhobo Text](https://github.com/Niger-Volta-LTI/urhobo-text/tree/master/JW300 "Dataset is a parallel dataset containing 10.3M tokens.")|-|Text, XML|[2019]()|Urhobo, English||
|[DiaBLa](https://github.com/rbawden/DiaBLa-dataset "Parallel dataset of spontaneous, written, bilingual dialogues for the evaluation of Machine Translation, annotated for human judgments of translation quality.")|5,700+|JSON|[2019](https://arxiv.org/abs/1905.13354)|French, English|<a target="_blank" href="https://paperswithcode.com/paper/diabla-a-corpus-of-bilingual-spontaneous" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[WikiMatrix](https://github.com/facebookresearch/LASER/tree/master/tasks/WikiMatrix "Dataset contains 135 million parallel sentences for 1,620 different language pairs in 85 different languages.")|135M|TSV|[2019](https://arxiv.org/abs/1907.05791)|Multi-Lingual|<a target="_blank" href="https://paperswithcode.com/paper/wikimatrix-mining-135m-parallel-sentences-in" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[LibriVoxDeEn](https://heidata.uni-heidelberg.de/dataset.xhtml?persistentId=doi:10.11588/data/TMEDTX "Dataset contains sentence-aligned triples of German audio, German text, and English translation, based on German audio books. The corpus consists of over 100 hours of audio material and over 50k parallel sentences.")|50,000+|Text, TSV|[2019](https://arxiv.org/abs/1910.07924)|German, English|<a target="_blank" href="https://paperswithcode.com/paper/librivoxdeen-a-corpus-for-german-to-english" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[CCMatrix](https://github.com/facebookresearch/LASER/tree/master/tasks/CCMatrix "4.5 billion parallel sentences in 576 language pairs pulled from snapshots of the CommonCrawl public dataset.")|4.5B|to be added soon|[2019](https://arxiv.org/abs/1911.04944)|Multi-Lingual|<a target="_blank" href="https://paperswithcode.com/paper/ccmatrix-mining-billions-of-high-quality" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[WAT 2019 Hindi-English](https://ufal.mff.cuni.cz/hindi-visual-genome/wat-2019-multimodal-task "Dataset consists of multimodal English-to-Hindi translation. It inputs an image, rectangular region in the image and english caption. It outputs a caption in Hindi.")|32,925|Text, JPEG|[2019](https://www.aclweb.org/anthology/D19-5224.pdf)|Hindi, English||
|[JW300](http://opus.nlpl.eu/JW300.php "Dataset is parallel corpus of over 300 languages with around 100 thousand parallel sentences per language pair on average.")|105.11M|XML|[2019](https://www.aclweb.org/anthology/P19-1310.pdf)|Multi-Lingual||
|[Tatoeba](https://tatoeba.org/eng "Dataset is a collection of sentences and translations.")|8.5M|CSV|[2020]()|Multi-Lingual||
|[NEJM-enzh](https://github.com/boxiangliu/med_translation "Dataset is an English-Chinese parallel corpus, consisting of about 100,000 sentence pairs and 3,000,000 tokens on each side, from the New England Journal of Medicine (NEJM).")|100k|-|[2020](https://arxiv.org/abs/2005.09133)|Chinese, English|<a target="_blank" href="https://paperswithcode.com/paper/nejm-enzh-a-parallel-corpus-for-english" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[CoVoST](https://github.com/facebookresearch/covost "Dataset is a multilingual speech-to-text translation corpus covering translations from 21 languages into English and from English into 15 languages. The overall speech duration is 2,880 hours. The total number of speakers is 78K.")|2,880 Hours|TSV, MP3|[2020](https://arxiv.org/abs/2007.10310)|Multi-Lingual|<a target="_blank" href="https://paperswithcode.com/paper/covost-2-a-massively-multilingual-speech-to" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Business Scene Dialogue (BSD)](https://github.com/tsuruoka-lab/BSD "Dataset contains 955 scenarios, 30,000 parallel sentences in English-Japanese.")|30k|JSON|[2020](https://arxiv.org/abs/2008.01940)|Japanese, English|<a target="_blank" href="https://paperswithcode.com/paper/designing-the-business-conversation-corpus-1" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Mathematical Reasoning

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Math Dataset](https://github.com/deepmind/mathematics_dataset "Dataset contains mathematical question and answer pairs, from a range of question types at roughly school-level difficulty.")|-|Text|[2019](https://openreview.net/pdf?id=H1gR5iR5FX)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=math_dataset" title="Open in Huggingface" target="_blank">ð¤</a>|

## Missing Elements

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Numeric Fused-Heads](https://github.com/yanaiela/num_fh/tree/master/data/resolution/processed "Dataset contains annotated sentences of numeric-fused-heads, along with their "missing head". A number refers to an implicit (and not explicitly provided) reference. For example, in the sentence "I miss being 10", the number 10 refers to the age of 10, but is not explicitly said.")|9,412|JSON|[2019](https://www.mitpressjournals.org/doi/pdf/10.1162/tacl_a_00280)|English||

## Multi-Modal

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Crema-D](https://github.com/CheyneyComputerScience/CREMA-D "Dataset consists of facial and vocal emotional expressions in sentences spoken in a range of basic emotional states (happy, sad, anger, fear, disgust, and neutral). 7,442 clips of 91 actors with diverse ethnic backgrounds were collected.")|7,438|Wav, MP3, Flash|[2014](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4313618/)|English||
|[ManyModalQA](https://github.com/hannandarryl/ManyModalQA "Dataset contains 10,190 questions, 2,873 images, 3,789 text, and 3,528 tables scraped from Wikipedia.")|10,190|JSON, PNG|[2020](https://aaai.org/Papers/AAAI/2020GB/AAAI-HannanD.8768.pdf)|English||

## Multi-Modal Hate Speech Detection

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Hateful Memes](https://github.com/facebookresearch/mmf/tree/master/projects/hateful_memes?fbclid=IwAR2DDOWqQa23etVlEd7vpXMZxaov-LMuxs3JH54WAPZkVS0O3S9vM7LmB3s "Dataset is used to detect hateful memes. In total, the datset contains 10,000 memes comprising of five different types: multimodal hate, where benign confounders were found for both modalities, unimodal hate, where one or both modalities were already hateful on their own, benign image, benign text confounders and finally random not-hateful examples.")|10k|-|[2020](https://arxiv.org/abs/2005.04790)|English|<a target="_blank" href="https://paperswithcode.com/paper/the-hateful-memes-challenge-detecting-hate" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Multi-Modal Learning

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Street View Text (SVT)](http://www.iapr-tc11.org/mediawiki/index.php/The_Street_View_Text_Dataset "Dataset contains images with textual content used for scene text recognition.")|-|XML, JPG|[2012](http://www.iapr-tc11.org/dataset/SVT/wang_eccv2010.pdf)|English||
|[MovieQA](https://github.com/makarandtapaswi/MovieQA_benchmark "Dataset used to evaluate automatic story comprehension from both video and text. The data set consists of almost 15,000 multiple choice question answers obtained from over 400 movies.")|14,944|JSON|[2016](https://arxiv.org/abs/1512.02902)|English|<a target="_blank" href="https://paperswithcode.com/paper/movieqa-understanding-stories-in-movies" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Visual Storytelling Dataset (VIST)](http://visionandlanguage.net/VIST/index.html "Dataset contains 81,743 unique photos in 20,211 sequences, aligned to descriptive and story language. VIST is previously known as "SIND", the Sequential Image Narrative Dataset (SIND).")|81,743|JSON|[2016](https://arxiv.org/abs/1604.03968)|English|<a target="_blank" href="https://paperswithcode.com/paper/visual-storytelling" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Multi30k](https://github.com/multi30k/dataset "Dataset of images paired with sentences in English and German. This dataset extends the Flickr30K dataset.")|31,014|-|[2016](https://arxiv.org/abs/1605.00459)|German, English|<a target="_blank" href="https://paperswithcode.com/paper/multi30k-multilingual-english-german-image" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Twitter100k](https://github.com/huyt16/Twitter100k "Pairs of images and tweets.")|100k|Text and Images|[2017](https://arxiv.org/abs/1703.06618)|English|<a target="_blank" href="https://paperswithcode.com/paper/twitter100k-a-real-world-dataset-for-weakly" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[TGIF-QA](https://github.com/YunseokJANG/tgif-qa "Dataset consists of 165K QA pairs from 72K animated GIFs. Used for video question answering.")|165k|CSV|[2017](https://arxiv.org/abs/1704.04497)|English|<a target="_blank" href="https://paperswithcode.com/paper/tgif-qa-toward-spatio-temporal-reasoning-in" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[TVQA](http://tvqa.cs.unc.edu/download_tvqa.html "Dataset is used for video question answering and consists of 152,545 QA pairs from 21,793 clips, spanning over 460 hours of video. ")|460+ Hours|HDF5, JSON|[2018](https://arxiv.org/abs/1809.01696)|English|<a target="_blank" href="https://paperswithcode.com/paper/tvqa-localized-compositional-video-question" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Multimodal EmotionLines Dataset (MELD)](https://affective-meld.github.io/ "Dataset contains the same dialogue instances available in EmotionLines dataset, but it also encompasses audio and visual modality along with text. It has more than 1,400 dialogues and 13,000 utterances from Friends TV series.  Each utterance in a dialogue has been labeled by any of these seven emotions: Anger, Disgust, Sadness, Joy, Neutral, Surprise and Fear. It also has sentiment (positive, negative and neutral) annotation for each utterance.")|1,400|CSV, MP4|[2018](https://arxiv.org/abs/1810.02508)|English|<a target="_blank" href="https://paperswithcode.com/paper/meld-a-multimodal-multi-party-dataset-for" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Audio Visual Scene-Aware Dialog (AVSD)](https://video-dialog.com/ "Dataset consists of text-based human conversations about short videos from the Charades dataset.")|11,816|JSON|[2019](https://arxiv.org/abs/1901.09107)|English|<a target="_blank" href="https://paperswithcode.com/paper/audio-visual-scene-aware-dialog" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Multimodal Sarcasm Detection Dataset (MUStARD)](https://github.com/soujanyaporia/MUStARD "The dataset, a multimodal video corpus, consists of audiovisual utterances annotated with sarcasm labels. Each utterance is accompanied by its context, which provides additional information on the scenario where the utterance occurs.")|6,365|JSON|[2019](https://arxiv.org/abs/1906.01815)|English|<a target="_blank" href="https://paperswithcode.com/paper/towards-multimodal-sarcasm-detection-an" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[WAT 2019 Hindi-English](https://ufal.mff.cuni.cz/hindi-visual-genome/wat-2019-multimodal-task "Dataset consists of multimodal English-to-Hindi translation. It inputs an image, rectangular region in the image and english caption. It outputs a caption in Hindi.")|32,925|Text, JPEG|[2019](https://www.aclweb.org/anthology/D19-5224.pdf)|Hindi, English||
|[Action Learning From Realistic Environments and Directives (ALFRED)](https://github.com/askforalfred/alfred "Dataset contains 8k+ expert demostrations with 3 or more language annotations each comprising of 25,000 language directives. A trajectory consists of a sequence of expert actions, the corresponding image observations, and language annotations describing segments of the trajectory.")|8,055|JSON|[2020](https://arxiv.org/abs/1912.01734)|English|<a target="_blank" href="https://paperswithcode.com/paper/alfred-a-benchmark-for-interpreting-grounded" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[VIdeO-and-Language INference (VIOLIN)](https://github.com/jimmy646/violin "Dataset contains 95,322 video-hypothesis pairs from 15,887 video clips, spanning over 582 hours of video (YouTube and TV shows). Inference descriptions of video content were annotated. Inferences are used to measure entailment vs video clip.")|15,887|JSON, H5|[2020](https://arxiv.org/abs/2003.11618)|English|<a target="_blank" href="https://paperswithcode.com/paper/violin-a-large-scale-dataset-for-video-and" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## NLU

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[WikiReading](https://github.com/google-research-datasets/wiki-reading "The task is to predict textual values from the structured knowledge base Wikidata by reading the text of the corresponding Wikipedia articles. Includes English, Russian and Turkish.")|18M|JSON|[2016](https://arxiv.org/abs/1608.03542)|Multi-Lingual|<a target="_blank" href="https://paperswithcode.com/paper/wikireading-a-novel-large-scale-language" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Named Entity Recognition

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Wikidata NE dataset](https://event.ifi.uni-heidelberg.de/?page_id=532 "Dataset has 2 parts: the Named Entity files and the link files. The Named Entity files include the most important information about the entities, whereas the link files contain the links and ids in other databases.")|-|JSON|[2017](https://www.researchgate.net/publication/322281320_NECKAr_A_Named_Entity_Classifier_for_Wikidata)|German, English||

## Named Entity Recognition (NER)

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Conference on Computational Natural Language Learning (CoNLL 2002)](https://www.clips.uantwerpen.be/conll2002/ner/ "Spanish data is a collection of newswire articles made available by the Spanish EFE News Agency.The Dutch data consist of four editions of the Belgian newspaper "De Morgen" of 2000. IOB2 format.")|-|HTML|[2002](https://www.aclweb.org/anthology/W02-2024.pdf)|Spanish, Dutch||
|[Conference on Computational Natural Language Learning (CoNLL 2003)](https://www.clips.uantwerpen.be/conll2003/ner/ "DatasetÂ contains news articles whose text are segmented in 4 columns: the first item is a word, the second a part-of-speech (POS) tag, the third a syntactic chunk tag and the fourth the named entity tag.")|English 1,393; German 909|Tar|[2003](https://www.aclweb.org/anthology/W03-0419.pdf)|German, English|<a href="https://huggingface.co/nlp/viewer/?dataset=conll2003" title="Open in Huggingface" target="_blank">ð¤</a>|
|[JNLPBA](http://www.geniaproject.org/shared-tasks/bionlp-jnlpba-shared-task-2004 "The BioNLP / JNLPBA Shared Task 2004 involves the identification and classification of technical terms referring to concepts of interest to biologists in the domain of molecular biology.Â ")|~2,000|Iob|[2004](https://www.aclweb.org/anthology/W04-1213.pdf)|English||
|[BioCreative II Gene Mention Recognition (BC2GM)](https://biocreative.bioinformatics.udel.edu/resources/corpora/biocreative-ii-corpus/ "Dataset contains data where participants are asked to identify a gene mention in a sentence by giving its start and end characters. The training set consists of a set of sentences, and for each sentence a set of gene mentions (GENE annotations). [registration required for access]")|20k|-|[2008](https://link.springer.com/content/pdf/10.1186/gb-2008-9-s2-s2.pdf)|English||
|[HAREM](https://www.linguateca.pt/aval_conjunta/HAREM/harem_ing.html "Dataset used for Named-Entity Recognition (NER) in Portuguese.")|-|XML|[2008](https://www.linguateca.pt/LivroSegundoHAREM/)|Portuguese||
|[KALIMAT Multipurpose Arabic Corpus](https://sourceforge.net/projects/kalimat/ "Dataset contains 20,291 Arabic articles collected from the Omani newspaper Alwatan. Extractive Single-document and multi-document system summaries.  Named Entity Recognised articles. The data has 6 categories: culture, economy, local-news, international-news, religion, and sports.")|20,291|Text|[2013](https://eprints.lancs.ac.uk/id/eprint/71282/1/KALIMAT_ELHAJ_KOULALI.pdf)|Arabic||
|[Named Entity Model for German, PoliticsÂ (NEMGP)](https://www.thomas-zastrow.de/nlp/ "Dataset contains texts from Wikipedia and WikiNews, manually annotated with named entity information.")|5,094|Text|[2013](https://www.thomas-zastrow.de/nlp/)|German||
|[GermEval 2014 NER Shared Task](https://sites.google.com/site/germeval2014ner/data "The data was sampled from German Wikipedia and News Corpora as a collection of citations.The dataset covers over 31,000 sentences correspondingÂ to over 590,000 tokens.")|31,000+|TSV|[2014](https://pdfs.semanticscholar.org/f6ea/166f38804860dc6b4ef66d5dca0eed17a2d1.pdf?_ga=2.84254811.354477249.1582324561-958501894.1582324561)|German|<a href="https://huggingface.co/nlp/viewer/?dataset=germeval_14" title="Open in Huggingface" target="_blank">ð¤</a>|
|[NCBI Disease Corpus](https://www.ncbi.nlm.nih.gov/CBBresearch/Dogan/DISEASE/ "Dataset contains 6,892 disease mentions, which are mapped to 790 unique disease concepts. Of these, 88% link to a MeSH identifier, while the rest contain an OMIM identifier.")|6,892|Text|[2014](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3951655/pdf/nihms557856.pdf)|English||
|[BC5CDR Disease (BC5-Disease)](https://biocreative.bioinformatics.udel.edu/resources/corpora/biocreative-v-cdr-corpus/ "Dataset consists of three separate sets of articles with chemicals and their relations annotated. [registration required for access]")|1,500|-|[2015](https://biocreative.bioinformatics.udel.edu/media/store/files/2015/BC5CDRcorpus.pdf)|English||
|[Europeana Newspapers](https://github.com/EuropeanaNewspapers/ner-corpora "Named Entity Recognition corpora for Dutch, French, German languages fromÂ Europeana Newspapers. Data is encoded in the IOB format.")|486,218|BIO|[2016](http://lab.kb.nl/dataset/europeana-newspapers-ner)|Multi-Lingual||
|[The NewsReader MEANTIME Corpus](http://www.newsreader-project.eu/results/data/wikinews/ "480 news articles: 120 English Wikinews articles on four topics (i.e. Airbus and Boeing, Apple Inc., Stock market, and General Motors, Chrysler and Ford) and their translations in Spanish, Italian, and Dutch. Annotated with entities, events, temporal, semantic roles and event/entity coreference.")|480|XML, NAF|[2016](http://www.lrec-conf.org/proceedings/lrec2016/pdf/488_Paper.pdf)|Multi-Lingual||
|[BC5CDR Drug/Chemical (BC5-Chem)](https://biocreative.bioinformatics.udel.edu/resources/corpora/biocreative-v-cdr-corpus/ "Dataset consists of three separate sets of articles with chemicals and their relations annotated. [registration required for access]")|1,500|-|[2016](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4860626/pdf/baw068.pdf)|English||
|[W-NUT 2017](https://github.com/leondz/emerging_entities_17 "Dataset containing tweets, reddit comments, YouTube comments, and StackExchange were annotated with 6 entities: Person, Location, Corporation, Consumer good, Creative work, and Group.")|2,295|CoNLL|[2017](http://www.derczynski.com/sheffield/papers/emerging-wnut.pdf)|English||
|[Densely Annotated Wikipedia Texts (DAWT)](https://github.com/klout/opendata/tree/master/wiki_annotation "Dataset contains a total of 13.6M articles across several languages: English, Spanish, Italian, German, French and Arabic. The annotations include labeled text mentions mapping to entities (represented by their Freebase machine ids) as well as the type of entity.")|13.6M|JSON|[2017](https://arxiv.org/abs/1703.00948)|Multi-Lingual|<a target="_blank" href="https://paperswithcode.com/paper/dawt-densely-annotated-wikipedia-texts-across" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[WikiAnn](https://elisa-ie.github.io/wikiann/ "Dataset with NER annotations forÂ PER,Â ORGÂ andÂ LOC. It has been constructed using the linked entities in Wikipedia pages for 282 different languages.")|95,924|JSON|[2017](https://www.aclweb.org/anthology/P17-1178.pdf)|Multi-Lingual||
|[Finnish News Corpus for Named Entity Recognition](https://github.com/mpsilfve/finer-data "Dataset contains 953 articles (193,742 word tokens) with 6 named entity classes: organization, location, person, product, event, and date.")|953|CSV|[2018](https://www.aclweb.org/anthology/C18-1177.pdf)|Finnish||
|[BSNLP-2019](http://bsnlp.cs.helsinki.fi/shared_task.html "Dataset used to classify named entities in web documents in Slavic languages, their lemmatization, and cross-language matching. Dataset covers 4 languages: Bulgarian, Czech, Polish, and Russian.")|-|Text, OUT|[2019](http://bsnlp.cs.helsinki.fi/shared_task_BNSLP_2019.pdf)|Multi-Lingual||
|[ScienceExamCER](http://cognitiveai.org/explanationbank/ "Dataset contains 133k mentions in the science exam domain where nearly all (96%) of content words have been annotated with one or more fine-grained semantic class labels including taxonomic groups, meronym groups, verb/action groups, properties and values, and synonyms.")|133k|Text, TSV|[2019](https://arxiv.org/abs/1911.10436)|English|<a target="_blank" href="https://paperswithcode.com/paper/scienceexamcer-a-high-density-fine-grained" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[LitBank](https://github.com/dbamman/litbank "Dataset contains 100 works of English-language fiction. It currently contains annotations for entities, events and entity coreference in a sample of ~2,000 words from each of those texts, totaling 210,532 tokens.")|100|TSV, Text|[2019](https://arxiv.org/abs/1912.01140)|English|<a target="_blank" href="https://paperswithcode.com/paper/an-annotated-dataset-of-coreference-in" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[NKJP-NER](https://klejbenchmark.com/tasks/ "Dataset contains extracted sentences with named entities of exactly one type. The task is to predict the type of the named entity.")|20k|TSV|[2020]()|Polish||

## Natural Language Inference (NLI)

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Stanford Natural Language Inference (SNLI) Corpus](https://nlp.stanford.edu/projects/snli/ "Image captions matched with newly constructed sentences to form entailment, contradiction, or neutral pairs.")|570k|Text|[2015](https://nlp.stanford.edu/pubs/snli_paper.pdf)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=snli" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Compositional Distributional Semantics Corpus (CDSC : E & R)](https://klejbenchmark.com/tasks/ "Dataset is s human-annotated for semantic relatedness and entailment by 3 human judges experienced in Polish linguistics.")|10k|TSV|[2017](https://www.aclweb.org/anthology/P17-1073.pdf)|Polish||
|[Question NLI](https://rajpurkar.github.io/SQuAD-explorer/ "Dataset converts SQuAD dataset into sentence pair classification by forming a pair between each question and each sentence in the corresponding context.")|110k|JSON|[2018](https://arxiv.org/abs/1806.03822)|English|<a target="_blank" href="https://paperswithcode.com/paper/know-what-you-dont-know-unanswerable" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=squad" title="Open in Huggingface" target="_blank">ð¤</a>|
|[e-SNLI](https://github.com/OanaMariaCamburu/e-SNLI "Dataset contains human-annotated natural language explanations of the entailment relations.")|-|CSV|[2018](https://arxiv.org/abs/1812.01193)|English|<a target="_blank" href="https://paperswithcode.com/paper/e-snli-natural-language-inference-with" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=esnli" title="Open in Huggingface" target="_blank">ð¤</a>|
|[SherLIiC](https://github.com/mnschmit/SherLIiC "Dataset contains manually annotated inference rule candidates (InfCands), accompanied by ~960k unlabeled InfCands, and  ~190k typed textual relations between Freebase entities extracted from the large entity-linked corpus ClueWeb09.")|~960,000|Text|[2019](https://arxiv.org/abs/1906.01393)|English|<a target="_blank" href="https://paperswithcode.com/paper/sherliic-a-typed-event-focused-lexical" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[CommitmentBank](https://github.com/mcdm/CommitmentBank "Dataset contains naturally occurring discourses whose final sentence contains a clause-embedding predicate under an entailment canceling operator (question, modal, negation, antecedent of conditional).")|1,200|CSV|[2019](https://semanticsarchive.net/Archive/Tg3ZGI2M/Marneffe.pdf)|English||
|[TabFact](https://github.com/wenhuchen/Table-Fact-Checking "Dataset contains 16k Wikipedia tables as evidence for 118k human annotated statements to study fact verification with semi-structured evidence.")|16k|JSON|[2020](https://arxiv.org/abs/1909.02164)|English|<a target="_blank" href="https://paperswithcode.com/paper/tabfact-a-large-scale-dataset-for-table-based" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Adversarial NLI (ANLI)](https://github.com/facebookresearch/anli/ "Dataset is an NLI benchmark created via human-and-model-in-the-loop enabled training (HAMLET). Human was tasked to provide a hypothesis that fools the model into misclassifying the label.")|169,265|JSON|[2020](https://arxiv.org/abs/1910.14599v2)|English|<a target="_blank" href="https://paperswithcode.com/paper/adversarial-nli-a-new-benchmark-for-natural" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=anli" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Implicature and Presupposition Diagnostic dataset (IMPPRES)](https://github.com/facebookresearch/Imppres "Dataset contains semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types. IMPPRES follows the format of SNLI, MultiNLI and XNLI, which was created to evaluate how well trained NLI models recognize several classes of presuppositions and scalar implicatures.")|25,000+|JSON|[2020](https://arxiv.org/abs/2004.03066)|English|<a target="_blank" href="https://paperswithcode.com/paper/are-natural-language-inference-models" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[KorNLI](https://github.com/kakaobrain/KorNLUDatasets "Dataset used for natural language inference for the Korean language.")|950,354|TSV|[2020](https://arxiv.org/abs/2004.03289)|Korean|<a target="_blank" href="https://paperswithcode.com/paper/kornli-and-korsts-new-benchmark-datasets-for" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=kor_nli" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Natural Language Inference in Turkish (NLI-TR)](https://github.com/boun-tabi/NLI-TR "Datasets that were obtained by translating the SNLIÂ andÂ MNLI corpora into Turkish.")|-|JSON|[2020](https://arxiv.org/abs/2004.14963)|Turkish|<a target="_blank" href="https://paperswithcode.com/paper/use-of-machine-translation-to-obtain-labeled" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[FarsTail](https://github.com/dml-qom/FarsTail "Dataset contains 10,367 instances generated from a collection of 3,539 multiple choice questions in the Farsi language. The train, validation, and test portions include 7,266, 1,537, and 1,564 instances.")|10,367|CSV|[2020](https://arxiv.org/abs/2009.08820)|Persian (Farsi)|<a target="_blank" href="https://paperswithcode.com/paper/farstail-a-persian-natural-language-inference" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[InfoTabs](https://infotabs.github.io/ "Dataset contains human-written textual hypotheses based on premises that are tables extracted from Wikipedia info-boxes.")|2,540|TSV, HTML, JSON|[2020](https://vgupta123.github.io/docs/ACL-GuptaV.InfoTabS.pdf)|English||

## Natural Language Understanding

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Language Modeling Broadened to Account for Discourse Aspects (LAMBADA)](https://zenodo.org/record/2630551 "Dataset contains narrative passages sharing the characteristic that human subjects are able to guess their last word if they are exposed to the whole passage, but not if they only see the last sentence preceding the target word.")|10,022|Text|[2016](https://arxiv.org/abs/1606.06031)|English|<a target="_blank" href="https://paperswithcode.com/paper/the-lambada-dataset-word-prediction-requiring" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Natural Question Understanding (NQU)

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Break](https://allenai.github.io/Break/ "Dataset contains 83,978 examples sampled from 10 question answering datasets over text, images and databases. Dataset used to obtain the Question Decomposition Meaning Representation (QDMR) for questions.")|83,978|CSV|[2020](https://arxiv.org/abs/2001.11770v1)|English|<a target="_blank" href="https://paperswithcode.com/paper/break-it-down-a-question-understanding" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=break_data" title="Open in Huggingface" target="_blank">ð¤</a>|

## Node Classification

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Wiki-CS](https://github.com/pmernyei/wiki-cs-dataset "Dataset consists of nodes corresponding to Computer Science articles, with edges based on hyperlinks and 10 classes representing different branches of the field.")|216,123 Edges, 11,701 Nodes|JSON|[2020](https://arxiv.org/abs/2007.02901)|English|<a target="_blank" href="https://paperswithcode.com/paper/wiki-cs-a-wikipedia-based-benchmark-for-graph" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Numeric Fused-Head

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Numeric Fused-Heads](https://github.com/yanaiela/num_fh/tree/master/data/resolution/processed "Dataset contains annotated sentences of numeric-fused-heads, along with their "missing head". A number refers to an implicit (and not explicitly provided) reference. For example, in the sentence "I miss being 10", the number 10 refers to the age of 10, but is not explicitly said.")|9,412|JSON|[2019](https://www.mitpressjournals.org/doi/pdf/10.1162/tacl_a_00280)|English||

## Open Link Prediction

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Olpbench](https://www.uni-mannheim.de/dws/research/resources/olpbench/ "Dataset contains 30M open triples, 1M distinct open relations and 2.5M distinct mentions of approximately 800K entities. Dataset is used for open link prediction task.")|30M|Text|[2020](https://www.aclweb.org/anthology/2020.acl-main.209.pdf)|English||

## PCA

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Yahoo! Music User Ratings of Musical Artists](https://webscope.sandbox.yahoo.com/catalog.php?datatype=r "Over 10M ratings of artists by Yahoo users. May be used to validate recommender systems or collaborative filtering algorithms.")|~10M|Text|[2004](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/ILAT5B)|English||

## Paraphrase Generation

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[PARANMT-50M](https://www.cs.cmu.edu/~jwieting/ "Dataset containing more than 50 million English-English sentential paraphrase pairs.")|50M|Text|[2018](https://www.aclweb.org/anthology/P18-1042.pdf)|English||
|[ParaPhraser Plus](http://paraphraser.ru/download/ "Dataset contains 7,227 pairs of sentences, which are classified by humans into three classes: 2,582 non-paraphrases, 2,957 near-paraphrases,and 1,688 precise-paraphrases.")|7,227|JSON|[2020](https://arxiv.org/abs/2006.09719)|Russian|<a target="_blank" href="https://paperswithcode.com/paper/automatically-ranked-russian-paraphrase" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Paraphrase Identification

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Armenian Paraphrase Detection Corpus (ARPA)](https://github.com/ivannikov-lab/arpa-paraphrase-corpus "Dataset used for paraphrase detection in Armenian was collected from news texts consisting of articles written in the last 10 years from Hetq and Panarmenian news websites.")|2,360|TSV|[2020](https://arxiv.org/ftp/arxiv/papers/2009/2009.12615.pdf)|Armenian||

## Paraphrasing Identification

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Microsoft Research Paraphrase Corpus (MRPC)](https://www.microsoft.com/en-us/download/details.aspx?id=52398 "Dataset contains pairs of sentences which have been extracted from news sources on the web, along with human annotations indicating whether each pair captures a paraphrase/semantic equivalence relationship.")|5,800|Text|[2005](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/I05-50025B15D.pdf)|English||
|[DuoRC](https://duorc.github.io/ "Dataset contains 186,089 unique question-answer pairs created from a collection of 7,680 pairs of movie plots where each pair in the collection reflects two versions of the same movie.")|186,089|JSON|[2018](https://arxiv.org/abs/1804.07927)|English|<a target="_blank" href="https://paperswithcode.com/paper/duorc-towards-complex-language-understanding" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Paraphrase Adversaries from Word Scrambling (PAWS)](https://github.com/google-research-datasets/paws "Dataset contains 108,463 human-labeled and 656k noisily labeled pairs that feature the importance of modeling structure, context, and word order information for the problem of paraphrase identification.")|750,000+|TSV|[2019](https://arxiv.org/abs/1904.01130)|English|<a target="_blank" href="https://paperswithcode.com/paper/paws-paraphrase-adversaries-from-word" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Paraphrase Adversaries from Word Scrambling (PAWS-X)](https://github.com/google-research-datasets/paws/tree/master/pawsx "Dataset contains 23,659 human translated PAWS evaluation pairs and 296,406 machine translated training pairs in six typologically distinct languages: French, Spanish, German, Chinese, Japanese, and Korean. All translated pairs are sourced from examples in PAWS-Wiki.")|300,000+|TSV|[2019](https://arxiv.org/abs/1908.11828)|Multi-Lingual|<a target="_blank" href="https://paperswithcode.com/paper/paws-x-a-cross-lingual-adversarial-dataset" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Part of Speech (POS)

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[The Penn Treebank Project](https://github.com/tomsercu/lstm/tree/master/data "Naturally occurring text annotated for linguistic structure.")|~1M words|Text|[1995](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.9.8216&rep=rep1&type=pdf)|English||
|[Genia](http://www.geniaproject.org/genia-corpus "Dataset contains 1,999 Medline abstracts, selected using a PubMed query for the three MeSH terms "human", "blood cells", and "transcription factors". The corpus has been annotated for part-of-speech, contituency syntactic, terms, events, relations, and coreference.")|1,999|Text, XML|[2003]()|English||
|[Conference on Computational Natural Language Learning (CoNLL 2003)](https://www.clips.uantwerpen.be/conll2003/ner/ "DatasetÂ contains news articles whose text are segmented in 4 columns: the first item is a word, the second a part-of-speech (POS) tag, the third a syntactic chunk tag and the fourth the named entity tag.")|English 1,393; German 909|Tar|[2003](https://www.aclweb.org/anthology/W03-0419.pdf)|German, English|<a href="https://huggingface.co/nlp/viewer/?dataset=conll2003" title="Open in Huggingface" target="_blank">ð¤</a>|
|[KALIMAT Multipurpose Arabic Corpus](https://sourceforge.net/projects/kalimat/ "Dataset contains 20,291 Arabic articles collected from the Omani newspaper Alwatan. Extractive Single-document and multi-document system summaries.  Named Entity Recognised articles. The data has 6 categories: culture, economy, local-news, international-news, religion, and sports.")|20,291|Text|[2013](https://eprints.lancs.ac.uk/id/eprint/71282/1/KALIMAT_ELHAJ_KOULALI.pdf)|Arabic||

## Phonetic Typology

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[VoxClamantis](https://voxclamantisproject.github.io/ "Dataset contains phoneme-level alignments for more than 600 languages, high-resource alignments for ~50 languages, and phonetic measures for all vowels and sibilants. Consists of 690 audio readings of the New Testament of the Bible.")|690|CSV|[2020](https://arxiv.org/abs/2005.13962)|Multi-Lingual|<a target="_blank" href="https://paperswithcode.com/paper/a-corpus-for-large-scale-phonetic-typology" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Post-Modifier Generation

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Post-Modifier Dataset (PoMo)](https://github.com/StonyBrookNLP/PoMo "Dataset for developing post-modifier generation systems. It's a collection of sentences that contain entity post-modifiers, along with a collection of facts about the entities obtained from Wikidata.")|231,057|PM, WIKI|[2019](https://www.aclweb.org/anthology/N19-1089.pdf)|English||

## Question Answering

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[TrecQA](https://github.com/castorini/data/tree/master/TrecQA/data "Dataset is commonly used for evaluating answer selection in question answering.")|-|XML|[2007](https://www.aclweb.org/anthology/D07-1003.pdf)|English||
|[WebQuestions](https://worksheets.codalab.org/worksheets/0xba659fe363cb46e7a505c5b6a774dc8a "Dataset contains 6,642 question/answer pairs. The questions are supposed to be answerable byÂ Freebase, a large knowledge graph. The questions are mostly centered around a single named entity.")|6,642|JSON|[2013](https://cs.stanford.edu/~pliang/papers/freebase-emnlp2013.pdf)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=web_questions" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Dataset for the Machine Comprehension of Text](https://github.com/mcobzarenco/mctest/tree/master/data/MCTest "Stories and associated questions for testing comprehension of text.")|660|Text|[2013](https://www.aclweb.org/anthology/D13-1020.pdf)|English||
|[Did You Know (DYK)](https://klejbenchmark.com/tasks/ "Dataset contains of 4,721 questionâanswer pairs obtained from Czy wiesz (Do you know) Wikipedia project.")|4,721|TSV|[2013](https://www.researchgate.net/publication/272685895_Open_dataset_for_development_of_Polish_Question_Answering_systems)|Polish||
|[Jeapardy Questions Answers](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/ "Dataset contains Jeopardy questions, answers and other data.")|216,930|JSON|[2014](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=jeopardy" title="Open in Huggingface" target="_blank">ð¤</a>|
|[bAbI 20 Tasks](https://research.fb.com/downloads/babi/ "Dataset cotains a set of contexts, with multiple question-answer pairs available based on the contexts.")|2k|Text|[2015](https://arxiv.org/abs/1502.05698)|Hindi, English|<a target="_blank" href="https://paperswithcode.com/paper/towards-ai-complete-question-answering-a-set" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[The SimpleQuestions Dataset](https://research.fb.com/downloads/babi/ "Dataset for question answering with human generated questions paired with a corresponding fact, formatted as (subject, relationship, object), that provides the answer but also a complete explanation.")|108,442|Text|[2015](https://arxiv.org/abs/1506.02075)|English|<a target="_blank" href="https://paperswithcode.com/paper/large-scale-simple-question-answering-with" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[CNN / Daily Mail Dataset](https://cs.nyu.edu/~kcho/DMQA/ "Cloze-style reading comprehension dataset created from CNN and Daily Mail news articles.")|1M+|Question|[2015](https://arxiv.org/abs/1506.03340)|English|<a target="_blank" href="https://paperswithcode.com/paper/teaching-machines-to-read-and-comprehend" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=cnn_dailymail" title="Open in Huggingface" target="_blank">ð¤</a>|
|[WikiTablesQuestions](https://github.com/ppasupat/WikiTableQuestions "Dataset is for the task of question answering on semi-structured HTML tables.")|22,033|TSV|[2015](https://arxiv.org/abs/1508.00305)|English|<a target="_blank" href="https://paperswithcode.com/paper/compositional-semantic-parsing-on-semi" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[InsuranceQA](https://github.com/shuzi/insuranceQA "Dataset contains questions and answers collected from the websiteÂ Insurance Library. It consists of questions from real world users, the answers with high quality were composed by professionals with deep domain knowledge. There are 16,889 questions in total.")|16,889|-|[2015](https://arxiv.org/abs/1508.01585)|English|<a target="_blank" href="https://paperswithcode.com/paper/applying-deep-learning-to-answer-selection-a" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[WikiQA Corpus](https://www.microsoft.com/en-us/download/details.aspx?id=52419 "Dataset contains Bing query logs as the question source. Each question is linked to a Wikipedia page that potentially has the answer.Â ")|3,047|TSV|[2015](https://www.aclweb.org/anthology/D15-1237.pdf)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=wiki_qa" title="Open in Huggingface" target="_blank">ð¤</a>|
|[A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning (CLEVR & CoGenT)](https://cs.stanford.edu/people/jcjohns/clevr/ "Visual question answering dataset contains 100,000 images and 999,968 questions.")|999,968 questions; 100,000 images|JSON|[2016](http://vision.stanford.edu/pdf/johnson2017cvpr.pdf)|English||
|[The Dialog-based Language Learning Dataset](https://research.fb.com/downloads/babi/ "Dataset was designed to measure how well models can perform at learning as a student given a teacherâs textual responses to the studentâs answer.")|-|Text|[2016](https://arxiv.org/abs/1604.06045)|English|<a target="_blank" href="https://paperswithcode.com/paper/dialog-based-language-learning" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[The WikiMovies Dataset](https://research.fb.com/downloads/babi/ "Dataset contains only the QA part of the Movie Dialog dataset, but using three different settings of knowledge: using a traditional knowledge base (KB), using Wikipedia as the source of knowledge, or using IE (information extraction) over Wikipedia.")|~100,000|Text|[2016](https://arxiv.org/abs/1606.03126)|English|<a target="_blank" href="https://paperswithcode.com/paper/key-value-memory-networks-for-directly" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[SelQA](https://github.com/emorynlp/selqa "Dataset provides crowdsourced annotation for two selection-based question answer tasks, answer sentence selection and answer triggering. Our dataset composes about 8K factoid questions for the top-10 most prevalent topics among Wikipedia articles.")|8k|JSON, TSV|[2016](https://arxiv.org/abs/1606.08513)|English|<a target="_blank" href="https://paperswithcode.com/paper/selqa-a-new-benchmark-for-selection-based" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Who Did What Dataset](https://tticnlp.github.io/who_did_what/download.html "Dataset contains over 200,000 fill-in-the-gap (cloze) multiple choice reading comprehension problems constructed from the LDC English Gigaword newswire corpus.")|200,000K|XML|[2016](https://arxiv.org/abs/1608.05457)|English|<a target="_blank" href="https://paperswithcode.com/paper/who-did-what-a-large-scale-person-centered" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Microsoft Machine Reading COmprehension Dataset (MS MARCO)](https://microsoft.github.io/msmarco/ "Dataset focused on machine reading comprehension, question answering, and passage ranking, keyphrase extraction, and conversational search studies.")|1,010,916|JSON|[2016](https://arxiv.org/abs/1611.09268)|English|<a target="_blank" href="https://paperswithcode.com/paper/ms-marco-a-human-generated-machine-reading" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=ms_marco" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Human-in-the-loop Dialogue Simulator (HITL)](https://research.fb.com/downloads/babi/ "Dataset provides a framework for evaluating a botâs ability to learn to improve its performance in an online setting using feedback from its dialog partner. The dataset contains questions based on the bAbI and WikiMovies datasets, with the addition of feedback from the dialog partner.")|-|Text|[2016](https://arxiv.org/abs/1611.09823)|English|<a target="_blank" href="https://paperswithcode.com/paper/dialogue-learning-with-human-in-the-loop" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Explanations for Science Questions](http://ai2-website.s3.amazonaws.com/data/COLING2016_Explanations_Oct2016.zip "Data contains: gold explanation sentences supporting 363 science questions, relation annotation for a subset of those explanations, and a graphical annotation tool with annotation guidelines.")|1,363|CSV|[2016](https://pdfs.semanticscholar.org/04d7/b7851683809cab561d09b5c5c80bd5c33c80.pdf?_ga=2.42297447.354477249.1582324561-958501894.1582324561)|English||
|[Sequential Question Answering (SQA)](https://www.microsoft.com/en-us/download/details.aspx?id=54253 "Dataset was created to explore the task of answering sequences of inter-related questions on HTML tables. It has 6,066 sequences with 17,553 questions in total.")|17,553|TSV|[2016](https://people.cs.umass.edu/~miyyer/pubs/2017_acl_dynsp.pdf)|English||
|[Childrenâs Book Test (CBT)](https://research.fb.com/downloads/babi/ "Dataset contains âquestionsâ from chapters in the book by enumerating 21 consecutive sentences. In each question, the first 20 sentences form the context, and a word is removed from the 21st sentence, which becomes the query. Models must identify the answer word among a selection of 10 candidate answers appearing in the context sentences and the query.")|~688,000|Text|[2016](https://research.fb.com/wp-content/uploads/2016/11/the_goldilocks_principle_reading_children_s_books_with_explicit_memory_representations.pdf?)|English||
|[The Movie Dialog Dataset](https://research.fb.com/downloads/babi/ "Dataset measures how well models can perform at goal and non-goal orientated dialogue centered around the topic of movies (question answering, recommendation and discussion).")|~3.5M|Text|[2016](https://www.aclweb.org/anthology/I17-1099.pdf)|English||
|[SemEvalCQA](http://alt.qcri.org/semeval2016/task3/index.php?id=data-and-tools "Dataset for community question answering.")|-|XML|[2016](https://www.aclweb.org/anthology/S16-1083.pdf)|Arabic, English||
|[AI2 Science Questions v2.1](http://data.allenai.org/ai2-science-questions/ "Dataset consists of questions used in student assessments in the United States across elementary and middle school grade levels. Each question is 4-way multiple choice format and may or may not include a diagram element.")|5,060|JSON, CSV|[2017]()|English|<a href="https://huggingface.co/nlp/viewer/?dataset=ai2_arc" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Textbook Question Answering](http://data.allenai.org/tqa/ "The M3C task builds on the popular Visual Question Answering (VQA) and Machine Comprehension (MC) paradigms by framing question answering as a machine comprehension task, where the context needed to answer questions is provided and composed of both text and images.")|26,620|JSON, PNG|[2017](http://ai2-website.s3.amazonaws.com/publications/CVPR17_TQA.pdf)|English||
|[LC-QuAD 2.0](http://lc-quad.sda.tech/ "Dataset contains questions and SPARQL queries. LC-QuAD usesÂ DBpedia v04.16Â as the target KB.")|30k|JSON|[2017](http://jens-lehmann.org/files/2019/iswc_lcquad2.pdf)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=lc_quad" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Fact-based Visual Question Answering (FVQA)](https://www.dropbox.com/s/iyz6l7jhbt6jb7q/new_dataset_release.zip?dl=0 "Dataset contains image question anwering triples")|5,826 questions; 2,190 images|JSON|[2017](https://arxiv.org/abs/1606.05433)|English|<a target="_blank" href="https://paperswithcode.com/paper/fvqa-fact-based-visual-question-answering" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[NewsQA](https://github.com/Maluuba/newsqa "Crowdworkers supply questions and answers based on a set of over 10,000 news articles from CNN.")|12,744|JSON, CSV|[2017](https://arxiv.org/abs/1611.09830)|English|<a target="_blank" href="https://paperswithcode.com/paper/newsqa-a-machine-comprehension-dataset" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[VisDial](https://visualdialog.org/data "Dataset contains images from COCO training set, and dialogues. Meant to be used for model to be trained in answering questions about images during conversation. Contains 1.2M dialog question-answers.")|1.2M|JSON|[2017](https://arxiv.org/abs/1703.06585)|English|<a target="_blank" href="https://paperswithcode.com/paper/learning-cooperative-visual-dialog-agents" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[ReAding Comprehension Dataset From Examinations (RACE)](http://www.cs.cmu.edu/~glai1/data/race/ "Dataset was collected from the English exams evaluating the students' ability in understanding and reasoning.")|28k|JSON|[2017](https://arxiv.org/abs/1704.04683)|English|<a target="_blank" href="https://paperswithcode.com/paper/race-large-scale-reading-comprehension" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=race" title="Open in Huggingface" target="_blank">ð¤</a>|
|[SearchQA](https://github.com/nyu-dl/dl4ir-searchqA "Dataset from Jeapardy archives which consists of more than 140k question-answer pairs with each pair having 49.6 snippets on average.")|140k|JSON|[2017](https://arxiv.org/abs/1704.05179)|English|<a target="_blank" href="https://paperswithcode.com/paper/searchqa-a-new-qa-dataset-augmented-with" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=search_qa" title="Open in Huggingface" target="_blank">ð¤</a>|
|[TriviaQA](http://nlp.cs.washington.edu/triviaqa/ "Dataset containing over 650K question-answer-evidence triples. It includes 95K QA pairs authored by trivia enthusiasts and independently gathered evidence documents, 6 per question on average.")|650,000+|JSON|[2017](https://arxiv.org/abs/1705.03551)|English|<a target="_blank" href="https://paperswithcode.com/paper/triviaqa-a-large-scale-distantly-supervised" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=trivia_qa" title="Open in Huggingface" target="_blank">ð¤</a>|
|[AQuA](https://github.com/deepmind/AQuA "Dataset containing algebraic word problems with rationales for their answers.")|100k|JSON|[2017](https://arxiv.org/abs/1705.04146)|English|<a target="_blank" href="https://paperswithcode.com/paper/program-induction-by-rationale-generation" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[QA-ZRE](http://nlp.cs.washington.edu/zeroshot/ "Dataset contain question answer pairs with each instance containing a relation, a question, a sentence, and an answer set.")|30M|Text|[2017](https://arxiv.org/abs/1706.04115)|English|<a target="_blank" href="https://paperswithcode.com/paper/zero-shot-relation-extraction-via-reading" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Quasar-S & T](http://curtis.ml.cmu.edu/datasets/quasar/ "The Quasar-S dataset consists of 37,000 cloze-style queries constructed from definitions of software entity tags on the popular website Stack Overflow. The Quasar-T dataset consists of 43,000 open-domain trivia questions and their answers obtained from various internet sources.")|80k|JSON|[2017](https://arxiv.org/abs/1707.03904)|English|<a target="_blank" href="https://paperswithcode.com/paper/quasar-datasets-for-question-answering-by" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[SciQ Dataset](http://data.allenai.org/sciq/ "Dataset contains 13,679 crowdsourced science exam questions about Physics, Chemistry and Biology, among others. The questions are in multiple-choice format with 4 answer options each.")|13,769|JSON|[2017](https://arxiv.org/abs/1707.06209)|English|<a target="_blank" href="https://paperswithcode.com/paper/crowdsourcing-multiple-choice-science" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=sciq" title="Open in Huggingface" target="_blank">ð¤</a>|
|[NarrativeQA](https://github.com/deepmind/narrativeqa "Dataset contains the list of documents with Wikipedia summaries, links to full stories, and questions and answers.")|1,572|CSV|[2017](https://arxiv.org/abs/1712.07040)|English|<a target="_blank" href="https://paperswithcode.com/paper/the-narrativeqa-reading-comprehension" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[The Story Cloze Test : ROCStories](https://cs.rochester.edu/nlp/rocstories/ "Dataset for story understanding that provides systems with four-sentence stories and two possible endings. The systems must then choose the correct ending to the story.")|100,000+|JSON|[2017](https://www.cs.rochester.edu/~nasrinm/files/Papers/lsdsem17-shared-task.pdf)|English||
|[SQuAD-it](https://github.com/crux82/squad-it "The dataset contains more than 60,000 question/answer pairs in Italian derived from the original English SQuAD dataset.")|60,000+|JSON|[2018](http://ceur-ws.org/Vol-2481/paper25.pdf)|Italian|<a href="https://huggingface.co/nlp/viewer/?dataset=squad_it" title="Open in Huggingface" target="_blank">ð¤</a>|
|[MoviE Text Audio QA (MetaQA)](https://github.com/yuyuz/MetaQA "Dataset contains more than 400K questions for both single and multi-hop reasoning, and provides more realistic text and audio versions. MetaQA serves as a comprehensive extension of WikiMovies.")|400,000+|Text, MP3|[2018](https://arxiv.org/abs/1709.04071)|English|<a target="_blank" href="https://paperswithcode.com/paper/variational-reasoning-for-question-answering" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[DuReader](http://ai.baidu.com/broad/download?dataset=dureader "DuReader version 2.0 contains more than 300K question, 1.4M evidence documents and 660K human generated answers.")|1,431,429|JSON|[2018](https://arxiv.org/abs/1711.05073)|Mandarin|<a target="_blank" href="https://paperswithcode.com/paper/dureader-a-chinese-machine-reading" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[DVQA](https://github.com/kushalkafle/DVQA_dataset "Dataset containing data visualizations and natural language questions.")|3,487,194|JSON, PNG|[2018](https://arxiv.org/abs/1801.08163)|English|<a target="_blank" href="https://paperswithcode.com/paper/dvqa-understanding-data-visualizations-via" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Complex Sequential Question Answering (CSQA)](https://github.com/amritasaha1812/CSQA_Code "Dataset contains around 200K dialogs with a total of 1.6M turns. Further, unlike existing large scale QA datasets which contain simple questions that can be answered from a single tuple, the questions in the dialogs require a larger subgraph of the KG.")|200k|-|[2018](https://arxiv.org/abs/1801.10314)|English|<a target="_blank" href="https://paperswithcode.com/paper/complex-sequential-question-answering-towards" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[AI2 Reasoning Challenge (ARC)](http://data.allenai.org/arc/ "Dataset contains 7,787 genuine grade-school level, multiple-choice science questions.")|7,787|JSON, CSV|[2018](https://arxiv.org/abs/1803.05457)|English|<a target="_blank" href="https://paperswithcode.com/paper/think-you-have-solved-question-answering-try" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[ComplexWebQuestions](https://www.tau-nlp.org/compwebq "Dataset contains a large set of complex questions in natural language, and can be used in multiple ways.")|34,689|JSON|[2018](https://arxiv.org/abs/1803.06643)|English|<a target="_blank" href="https://paperswithcode.com/paper/the-web-as-a-knowledge-base-for-answering" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Clinical Case Reports for Machine Reading Comprehension (CliCR)](https://github.com/clips/clicr "Dataset was built from clinical case reports, requiring the reader to answer the query with a medical problem/test/treatment entity.")|100k|JSON|[2018](https://arxiv.org/abs/1803.09720)|English|<a target="_blank" href="https://paperswithcode.com/paper/clicr-a-dataset-of-clinical-case-reports-for" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[QA-SRL Bank](http://qasrl.org/ "Dataset contains question answer pairs for 64,000 sentences. Dataset is used to train model for semantic role labeling")|64k|JSON|[2018](https://arxiv.org/abs/1805.05377v1)|English|<a target="_blank" href="https://paperswithcode.com/paper/large-scale-qa-srl-parsing" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[ProPara Dataset](http://data.allenai.org/propara/ "Dataset is used for comprehension of simple paragraphs describing processes, e.g., photosynthesis. The comprehension task relies on predicting, tracking, and answering questions about how entities change during the process.")|488Â |Google Sheets|[2018](https://arxiv.org/abs/1805.06975)|English|<a target="_blank" href="https://paperswithcode.com/paper/tracking-state-changes-in-procedural-text-a" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[SQuAD v2.0](https://rajpurkar.github.io/SQuAD-explorer/ "Paragraphs w/ questions and answers.")|150k|JSON|[2018](https://arxiv.org/abs/1806.03822)|English|<a target="_blank" href="https://paperswithcode.com/paper/know-what-you-dont-know-unanswerable" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=squad" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Situations With Adversarial Generations (SWAG)](https://rowanzellers.com/swag/ "Dataset consists of 113k multiple choice questions about groundedÂ situations. Each question is a video caption fromÂ LSMDCÂ orÂ ActivityNet Captions, with four answer choices about what might happen next in the scene.")|113k|CSV|[2018](https://arxiv.org/abs/1808.05326)|English|<a target="_blank" href="https://paperswithcode.com/paper/swag-a-large-scale-adversarial-dataset-for" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Question Answering in Context (QuAC)](http://quac.ai/ "Dataset for modeling, understanding, and participating in information seeking dialog.")|14k|JSON|[2018](https://arxiv.org/abs/1808.07036)|English|<a target="_blank" href="https://paperswithcode.com/paper/quac-question-answering-in-context" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[emrQA](https://github.com/panushri25/emrQA "Dataset contains 1M question-logical form and 400,000+ question answer evidence pairs on electronic medical records. In total, there are 2,495 clinical notes.")|2,495|CSV|[2018](https://arxiv.org/abs/1809.00732)|English|<a target="_blank" href="https://paperswithcode.com/paper/emrqa-a-large-corpus-for-question-answering" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[OpenBookQA](https://leaderboard.allenai.org/open_book_qa/submissions/get-started "Dataset modeled after open book exams for assessing human understanding of a subject. It consists of 5,957 multiple-choice elementary-level science questions (4,957 train, 500 dev, 500 test), which probe the understanding of a small "book" of 1,326 core science facts and the application of these facts to novel situations.")|5,957|JSON|[2018](https://arxiv.org/abs/1809.02789)|English|<a target="_blank" href="https://paperswithcode.com/paper/can-a-suit-of-armor-conduct-electricity-a-new" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=openbookqa" title="Open in Huggingface" target="_blank">ð¤</a>|
|[HotpotQA](https://hotpotqa.github.io/ "Dataset featuring natural, multi-hop questions, with strong supervision for supporting facts to enable more explainable question answering systems.")|1.25M|JSON|[2018](https://arxiv.org/abs/1809.09600)|English|<a target="_blank" href="https://paperswithcode.com/paper/hotpotqa-a-dataset-for-diverse-explainable" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=hotpot_qa" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Chinese Machine Reading Comprehension (CMRC 2018)](https://github.com/ymcui/cmrc2018 "Dataset is composed by near 20,000 real questions annotated on Wikipedia paragraphs by human experts.")|20k|JSON|[2018](https://arxiv.org/abs/1810.07366)|Chinese|<a target="_blank" href="https://paperswithcode.com/paper/a-span-extraction-dataset-for-chinese-machine" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=cmrc2018" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Reading Comprehension with Commonsense Reasoning Dataset (Record)](https://sheng-z.github.io/ReCoRD-explorer/ "Reading comprehension dataset which requires commonsense reasoning. Contains 120,000+ queries from 70,000+ news articles.")|70,000+|JSON|[2018](https://arxiv.org/abs/1810.12885)|English|<a target="_blank" href="https://paperswithcode.com/paper/record-bridging-the-gap-between-human-and" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[CommonsenseQA](https://www.tau-nlp.org/commonsenseqa "Dataset contains multiple-choice question answering dataset that requires different types of commonsense knowledge to predict the correct answers . It contains 12,102 questions with one correct answer and four distractor answers.")|12,012|JSON|[2018](https://arxiv.org/abs/1811.00937)|English|<a target="_blank" href="https://paperswithcode.com/paper/commonsenseqa-a-question-answering-challenge" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=commonsense_qa" title="Open in Huggingface" target="_blank">ð¤</a>|
|[QuaRel Dataset](http://data.allenai.org/quarel/ "Dataset contains 2,771 story questions about qualitative relationships.")|2,771|JSON|[2018](https://arxiv.org/abs/1811.08048)|English|<a target="_blank" href="https://paperswithcode.com/paper/quarel-a-dataset-and-models-for-answering" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=quarel" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Video Commonsense Reasoning (VCR)](https://visualcommonsense.com/download/ "Dataset contains 290K multiple-choice questions on 110K images.")|290k|JSON, JPG|[2018](https://arxiv.org/abs/1811.10830)|English|<a target="_blank" href="https://paperswithcode.com/paper/from-recognition-to-cognition-visual" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Reading Comprehension with Multiple Hops (Qangaroo)](http://qangaroo.cs.ucl.ac.uk/index.html "Reading Comprehension datasets focussing on multi-hop (alias multi-step) inference. There are 2 datasets: Wikihop (based on wikipedia) and Medhop (based on PubMed research papers).")|~53,000|JSON|[2018](https://transacl.org/ojs/index.php/tacl/article/viewFile/1325/299)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=qangaroo" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Multimodal Comprehension of Cooking Recipes (RecipeQA)](https://hucvl.github.io/recipeqa/ "Dataset for multimodal comprehension of cooking recipes. It consists of over 36K question-answer pairs automatically generated from approximately 20K unique recipes with step-by-step instructions and images.")|20k|JSON|[2018](https://www.aclweb.org/anthology/D18-1166.pdf)|English||
|[Shaping Answers with Rules through Conversation (ShARC)](https://sharc-data.github.io/ "ShARC is a Conversational Question Answering dataset focussing on question answering from texts containing rules.")|32k|JSON|[2018](https://www.aclweb.org/anthology/D18-1233.pdf)|English||
|[Reading Comprehension over Multiple Sentences (MultiRC)](https://cogcomp.seas.upenn.edu/multirc/ "Dataset of short paragraphs and multi-sentence questions that can be answered from the content of the paragraph.")|~10,000|JSON|[2018](https://www.aclweb.org/anthology/N18-1023.pdf)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=eraser_multi_rc" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Portuguese SQuAD v1.1](https://github.com/nunorc/squad-v1.1-pt "Portuguese translation of theÂ SQuADÂ dataset. The translation was performed using the Google Cloud API.")|~100,000|JSON|[2019]()|Portuguese|<a href="https://huggingface.co/nlp/viewer/?dataset=squad_v1_pt" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Social-IQ Dataset](https://github.com/A2Zadeh/Social-IQ "Dataset containing videos and natural language questions for visual reasoning.")|7,500|-|[2019](http://openaccess.thecvf.com/content_CVPR_2019/papers/Zadeh_Social-IQ_A_Question_Answering_Benchmark_for_Artificial_Social_Intelligence_CVPR_2019_paper.pdf)|English||
|[A Conversational Question Answering Challenge (CoQA)](https://stanfordnlp.github.io/coqa/ "Dataset for measuring the ability of machines to understand a text passage and answer a series of interconnected questions that appear in a conversation.")|127,000+|JSON|[2019](https://arxiv.org/abs/1808.07042)|English|<a target="_blank" href="https://paperswithcode.com/paper/coqa-a-conversational-question-answering" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=coqa" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Cornell Natural Language for Visual Reasoning (NLVR and NLVR2)](http://lil.nlp.cornell.edu/nlvr/ "Dataset contains two language grounding datasets containing natural language sentences grounded in images. The task is to determine whether a sentence is true about a visual input.")|NLVR2 107,292; NLVR 92,244|JSON|[2019](https://arxiv.org/abs/1811.00491)|English|<a target="_blank" href="https://paperswithcode.com/paper/a-corpus-for-reasoning-about-natural-language" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Dialogue-Based Reading Comprehension Examination (DREAM)](https://dataset.org/dream/ "Dataset contains 10,197 multiple choice questions for 6,444 dialogues, collected from English-as-a-foreign-language examinations designed by human experts. DREAM is likely to present significant challenges for existing reading comprehension systems: 84% of answers are non-extractive, 85% of questions require reasoning beyond a single sentence, and 34% of questions also involve commonsense knowledge.")|6,444|JSON|[2019](https://arxiv.org/abs/1902.00164)|English|<a target="_blank" href="https://paperswithcode.com/paper/dream-a-challenge-dataset-and-models-for" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[GQA](https://cs.stanford.edu/people/dorarad/gqa/download.html "Question answering on imageÂ scene graphs.")|22M|JSON, H5|[2019](https://arxiv.org/abs/1902.09506)|English|<a target="_blank" href="https://paperswithcode.com/paper/gqa-a-new-dataset-for-compositional-question" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs (DROP)](https://allennlp.org/drop "Dataset is used to resolve references in a question, perhaps to multiple input positions, and perform discrete operations over them (such as addition, counting, or sorting).")|96k|JSON|[2019](https://arxiv.org/abs/1903.00161)|English|<a target="_blank" href="https://paperswithcode.com/paper/drop-a-reading-comprehension-benchmark" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=drop" title="Open in Huggingface" target="_blank">ð¤</a>|
|[COmmonsense Dataset Adversarially-authored by Humans (CODAH)](https://github.com/Websail-NU/CODAH "Commonsense QA in the sentence completion style of SWAG. As opposed to other automatically generated NLI datasets, CODAH is adversarially constructed by humans who can view feedback from a pre-trained model and use this information to design challenging commonsense questions.")|2,776|TSV|[2019](https://arxiv.org/abs/1904.04365)|English|<a target="_blank" href="https://paperswithcode.com/paper/aqua-an-adversarially-authored-question" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[TextVQA](https://textvqa.org/dataset "TextVQA requires models to read and reason about text in images to answer questions about them. Specifically, models need to incorporate a new modality of text present in the images and reason over it to answer TextVQA questions.")|36,602|JSON, PNG|[2019](https://arxiv.org/abs/1904.08920)|English|<a target="_blank" href="https://paperswithcode.com/paper/towards-vqa-models-that-can-read" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Social IQA](https://leaderboard.allenai.org/socialiqa/submissions/get-started "Dataset used fo question-answering benchmark for testing social commonsense intelligence.")|37,000+|JSON|[2019](https://arxiv.org/abs/1904.09728)|English|<a target="_blank" href="https://paperswithcode.com/paper/socialiqa-commonsense-reasoning-about-social" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=social_i_qa" title="Open in Huggingface" target="_blank">ð¤</a>|
|[BoolQ](https://github.com/google-research-datasets/boolean-questions "Question answering dataset for yes/no questions.")|15,942|JSON|[2019](https://arxiv.org/abs/1905.10044)|English|<a target="_blank" href="https://paperswithcode.com/paper/boolq-exploring-the-surprising-difficulty-of" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=boolq" title="Open in Huggingface" target="_blank">ð¤</a>|
|[MathQA](https://math-qa.github.io/math-QA/ "Dataset contains English multiple-choice math word problems covering multiple math domain categories by modeling operation programs corresponding to word problems in the AQuA dataset.")|37k|JSON|[2019](https://arxiv.org/abs/1905.13319)|English|<a target="_blank" href="https://paperswithcode.com/paper/mathqa-towards-interpretable-math-word" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=math_qa" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Activitynet-QA](https://github.com/MILVLG/activitynet-qa "Dataset contains 58,000 human-annotated QA pairs on 5,800 videos derived from the popular ActivityNet dataset. The dataset provides a benckmark for testing the performance of VideoQA models on long-term spatio-temporal.")|58k|JSON|[2019](https://arxiv.org/abs/1906.02467)|English|<a target="_blank" href="https://paperswithcode.com/paper/activitynet-qa-a-dataset-for-understanding" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Arabic Reading Comprehension Dataset (ARCD)](https://github.com/husseinmozannar/SOQAL "Dataset contains 1,395 questions posed by crowdworkers on Wikipedia articles, and a machine translation of the Stanford Question Answering Dataset (Arabic-SQuAD) containing 48,344 questions.")|~50,000|JSON|[2019](https://arxiv.org/abs/1906.05394)|Arabic|<a target="_blank" href="https://paperswithcode.com/paper/neural-arabic-question-answering" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=arcd" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Explain Like Iâm Five (ELI5)](https://github.com/facebookresearch/ELI5 "The dataset contains 270K threads of open-ended questions that require multi-sentence answers. It was extracted from subreddit titled âExplain Like Iâm Fiveâ (ELI5), in which an online community answers questions with responses that 5-year-olds can comprehend. Facebook scripts allow you to preprocess data.")|270k|Text|[2019](https://arxiv.org/abs/1907.09190)|English|<a target="_blank" href="https://paperswithcode.com/paper/eli5-long-form-question-answering" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=eli5" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Quoref](https://leaderboard.allenai.org/quoref/submissions/get-started "Dataset which tests the coreferential reasoning capability of reading comprehension systems. In this span-selection benchmark containing 24K questions over 4.7K paragraphs from Wikipedia, a system must resolve hard coreferences before selecting the appropriate span(s) in the paragraphs for answering questions.")|24k|JSON|[2019](https://arxiv.org/abs/1908.05803)|English|<a target="_blank" href="https://paperswithcode.com/paper/quoref-a-reading-comprehension-dataset-with" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=quoref" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Cosmos QA](https://github.com/wilburOne/cosmosqa/tree/master/data/ "Dataset containing thousands ofÂ problems that requireÂ commonsense-based reading comprehension, formulated asÂ multiple-choiceÂ questions.")|35k|CSV|[2019](https://arxiv.org/abs/1909.00277)|English|<a target="_blank" href="https://paperswithcode.com/paper/cosmos-qa-machine-reading-comprehension-with" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=cosmos_qa" title="Open in Huggingface" target="_blank">ð¤</a>|
|[QuaRTz Dataset](http://data.allenai.org/quartz/ "Dataset contains 3,864 questions about open domain qualitative relationships. Each question is paired with one of 405 different background sentences (sometimes short paragraphs).")|3,864|JSON|[2019](https://arxiv.org/abs/1909.03553)|English|<a target="_blank" href="https://paperswithcode.com/paper/quartz-an-open-domain-dataset-of-qualitative" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=quartz" title="Open in Huggingface" target="_blank">ð¤</a>|
|[PubmedQA](https://pubmedqa.github.io/ "A biomedical question answering (QA) dataset collected from PubMed abstracts. The task of PubMedQA is to answer research questions with yes/no/maybe.")|~273,000|JSON|[2019](https://arxiv.org/abs/1909.06146)|English|<a target="_blank" href="https://paperswithcode.com/paper/pubmedqa-a-dataset-for-biomedical-research" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[MultiLingual Question Answering (MLQA)](https://github.com/facebookresearch/MLQA "Dataset for evaluating cross-lingual question answering performance. ~12K QA instances in English and 5K in each other language in SQuAD format in seven languages - English, Arabic, German, Spanish, Hindi, Vietnamese and Simplified Chinese.")|46,444|JSON|[2019](https://arxiv.org/abs/1910.07475)|Multi-Lingual|<a target="_blank" href="https://paperswithcode.com/paper/mlqa-evaluating-cross-lingual-extractive" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=mlqa" title="Open in Huggingface" target="_blank">ð¤</a>|
|[XQuAD](https://github.com/deepmind/xquad "Dataset consists of a subset of 240 context paragraphs and 1,190 question-answer pairs from the development set of SQuAD v1.1  with their translations in 10 languages: Spanish, German, Greek, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese, and Hindi.")|1,190Â |JSON|[2019](https://arxiv.org/abs/1910.11856)|Multi-Lingual|<a target="_blank" href="https://paperswithcode.com/paper/on-the-cross-lingual-transferability-of" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=xquad" title="Open in Huggingface" target="_blank">ð¤</a>|
|[OpenKeyPhrase (OpenKP)](https://microsoft.github.io/msmarco/ "Open domain keyphrase extraction dataset containing 148,124 real world web documents along with a human annotation indicating the 1-3 most relevant keyphrases.")|148,124|JSON|[2019](https://arxiv.org/abs/1911.02671)|English|<a target="_blank" href="https://paperswithcode.com/paper/open-domain-web-keyphrase-extraction-beyond-1" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=ms_marco" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Physical IQA](https://leaderboard.allenai.org/physicaliqa/submissions/get-started "Dataset is used for commonsense QA benchmark for naive physics reasoning focusing on how we interact with everyday objects in everyday situations. The dataset includes 20,000 QA pairs that are either multiple-choice or true/false questions.")|20k|JSON|[2019](https://arxiv.org/abs/1911.11641)|English|<a target="_blank" href="https://paperswithcode.com/paper/piqa-reasoning-about-physical-commonsense-in" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[SberQuAD](https://github.com/sberbank-ai/data-science-journey-2017 "Dataset consists of a question answers modeleld after SQuAD.")|50,364|CSV|[2019](https://arxiv.org/abs/1912.09723)|Russian|<a target="_blank" href="https://paperswithcode.com/paper/sberquad-russian-reading-comprehension" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[EventQA](https://github.com/tarcisiosouza/Event-QA "A dataset for answering Event-Centric questions over Knowledge Graphs (KGs). It contains 1,000 semantic queries and the corresponding verbalisations.")|1k|JSON|[2019](https://arxiv.org/abs/2004.11861)|English|<a target="_blank" href="https://paperswithcode.com/paper/event-qa-a-dataset-for-event-centric-question" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Delta Reading Comprehension Dataset](https://github.com/DRCKnowledgeTeam/DRCD "Dataset organizes 10,014 paragraphs from 2,108 wiki entries and highlights more than 30,000 questions from the paragraphs.")|10,014|JSON|[2019](https://arxiv.org/ftp/arxiv/papers/1806/1806.00920.pdf)|Chinese||
|[KorQuAD](https://korquad.github.io/ "Dataset containing a total of 100,000+ question answer pairs.")|102,960|JSON|[2019](https://arxiv.org/ftp/arxiv/papers/1909/1909.07005.pdf)|Korean||
|[Natural Questions (NQ)](https://ai.google.com/research/NaturalQuestions "Dataset contains questions from real users, and it requires QA systems to read and comprehend an entire Wikipedia article that may or may not contain the answer to the question.")|320,000+|HTML|[2019](https://persagen.com/files/misc/kwiatkowski2019natural.pdf)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=natural_questions" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Complex Factoid Question Answering with Paraphrase Clusters (ComQA)](http://qa.mpi-inf.mpg.de/comqa/ "The dataset contains questions with various challenging phenomena such as the need forÂ temporal reasoning, comparison (e.g., comparatives, superlatives, ordinals), compositionality (multiple, possibly nested, subquestions with multiple entities), and unanswerable questions.")|11,214|JSON|[2019](https://www.aclweb.org/anthology/N19-1027.pdf)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=com_qa" title="Open in Huggingface" target="_blank">ð¤</a>|
|[FreebaseQA](https://github.com/kelvin-jiang/FreebaseQA "Dataset contains 28,348 unique questions for open domain QA over the Freebase knowledge graph.")|28,348|JSON|[2019](https://www.aclweb.org/anthology/N19-1028.pdf)|English||
|[Vietnamese Question Answering Dataset (ViQuAD)](https://sites.google.com/uit.edu.vn/uit-nlp/datasets-projects "Dataset comprises over 23,000 human-generated question-answer pairs based on 5,109 passages of 174 Vietnamese articles from Wikipedia. [REQUIRES GETTING AUTHOR PERMISSION]")|23k|-|[2020]()|Vietnamese||
|[Worldtree Corpus](http://cognitiveai.org/explanationbank/ "Dataset contains multi-hop question answering/explanations where questions require combining between 1 and 16 facts (average 6) to generate detailed explanations for question answering inference. Each explanation is represented as a lexically-connected âexplanation graphâ that combines an average of 6 facts drawn from a semi-structured knowledge base of 9,216 facts across 66 tables.")|5,114|Text, TSV|[2020](http://cognitiveai.org/wp-content/uploads/2020/05/xie_et_al_lrec2020_worldtree_v2_structured_explanations_and_inference_patterns_multihop_inference.pdf)|English||
|[DoQa](http://ixa.eus/node/12931 "Dataset contains domain specific FAQs via conversational QA that contains 2,437 information-seeking question/answer dialogues (10,917 questions in total) on three different domains: cooking, travel and movies.")|10,917|JSON|[2020](http://ixa.eus/sites/default/files/dokumentuak/13030/DoQA_cameraready.pdf)|English||
|[ManyModalQA](https://github.com/hannandarryl/ManyModalQA "Dataset contains 10,190 questions, 2,873 images, 3,789 text, and 3,528 tables scraped from Wikipedia.")|10,190|JSON, PNG|[2020](https://aaai.org/Papers/AAAI/2020GB/AAAI-HannanD.8768.pdf)|English||
|[TyDi QA](https://github.com/google-research-datasets/tydiqa "TyDi QA includes question-answer pairs from 11 languages: Arabic, Bengali, English, Finnish, Indonesian, Kiswahili, Russian. Japanese, Korean, Thai, and Telugu.")|204k|JSON|[2020](https://ai.googleblog.com/2020/02/tydi-qa-multilingual-question-answering.html)|Multi-Lingual|<a href="https://huggingface.co/nlp/viewer/?dataset=tydiqa" title="Open in Huggingface" target="_blank">ð¤</a>|
|[C3](https://github.com/nlpdata/c3 "Dataset is first free-form multipleChoice Chinese machine reading Comprehension dataset (C3), containing 13,369 documents (dialogues or more formally written mixed-genre texts) and their associated 19,577 multiple-choice free-form questions collected from Chinese-as-a-second language examinations.")|13,369|JSON|[2020](https://arxiv.org/abs/1904.09679)|Chinese|<a target="_blank" href="https://paperswithcode.com/paper/probing-prior-knowledge-needed-in-challenging" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[QASC](https://leaderboard.allenai.org/qasc/submissions/get-started "QASC is a question-answering dataset with a focus on sentence composition. It consists of 9,980 8-way multiple-choice questions about grade school science (8,134 train, 926 dev, 920 test), and comes with a corpus of 17M sentences.")|9,980|JSON|[2020](https://arxiv.org/abs/1910.11473)|English|<a target="_blank" href="https://paperswithcode.com/paper/qasc-a-dataset-for-question-answering-via" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=qasc" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Vietnamese Multiple-choice Machine Reading Comprehension Corpus (ViMMRC)](https://sites.google.com/uit.edu.vn/uit-nlp/datasets-projects "Dataset contains 2,783 multiple-choice questions and answers based on a set of 417 Vietnamese texts used for teaching reading comprehension for 1st to 5th graders. [requires contacting author for corpus]")|417|-|[2020](https://arxiv.org/abs/2001.05687)|Vietnamese|<a target="_blank" href="https://paperswithcode.com/paper/a-pilot-study-on-multiple-choice-machine" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[FQuAD](https://fquad.illuin.tech/ "Dataset contains 25,000+ questions on a set of Wikipedia articles, modeled after SQuAD.")|25,000+|JSON|[2020](https://arxiv.org/abs/2002.06071)|French|<a target="_blank" href="https://paperswithcode.com/paper/fquad-french-question-answering-dataset" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=fquad" title="Open in Huggingface" target="_blank">ð¤</a>|
|[HybridQA](https://github.com/wenhuchen/HybridQA "Dataset contains over 70K question-answer pairs based on 13,000 tables, each table is in average linked to 44 passages.")|70k|JSON|[2020](https://arxiv.org/abs/2004.07347)|English|<a target="_blank" href="https://paperswithcode.com/paper/hybridqa-a-dataset-of-multi-hop-question" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[AmbigNQ](https://nlp.cs.washington.edu/ambigqa/ "Dataset covering 14,042 questions from NQ-open, an existing open-domain QA benchmark.")|14,042|JSON|[2020](https://arxiv.org/abs/2004.10645)|English|<a target="_blank" href="https://paperswithcode.com/paper/ambigqa-answering-ambiguous-open-domain" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[OneStopQA](https://github.com/berzak/onestop-qa "Dataset comprises 30 articles from the Guardian in 3 parallel text difficulty versions and contains 1,458 paragraph-question pairs with multiple choice questions, along with manual span markings for both correct and incorrect answers.")|30|Text|[2020](https://arxiv.org/abs/2004.14797)|English|<a target="_blank" href="https://paperswithcode.com/paper/starc-structured-annotations-for-reading" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[DramaQA](https://dramaqa.snu.ac.kr/Dataset "Dataset contains 16,191 question answer pairs from 23,928 various length video clips, with each question answer pair belonging to one of four difficulty levels.")|23,928|JSON|[2020](https://arxiv.org/abs/2005.03356)|English|<a target="_blank" href="https://paperswithcode.com/paper/dramaqa-character-centered-video-story" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[RuBQ](https://github.com/vladislavneon/RuBQ "Dataset consists of 1,500 Russian questions of varying complexity, their English machine translations, SPARQL queries to Wikidata, reference answers, as well as a Wikidata sample of triples containing entities with Russian labels.")|1,500|JSON|[2020](https://arxiv.org/abs/2005.10659)|Russian|<a target="_blank" href="https://paperswithcode.com/paper/rubq-a-russian-dataset-for-question-answering" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[LogiQA](https://github.com/lgw863/LogiQA-dataset "Dataset consists of 8,678 QA instances, covering multiple types of deductive reasoning. Multiple-choice.")|8,678|Text|[2020](https://arxiv.org/abs/2007.08124)|English|<a target="_blank" href="https://paperswithcode.com/paper/logiqa-a-challenge-dataset-for-machine" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Multilingual Knowledge Questions & Answers (MKQA)](https://github.com/apple/ml-mkqa/ "Dataset is an open-domain question answering evaluation set comprising 10k question-answer pairs aligned across 26 typologically diverse languages (260k question-answer pairs in total).")|10k|JSON|[2020](https://arxiv.org/abs/2007.15207)|Multi-Lingual|<a target="_blank" href="https://paperswithcode.com/paper/mkqa-a-linguistically-diverse-benchmark-for" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[QED](https://github.com/google-research-datasets/QED "Given a question and a passage, QED represents an explanation of the answer as a combination of discrete, human-interpretable steps: sentence selection, referential equality, and predicate entailment. Dataset was built as a subset of the Natural Questions dataset.")|8,993|JSON|[2020](https://arxiv.org/abs/2009.06354)|English|<a target="_blank" href="https://paperswithcode.com/paper/qed-a-framework-and-dataset-for-explanations" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[LiveQA](https://github.com/PKU-TANGENT/GAReader-LiveQA "Dataset was constructed from play-by-play live broadcast. It contains 117k multiple-choice questions written by human commentators for over 1,670 NBA games, which are collected from the Chinese Hupu1 website.")|117k|JSON|[2020](https://arxiv.org/abs/2010.00526)|Chinese|<a target="_blank" href="https://paperswithcode.com/paper/liveqa-a-question-answering-dataset-over" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Compositional Freebase Questions (CFQ)](https://github.com/google-research/google-research/tree/master/cfq "Dataset contains questions and answers that also provides for each question a corresponding SPARQL query against the Freebase knowledge base.")|239,357|JSON|[2020](https://openreview.net/pdf?id=SygcCnNKwr)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=cfq" title="Open in Huggingface" target="_blank">ð¤</a>|
|[VQA-Introspect](https://www.microsoft.com/en-us/research/project/vqa-introspect/ "Dataset consists of 238K new perception questions from the VQA dataset which serve as sub questions corresponding to the set of perceptual tasks needed to answer complex reasoning questions.")|238k|JSON|[2020](https://www.microsoft.com/en-us/research/uploads/prod/2020/06/SQuINT_CVPR.pdf)|English||

## Question Clarification

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[ClariQ](https://github.com/aliannejadi/ClariQ "Dataset consists of single-turn conversations (initial_request, followed by clarifying question and answer). In addition, it comes with synthetic multi-turn conversations (up to three turns). ClariQ features approximately 18K single-turn conversations, as well as 1.8 million multi-turn conversations.")|1.8M|TSV, JSON|[2020](https://arxiv.org/abs/2009.11352)|English|<a target="_blank" href="https://paperswithcode.com/paper/convai3-generating-clarifying-questions-for" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Question Generation

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Inquisitive](https://github.com/wjko2/inquisitive "Dataset contains â¼19K questions that are elicited while a person is reading through a document. Compared to existing datasets, INQUISITIVE questions target more towards high-level (semantic and discourse) comprehension of text.")|19k|Text|[2020](https://arxiv.org/abs/2010.01657)|English|<a target="_blank" href="https://paperswithcode.com/paper/inquisitive-question-generation-for-high" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Reading Comprehension

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[TrecQA](https://github.com/castorini/data/tree/master/TrecQA/data "Dataset is commonly used for evaluating answer selection in question answering.")|-|XML|[2007](https://www.aclweb.org/anthology/D07-1003.pdf)|English||
|[Dataset for the Machine Comprehension of Text](https://github.com/mcobzarenco/mctest/tree/master/data/MCTest "Stories and associated questions for testing comprehension of text.")|660|Text|[2013](https://www.aclweb.org/anthology/D13-1020.pdf)|English||
|[Jeapardy Questions Answers](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/ "Dataset contains Jeopardy questions, answers and other data.")|216,930|JSON|[2014](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=jeopardy" title="Open in Huggingface" target="_blank">ð¤</a>|
|[bAbI 20 Tasks](https://research.fb.com/downloads/babi/ "Dataset cotains a set of contexts, with multiple question-answer pairs available based on the contexts.")|2k|Text|[2015](https://arxiv.org/abs/1502.05698)|Hindi, English|<a target="_blank" href="https://paperswithcode.com/paper/towards-ai-complete-question-answering-a-set" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[The SimpleQuestions Dataset](https://research.fb.com/downloads/babi/ "Dataset for question answering with human generated questions paired with a corresponding fact, formatted as (subject, relationship, object), that provides the answer but also a complete explanation.")|108,442|Text|[2015](https://arxiv.org/abs/1506.02075)|English|<a target="_blank" href="https://paperswithcode.com/paper/large-scale-simple-question-answering-with" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[CNN / Daily Mail Dataset](https://cs.nyu.edu/~kcho/DMQA/ "Cloze-style reading comprehension dataset created from CNN and Daily Mail news articles.")|1M+|Question|[2015](https://arxiv.org/abs/1506.03340)|English|<a target="_blank" href="https://paperswithcode.com/paper/teaching-machines-to-read-and-comprehend" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=cnn_dailymail" title="Open in Huggingface" target="_blank">ð¤</a>|
|[InsuranceQA](https://github.com/shuzi/insuranceQA "Dataset contains questions and answers collected from the websiteÂ Insurance Library. It consists of questions from real world users, the answers with high quality were composed by professionals with deep domain knowledge. There are 16,889 questions in total.")|16,889|-|[2015](https://arxiv.org/abs/1508.01585)|English|<a target="_blank" href="https://paperswithcode.com/paper/applying-deep-learning-to-answer-selection-a" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[WikiQA Corpus](https://www.microsoft.com/en-us/download/details.aspx?id=52419 "Dataset contains Bing query logs as the question source. Each question is linked to a Wikipedia page that potentially has the answer.Â ")|3,047|TSV|[2015](https://www.aclweb.org/anthology/D15-1237.pdf)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=wiki_qa" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Urban DictionaryÂ Dataset](https://www.kaggle.com/therohk/urban-dictionary-words-dataset "Corpus of words, votes and definitions.")|2,606,522|CSV|[2016-05](https://www.kaggle.com/therohk/urban-dictionary-words-dataset)|English||
|[The Dialog-based Language Learning Dataset](https://research.fb.com/downloads/babi/ "Dataset was designed to measure how well models can perform at learning as a student given a teacherâs textual responses to the studentâs answer.")|-|Text|[2016](https://arxiv.org/abs/1604.06045)|English|<a target="_blank" href="https://paperswithcode.com/paper/dialog-based-language-learning" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[The WikiMovies Dataset](https://research.fb.com/downloads/babi/ "Dataset contains only the QA part of the Movie Dialog dataset, but using three different settings of knowledge: using a traditional knowledge base (KB), using Wikipedia as the source of knowledge, or using IE (information extraction) over Wikipedia.")|~100,000|Text|[2016](https://arxiv.org/abs/1606.03126)|English|<a target="_blank" href="https://paperswithcode.com/paper/key-value-memory-networks-for-directly" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[SelQA](https://github.com/emorynlp/selqa "Dataset provides crowdsourced annotation for two selection-based question answer tasks, answer sentence selection and answer triggering. Our dataset composes about 8K factoid questions for the top-10 most prevalent topics among Wikipedia articles.")|8k|JSON, TSV|[2016](https://arxiv.org/abs/1606.08513)|English|<a target="_blank" href="https://paperswithcode.com/paper/selqa-a-new-benchmark-for-selection-based" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Who Did What Dataset](https://tticnlp.github.io/who_did_what/download.html "Dataset contains over 200,000 fill-in-the-gap (cloze) multiple choice reading comprehension problems constructed from the LDC English Gigaword newswire corpus.")|200,000K|XML|[2016](https://arxiv.org/abs/1608.05457)|English|<a target="_blank" href="https://paperswithcode.com/paper/who-did-what-a-large-scale-person-centered" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Microsoft Machine Reading COmprehension Dataset (MS MARCO)](https://microsoft.github.io/msmarco/ "Dataset focused on machine reading comprehension, question answering, and passage ranking, keyphrase extraction, and conversational search studies.")|1,010,916|JSON|[2016](https://arxiv.org/abs/1611.09268)|English|<a target="_blank" href="https://paperswithcode.com/paper/ms-marco-a-human-generated-machine-reading" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=ms_marco" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Human-in-the-loop Dialogue Simulator (HITL)](https://research.fb.com/downloads/babi/ "Dataset provides a framework for evaluating a botâs ability to learn to improve its performance in an online setting using feedback from its dialog partner. The dataset contains questions based on the bAbI and WikiMovies datasets, with the addition of feedback from the dialog partner.")|-|Text|[2016](https://arxiv.org/abs/1611.09823)|English|<a target="_blank" href="https://paperswithcode.com/paper/dialogue-learning-with-human-in-the-loop" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Explanations for Science Questions](http://ai2-website.s3.amazonaws.com/data/COLING2016_Explanations_Oct2016.zip "Data contains: gold explanation sentences supporting 363 science questions, relation annotation for a subset of those explanations, and a graphical annotation tool with annotation guidelines.")|1,363|CSV|[2016](https://pdfs.semanticscholar.org/04d7/b7851683809cab561d09b5c5c80bd5c33c80.pdf?_ga=2.42297447.354477249.1582324561-958501894.1582324561)|English||
|[Childrenâs Book Test (CBT)](https://research.fb.com/downloads/babi/ "Dataset contains âquestionsâ from chapters in the book by enumerating 21 consecutive sentences. In each question, the first 20 sentences form the context, and a word is removed from the 21st sentence, which becomes the query. Models must identify the answer word among a selection of 10 candidate answers appearing in the context sentences and the query.")|~688,000|Text|[2016](https://research.fb.com/wp-content/uploads/2016/11/the_goldilocks_principle_reading_children_s_books_with_explicit_memory_representations.pdf?)|English||
|[The Movie Dialog Dataset](https://research.fb.com/downloads/babi/ "Dataset measures how well models can perform at goal and non-goal orientated dialogue centered around the topic of movies (question answering, recommendation and discussion).")|~3.5M|Text|[2016](https://www.aclweb.org/anthology/I17-1099.pdf)|English||
|[SemEvalCQA](http://alt.qcri.org/semeval2016/task3/index.php?id=data-and-tools "Dataset for community question answering.")|-|XML|[2016](https://www.aclweb.org/anthology/S16-1083.pdf)|Arabic, English||
|[AI2 Science Questions v2.1](http://data.allenai.org/ai2-science-questions/ "Dataset consists of questions used in student assessments in the United States across elementary and middle school grade levels. Each question is 4-way multiple choice format and may or may not include a diagram element.")|5,060|JSON, CSV|[2017]()|English|<a href="https://huggingface.co/nlp/viewer/?dataset=ai2_arc" title="Open in Huggingface" target="_blank">ð¤</a>|
|[AI2 Science Questions Mercury](http://data.allenai.org/ai2-science-questions-mercury/ "Dataset consists of questions used in student assessments across elementary and middle school grade levels. Includes questions with diagrams and without.")|6,940|JSON, JPG|[2017]()|English||
|[Textbook Question Answering](http://data.allenai.org/tqa/ "The M3C task builds on the popular Visual Question Answering (VQA) and Machine Comprehension (MC) paradigms by framing question answering as a machine comprehension task, where the context needed to answer questions is provided and composed of both text and images.")|26,620|JSON, PNG|[2017](http://ai2-website.s3.amazonaws.com/publications/CVPR17_TQA.pdf)|English||
|[NewsQA](https://github.com/Maluuba/newsqa "Crowdworkers supply questions and answers based on a set of over 10,000 news articles from CNN.")|12,744|JSON, CSV|[2017](https://arxiv.org/abs/1611.09830)|English|<a target="_blank" href="https://paperswithcode.com/paper/newsqa-a-machine-comprehension-dataset" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[ReAding Comprehension Dataset From Examinations (RACE)](http://www.cs.cmu.edu/~glai1/data/race/ "Dataset was collected from the English exams evaluating the students' ability in understanding and reasoning.")|28k|JSON|[2017](https://arxiv.org/abs/1704.04683)|English|<a target="_blank" href="https://paperswithcode.com/paper/race-large-scale-reading-comprehension" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=race" title="Open in Huggingface" target="_blank">ð¤</a>|
|[SearchQA](https://github.com/nyu-dl/dl4ir-searchqA "Dataset from Jeapardy archives which consists of more than 140k question-answer pairs with each pair having 49.6 snippets on average.")|140k|JSON|[2017](https://arxiv.org/abs/1704.05179)|English|<a target="_blank" href="https://paperswithcode.com/paper/searchqa-a-new-qa-dataset-augmented-with" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=search_qa" title="Open in Huggingface" target="_blank">ð¤</a>|
|[TriviaQA](http://nlp.cs.washington.edu/triviaqa/ "Dataset containing over 650K question-answer-evidence triples. It includes 95K QA pairs authored by trivia enthusiasts and independently gathered evidence documents, 6 per question on average.")|650,000+|JSON|[2017](https://arxiv.org/abs/1705.03551)|English|<a target="_blank" href="https://paperswithcode.com/paper/triviaqa-a-large-scale-distantly-supervised" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=trivia_qa" title="Open in Huggingface" target="_blank">ð¤</a>|
|[AQuA](https://github.com/deepmind/AQuA "Dataset containing algebraic word problems with rationales for their answers.")|100k|JSON|[2017](https://arxiv.org/abs/1705.04146)|English|<a target="_blank" href="https://paperswithcode.com/paper/program-induction-by-rationale-generation" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Quasar-S & T](http://curtis.ml.cmu.edu/datasets/quasar/ "The Quasar-S dataset consists of 37,000 cloze-style queries constructed from definitions of software entity tags on the popular website Stack Overflow. The Quasar-T dataset consists of 43,000 open-domain trivia questions and their answers obtained from various internet sources.")|80k|JSON|[2017](https://arxiv.org/abs/1707.03904)|English|<a target="_blank" href="https://paperswithcode.com/paper/quasar-datasets-for-question-answering-by" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[SciQ Dataset](http://data.allenai.org/sciq/ "Dataset contains 13,679 crowdsourced science exam questions about Physics, Chemistry and Biology, among others. The questions are in multiple-choice format with 4 answer options each.")|13,769|JSON|[2017](https://arxiv.org/abs/1707.06209)|English|<a target="_blank" href="https://paperswithcode.com/paper/crowdsourcing-multiple-choice-science" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=sciq" title="Open in Huggingface" target="_blank">ð¤</a>|
|[NarrativeQA](https://github.com/deepmind/narrativeqa "Dataset contains the list of documents with Wikipedia summaries, links to full stories, and questions and answers.")|1,572|CSV|[2017](https://arxiv.org/abs/1712.07040)|English|<a target="_blank" href="https://paperswithcode.com/paper/the-narrativeqa-reading-comprehension" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[The Story Cloze Test : ROCStories](https://cs.rochester.edu/nlp/rocstories/ "Dataset for story understanding that provides systems with four-sentence stories and two possible endings. The systems must then choose the correct ending to the story.")|100,000+|JSON|[2017](https://www.cs.rochester.edu/~nasrinm/files/Papers/lsdsem17-shared-task.pdf)|English||
|[SQuAD-it](https://github.com/crux82/squad-it "The dataset contains more than 60,000 question/answer pairs in Italian derived from the original English SQuAD dataset.")|60,000+|JSON|[2018](http://ceur-ws.org/Vol-2481/paper25.pdf)|Italian|<a href="https://huggingface.co/nlp/viewer/?dataset=squad_it" title="Open in Huggingface" target="_blank">ð¤</a>|
|[DuReader](http://ai.baidu.com/broad/download?dataset=dureader "DuReader version 2.0 contains more than 300K question, 1.4M evidence documents and 660K human generated answers.")|1,431,429|JSON|[2018](https://arxiv.org/abs/1711.05073)|Mandarin|<a target="_blank" href="https://paperswithcode.com/paper/dureader-a-chinese-machine-reading" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[AI2 Reasoning Challenge (ARC)](http://data.allenai.org/arc/ "Dataset contains 7,787 genuine grade-school level, multiple-choice science questions.")|7,787|JSON, CSV|[2018](https://arxiv.org/abs/1803.05457)|English|<a target="_blank" href="https://paperswithcode.com/paper/think-you-have-solved-question-answering-try" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[ComplexWebQuestions](https://www.tau-nlp.org/compwebq "Dataset contains a large set of complex questions in natural language, and can be used in multiple ways.")|34,689|JSON|[2018](https://arxiv.org/abs/1803.06643)|English|<a target="_blank" href="https://paperswithcode.com/paper/the-web-as-a-knowledge-base-for-answering" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Clinical Case Reports for Machine Reading Comprehension (CliCR)](https://github.com/clips/clicr "Dataset was built from clinical case reports, requiring the reader to answer the query with a medical problem/test/treatment entity.")|100k|JSON|[2018](https://arxiv.org/abs/1803.09720)|English|<a target="_blank" href="https://paperswithcode.com/paper/clicr-a-dataset-of-clinical-case-reports-for" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[ProPara Dataset](http://data.allenai.org/propara/ "Dataset is used for comprehension of simple paragraphs describing processes, e.g., photosynthesis. The comprehension task relies on predicting, tracking, and answering questions about how entities change during the process.")|488Â |Google Sheets|[2018](https://arxiv.org/abs/1805.06975)|English|<a target="_blank" href="https://paperswithcode.com/paper/tracking-state-changes-in-procedural-text-a" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[SQuAD v2.0](https://rajpurkar.github.io/SQuAD-explorer/ "Paragraphs w/ questions and answers.")|150k|JSON|[2018](https://arxiv.org/abs/1806.03822)|English|<a target="_blank" href="https://paperswithcode.com/paper/know-what-you-dont-know-unanswerable" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=squad" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Situations With Adversarial Generations (SWAG)](https://rowanzellers.com/swag/ "Dataset consists of 113k multiple choice questions about groundedÂ situations. Each question is a video caption fromÂ LSMDCÂ orÂ ActivityNet Captions, with four answer choices about what might happen next in the scene.")|113k|CSV|[2018](https://arxiv.org/abs/1808.05326)|English|<a target="_blank" href="https://paperswithcode.com/paper/swag-a-large-scale-adversarial-dataset-for" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Question Answering in Context (QuAC)](http://quac.ai/ "Dataset for modeling, understanding, and participating in information seeking dialog.")|14k|JSON|[2018](https://arxiv.org/abs/1808.07036)|English|<a target="_blank" href="https://paperswithcode.com/paper/quac-question-answering-in-context" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[emrQA](https://github.com/panushri25/emrQA "Dataset contains 1M question-logical form and 400,000+ question answer evidence pairs on electronic medical records. In total, there are 2,495 clinical notes.")|2,495|CSV|[2018](https://arxiv.org/abs/1809.00732)|English|<a target="_blank" href="https://paperswithcode.com/paper/emrqa-a-large-corpus-for-question-answering" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[OpenBookQA](https://leaderboard.allenai.org/open_book_qa/submissions/get-started "Dataset modeled after open book exams for assessing human understanding of a subject. It consists of 5,957 multiple-choice elementary-level science questions (4,957 train, 500 dev, 500 test), which probe the understanding of a small "book" of 1,326 core science facts and the application of these facts to novel situations.")|5,957|JSON|[2018](https://arxiv.org/abs/1809.02789)|English|<a target="_blank" href="https://paperswithcode.com/paper/can-a-suit-of-armor-conduct-electricity-a-new" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=openbookqa" title="Open in Huggingface" target="_blank">ð¤</a>|
|[HotpotQA](https://hotpotqa.github.io/ "Dataset featuring natural, multi-hop questions, with strong supervision for supporting facts to enable more explainable question answering systems.")|1.25M|JSON|[2018](https://arxiv.org/abs/1809.09600)|English|<a target="_blank" href="https://paperswithcode.com/paper/hotpotqa-a-dataset-for-diverse-explainable" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=hotpot_qa" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Chinese Machine Reading Comprehension (CMRC 2018)](https://github.com/ymcui/cmrc2018 "Dataset is composed by near 20,000 real questions annotated on Wikipedia paragraphs by human experts.")|20k|JSON|[2018](https://arxiv.org/abs/1810.07366)|Chinese|<a target="_blank" href="https://paperswithcode.com/paper/a-span-extraction-dataset-for-chinese-machine" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=cmrc2018" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Reading Comprehension with Commonsense Reasoning Dataset (Record)](https://sheng-z.github.io/ReCoRD-explorer/ "Reading comprehension dataset which requires commonsense reasoning. Contains 120,000+ queries from 70,000+ news articles.")|70,000+|JSON|[2018](https://arxiv.org/abs/1810.12885)|English|<a target="_blank" href="https://paperswithcode.com/paper/record-bridging-the-gap-between-human-and" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[CommonsenseQA](https://www.tau-nlp.org/commonsenseqa "Dataset contains multiple-choice question answering dataset that requires different types of commonsense knowledge to predict the correct answers . It contains 12,102 questions with one correct answer and four distractor answers.")|12,012|JSON|[2018](https://arxiv.org/abs/1811.00937)|English|<a target="_blank" href="https://paperswithcode.com/paper/commonsenseqa-a-question-answering-challenge" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=commonsense_qa" title="Open in Huggingface" target="_blank">ð¤</a>|
|[QuaRel Dataset](http://data.allenai.org/quarel/ "Dataset contains 2,771 story questions about qualitative relationships.")|2,771|JSON|[2018](https://arxiv.org/abs/1811.08048)|English|<a target="_blank" href="https://paperswithcode.com/paper/quarel-a-dataset-and-models-for-answering" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=quarel" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Reading Comprehension with Multiple Hops (Qangaroo)](http://qangaroo.cs.ucl.ac.uk/index.html "Reading Comprehension datasets focussing on multi-hop (alias multi-step) inference. There are 2 datasets: Wikihop (based on wikipedia) and Medhop (based on PubMed research papers).")|~53,000|JSON|[2018](https://transacl.org/ojs/index.php/tacl/article/viewFile/1325/299)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=qangaroo" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Multimodal Comprehension of Cooking Recipes (RecipeQA)](https://hucvl.github.io/recipeqa/ "Dataset for multimodal comprehension of cooking recipes. It consists of over 36K question-answer pairs automatically generated from approximately 20K unique recipes with step-by-step instructions and images.")|20k|JSON|[2018](https://www.aclweb.org/anthology/D18-1166.pdf)|English||
|[Shaping Answers with Rules through Conversation (ShARC)](https://sharc-data.github.io/ "ShARC is a Conversational Question Answering dataset focussing on question answering from texts containing rules.")|32k|JSON|[2018](https://www.aclweb.org/anthology/D18-1233.pdf)|English||
|[Reading Comprehension over Multiple Sentences (MultiRC)](https://cogcomp.seas.upenn.edu/multirc/ "Dataset of short paragraphs and multi-sentence questions that can be answered from the content of the paragraph.")|~10,000|JSON|[2018](https://www.aclweb.org/anthology/N18-1023.pdf)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=eraser_multi_rc" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Portuguese SQuAD v1.1](https://github.com/nunorc/squad-v1.1-pt "Portuguese translation of theÂ SQuADÂ dataset. The translation was performed using the Google Cloud API.")|~100,000|JSON|[2019]()|Portuguese|<a href="https://huggingface.co/nlp/viewer/?dataset=squad_v1_pt" title="Open in Huggingface" target="_blank">ð¤</a>|
|[A Conversational Question Answering Challenge (CoQA)](https://stanfordnlp.github.io/coqa/ "Dataset for measuring the ability of machines to understand a text passage and answer a series of interconnected questions that appear in a conversation.")|127,000+|JSON|[2019](https://arxiv.org/abs/1808.07042)|English|<a target="_blank" href="https://paperswithcode.com/paper/coqa-a-conversational-question-answering" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=coqa" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Dialogue-Based Reading Comprehension Examination (DREAM)](https://dataset.org/dream/ "Dataset contains 10,197 multiple choice questions for 6,444 dialogues, collected from English-as-a-foreign-language examinations designed by human experts. DREAM is likely to present significant challenges for existing reading comprehension systems: 84% of answers are non-extractive, 85% of questions require reasoning beyond a single sentence, and 34% of questions also involve commonsense knowledge.")|6,444|JSON|[2019](https://arxiv.org/abs/1902.00164)|English|<a target="_blank" href="https://paperswithcode.com/paper/dream-a-challenge-dataset-and-models-for" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs (DROP)](https://allennlp.org/drop "Dataset is used to resolve references in a question, perhaps to multiple input positions, and perform discrete operations over them (such as addition, counting, or sorting).")|96k|JSON|[2019](https://arxiv.org/abs/1903.00161)|English|<a target="_blank" href="https://paperswithcode.com/paper/drop-a-reading-comprehension-benchmark" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=drop" title="Open in Huggingface" target="_blank">ð¤</a>|
|[COmmonsense Dataset Adversarially-authored by Humans (CODAH)](https://github.com/Websail-NU/CODAH "Commonsense QA in the sentence completion style of SWAG. As opposed to other automatically generated NLI datasets, CODAH is adversarially constructed by humans who can view feedback from a pre-trained model and use this information to design challenging commonsense questions.")|2,776|TSV|[2019](https://arxiv.org/abs/1904.04365)|English|<a target="_blank" href="https://paperswithcode.com/paper/aqua-an-adversarially-authored-question" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[MathQA](https://math-qa.github.io/math-QA/ "Dataset contains English multiple-choice math word problems covering multiple math domain categories by modeling operation programs corresponding to word problems in the AQuA dataset.")|37k|JSON|[2019](https://arxiv.org/abs/1905.13319)|English|<a target="_blank" href="https://paperswithcode.com/paper/mathqa-towards-interpretable-math-word" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=math_qa" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Arabic Reading Comprehension Dataset (ARCD)](https://github.com/husseinmozannar/SOQAL "Dataset contains 1,395 questions posed by crowdworkers on Wikipedia articles, and a machine translation of the Stanford Question Answering Dataset (Arabic-SQuAD) containing 48,344 questions.")|~50,000|JSON|[2019](https://arxiv.org/abs/1906.05394)|Arabic|<a target="_blank" href="https://paperswithcode.com/paper/neural-arabic-question-answering" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=arcd" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Explain Like Iâm Five (ELI5)](https://github.com/facebookresearch/ELI5 "The dataset contains 270K threads of open-ended questions that require multi-sentence answers. It was extracted from subreddit titled âExplain Like Iâm Fiveâ (ELI5), in which an online community answers questions with responses that 5-year-olds can comprehend. Facebook scripts allow you to preprocess data.")|270k|Text|[2019](https://arxiv.org/abs/1907.09190)|English|<a target="_blank" href="https://paperswithcode.com/paper/eli5-long-form-question-answering" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=eli5" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Quoref](https://leaderboard.allenai.org/quoref/submissions/get-started "Dataset which tests the coreferential reasoning capability of reading comprehension systems. In this span-selection benchmark containing 24K questions over 4.7K paragraphs from Wikipedia, a system must resolve hard coreferences before selecting the appropriate span(s) in the paragraphs for answering questions.")|24k|JSON|[2019](https://arxiv.org/abs/1908.05803)|English|<a target="_blank" href="https://paperswithcode.com/paper/quoref-a-reading-comprehension-dataset-with" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=quoref" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Cosmos QA](https://github.com/wilburOne/cosmosqa/tree/master/data/ "Dataset containing thousands ofÂ problems that requireÂ commonsense-based reading comprehension, formulated asÂ multiple-choiceÂ questions.")|35k|CSV|[2019](https://arxiv.org/abs/1909.00277)|English|<a target="_blank" href="https://paperswithcode.com/paper/cosmos-qa-machine-reading-comprehension-with" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=cosmos_qa" title="Open in Huggingface" target="_blank">ð¤</a>|
|[QuaRTz Dataset](http://data.allenai.org/quartz/ "Dataset contains 3,864 questions about open domain qualitative relationships. Each question is paired with one of 405 different background sentences (sometimes short paragraphs).")|3,864|JSON|[2019](https://arxiv.org/abs/1909.03553)|English|<a target="_blank" href="https://paperswithcode.com/paper/quartz-an-open-domain-dataset-of-qualitative" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=quartz" title="Open in Huggingface" target="_blank">ð¤</a>|
|[MultiLingual Question Answering (MLQA)](https://github.com/facebookresearch/MLQA "Dataset for evaluating cross-lingual question answering performance. ~12K QA instances in English and 5K in each other language in SQuAD format in seven languages - English, Arabic, German, Spanish, Hindi, Vietnamese and Simplified Chinese.")|46,444|JSON|[2019](https://arxiv.org/abs/1910.07475)|Multi-Lingual|<a target="_blank" href="https://paperswithcode.com/paper/mlqa-evaluating-cross-lingual-extractive" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=mlqa" title="Open in Huggingface" target="_blank">ð¤</a>|
|[XQuAD](https://github.com/deepmind/xquad "Dataset consists of a subset of 240 context paragraphs and 1,190 question-answer pairs from the development set of SQuAD v1.1  with their translations in 10 languages: Spanish, German, Greek, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese, and Hindi.")|1,190Â |JSON|[2019](https://arxiv.org/abs/1910.11856)|Multi-Lingual|<a target="_blank" href="https://paperswithcode.com/paper/on-the-cross-lingual-transferability-of" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=xquad" title="Open in Huggingface" target="_blank">ð¤</a>|
|[OpenKeyPhrase (OpenKP)](https://microsoft.github.io/msmarco/ "Open domain keyphrase extraction dataset containing 148,124 real world web documents along with a human annotation indicating the 1-3 most relevant keyphrases.")|148,124|JSON|[2019](https://arxiv.org/abs/1911.02671)|English|<a target="_blank" href="https://paperswithcode.com/paper/open-domain-web-keyphrase-extraction-beyond-1" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=ms_marco" title="Open in Huggingface" target="_blank">ð¤</a>|
|[SberQuAD](https://github.com/sberbank-ai/data-science-journey-2017 "Dataset consists of a question answers modeleld after SQuAD.")|50,364|CSV|[2019](https://arxiv.org/abs/1912.09723)|Russian|<a target="_blank" href="https://paperswithcode.com/paper/sberquad-russian-reading-comprehension" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Delta Reading Comprehension Dataset](https://github.com/DRCKnowledgeTeam/DRCD "Dataset organizes 10,014 paragraphs from 2,108 wiki entries and highlights more than 30,000 questions from the paragraphs.")|10,014|JSON|[2019](https://arxiv.org/ftp/arxiv/papers/1806/1806.00920.pdf)|Chinese||
|[KorQuAD](https://korquad.github.io/ "Dataset containing a total of 100,000+ question answer pairs.")|102,960|JSON|[2019](https://arxiv.org/ftp/arxiv/papers/1909/1909.07005.pdf)|Korean||
|[Natural Questions (NQ)](https://ai.google.com/research/NaturalQuestions "Dataset contains questions from real users, and it requires QA systems to read and comprehend an entire Wikipedia article that may or may not contain the answer to the question.")|320,000+|HTML|[2019](https://persagen.com/files/misc/kwiatkowski2019natural.pdf)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=natural_questions" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Complex Factoid Question Answering with Paraphrase Clusters (ComQA)](http://qa.mpi-inf.mpg.de/comqa/ "The dataset contains questions with various challenging phenomena such as the need forÂ temporal reasoning, comparison (e.g., comparatives, superlatives, ordinals), compositionality (multiple, possibly nested, subquestions with multiple entities), and unanswerable questions.")|11,214|JSON|[2019](https://www.aclweb.org/anthology/N19-1027.pdf)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=com_qa" title="Open in Huggingface" target="_blank">ð¤</a>|
|[TyDi QA](https://github.com/google-research-datasets/tydiqa "TyDi QA includes question-answer pairs from 11 languages: Arabic, Bengali, English, Finnish, Indonesian, Kiswahili, Russian. Japanese, Korean, Thai, and Telugu.")|204k|JSON|[2020](https://ai.googleblog.com/2020/02/tydi-qa-multilingual-question-answering.html)|Multi-Lingual|<a href="https://huggingface.co/nlp/viewer/?dataset=tydiqa" title="Open in Huggingface" target="_blank">ð¤</a>|
|[QASC](https://leaderboard.allenai.org/qasc/submissions/get-started "QASC is a question-answering dataset with a focus on sentence composition. It consists of 9,980 8-way multiple-choice questions about grade school science (8,134 train, 926 dev, 920 test), and comes with a corpus of 17M sentences.")|9,980|JSON|[2020](https://arxiv.org/abs/1910.11473)|English|<a target="_blank" href="https://paperswithcode.com/paper/qasc-a-dataset-for-question-answering-via" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=qasc" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Vietnamese Multiple-choice Machine Reading Comprehension Corpus (ViMMRC)](https://sites.google.com/uit.edu.vn/uit-nlp/datasets-projects "Dataset contains 2,783 multiple-choice questions and answers based on a set of 417 Vietnamese texts used for teaching reading comprehension for 1st to 5th graders. [requires contacting author for corpus]")|417|-|[2020](https://arxiv.org/abs/2001.05687)|Vietnamese|<a target="_blank" href="https://paperswithcode.com/paper/a-pilot-study-on-multiple-choice-machine" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[FQuAD](https://fquad.illuin.tech/ "Dataset contains 25,000+ questions on a set of Wikipedia articles, modeled after SQuAD.")|25,000+|JSON|[2020](https://arxiv.org/abs/2002.06071)|French|<a target="_blank" href="https://paperswithcode.com/paper/fquad-french-question-answering-dataset" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=fquad" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Chinese Machine Reading Comprehension (CMRC)](https://github.com/ymcui/cmrc2019 "Dataset (cloze style) contains over 100K blanks (questions) within over 10K passages, which was originated from Chinese narrative stories.")|10,438|JSON|[2020](https://arxiv.org/abs/2004.03116)|Chinese|<a target="_blank" href="https://paperswithcode.com/paper/a-sentence-cloze-dataset-for-chinese-machine" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[AmbigNQ](https://nlp.cs.washington.edu/ambigqa/ "Dataset covering 14,042 questions from NQ-open, an existing open-domain QA benchmark.")|14,042|JSON|[2020](https://arxiv.org/abs/2004.10645)|English|<a target="_blank" href="https://paperswithcode.com/paper/ambigqa-answering-ambiguous-open-domain" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[OneStopQA](https://github.com/berzak/onestop-qa "Dataset comprises 30 articles from the Guardian in 3 parallel text difficulty versions and contains 1,458 paragraph-question pairs with multiple choice questions, along with manual span markings for both correct and incorrect answers.")|30|Text|[2020](https://arxiv.org/abs/2004.14797)|English|<a target="_blank" href="https://paperswithcode.com/paper/starc-structured-annotations-for-reading" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[LogiQA](https://github.com/lgw863/LogiQA-dataset "Dataset consists of 8,678 QA instances, covering multiple types of deductive reasoning. Multiple-choice.")|8,678|Text|[2020](https://arxiv.org/abs/2007.08124)|English|<a target="_blank" href="https://paperswithcode.com/paper/logiqa-a-challenge-dataset-for-machine" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[ReClor](http://whyu.me/reclor/ "Dataset contains logical reasoning questions of standardized graduate admission examinations.")|6,138|-|[2020](https://openreview.net/pdf?id=HJgJtT4tvB)|English||

## Regression

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[BlogFeedback Dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/00304/ "Dataset to predict the number of comments a post will receive based on features of that post.")|60,021|Text|[2014](http://www.cs.bme.hu/~buza/pdfs/gfkl2012_blogs.pdf)|English||

## Relation

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Genia](http://www.geniaproject.org/genia-corpus "Dataset contains 1,999 Medline abstracts, selected using a PubMed query for the three MeSH terms "human", "blood cells", and "transcription factors". The corpus has been annotated for part-of-speech, contituency syntactic, terms, events, relations, and coreference.")|1,999|Text, XML|[2003]()|English||

## Relation Extraction

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Gene-Disease Associations (GAD)](https://geneticassociationdb.nih.gov/ "Dataset is an archive of published genetic association studies that provides a comprehensive, public, web-based repository of molecular, clinical and study parameters for >5,000 human genetic association studies at this time.")|5k|Text, SQL|[2004](https://www.nature.com/articles/ng0504-431.pdf)|English||
|[SemEval2010 Task 8](https://github.com/sahitya0000/Relation-Classification/tree/master/corpus/SemEval2010_task8_training "Dataset consists of 8,000 sentences annotated for Cause-Effect , Instrument-Agency, Product-Producer, Content-Container, Entity-Origin, Entity-Destination, Component-Whole, Member-Collection, and Message-Topic. ")|8k|Text|[2010](https://www.aclweb.org/anthology/S10-1006.pdf)|English||
|[Relation Extraction Corpus](https://github.com/google-research-datasets/relation-extraction-corpus "A human-judged dataset of two relations involving public figures on Wikipedia: about 10,000 examples of "place of birth" and 40,000 examples of "attended or graduated from an institution."")|10k|JSON|[2013](https://ai.googleblog.com/2013/04/50000-lessons-on-how-to-read-relation.html)|English||
|[Drug-Disease Interaction (DDI)](https://www.cs.york.ac.uk/semeval-2013/task9/index.php%3Fid=data.html "Dataset contains 792 texts selected from the DrugBank database and other 233 Medline abstracts. This fined-grained corpus has been annotated with a total of 18,502 pharmacological substances and 5028 DDIs, including both PK as well as PD interactions.")|792|XML|[2013](https://www.sciencedirect.com/science/article/pii/S1532046413001123)|English||
|[QA-ZRE](http://nlp.cs.washington.edu/zeroshot/ "Dataset contain question answer pairs with each instance containing a relation, a question, a sentence, and an answer set.")|30M|Text|[2017](https://arxiv.org/abs/1706.04115)|English|<a target="_blank" href="https://paperswithcode.com/paper/zero-shot-relation-extraction-via-reading" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[ChemProt](https://biocreative.bioinformatics.udel.edu/news/corpora/chemprot-corpus-biocreative-vi/ "ChemProt [is] a disease chemical biology database, which is based on a compilation of multiple chemicalâprotein annotation resources, as well as disease-associated proteinâprotein interactions (PPIs). [registration required for access]")|-|TSV|[2017](https://biocreative.bioinformatics.udel.edu/media/store/files/2017/chemprot_overview_v03.pdf)|English||
|[The TAC Relation Extraction Dataset (TACRED)](https://nlp.stanford.edu/projects/tacred/ "A relation extraction dataset containing 106k+ examples covering 42 TAC KBP relation types. Costs $25 for non-members.")|106,264|CoNLL, JSON|[2017](https://nlp.stanford.edu/pubs/zhang2017tacred.pdf)|English||
|[FewRel 1.0](https://github.com/thunlp/FewRel "Dataset is a few-shot relation extraction dataset, which contains more than one hundred relations and tens of thousands of annotated instances cross different domains.")|70k|JSON|[2018](https://www.aclweb.org/anthology/D18-1514.pdf)|English||
|[T-REx](https://hadyelsahar.github.io/t-rex/downloads/ "Dataset contains Wikipedia abstracts aligned withÂ WikidataÂ entities.")|11M aligned triples|JSON and NIF|[2018](https://www.aclweb.org/anthology/L18-1544.pdf)|English||
|[DocRed](https://github.com/thunlp/DocRED "Dataset was constructed from Wikipedia and Wikidata. It annotates both named entities and relations.")|107,050|JSON|[2019](https://arxiv.org/abs/1906.06127v3)|English|<a target="_blank" href="https://paperswithcode.com/paper/docred-a-large-scale-document-level-relation" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=docred" title="Open in Huggingface" target="_blank">ð¤</a>|
|[KnowledgeNet](https://github.com/diffbot/knowledge-net "KnowledgeNet is a benchmark dataset for the task of automatically populating a knowledge base (Wikidata) with facts expressed in natural language text on the web.")|9k|JSON|[2019](https://pdfs.semanticscholar.org/d799/cd1a35278a4a8d863092f3f3a7914b719ec6.pdf?_ga=2.101541378.2044998952.1601476249-1179939496.1599584294)|English||
|[Perlex](http://farsbase.net/PERLEX.html "Dataset is an expert translated version of the Semeval-2010-Task-8 dataset.")|10,717|-|[2020](https://arxiv.org/abs/2005.06588)|Persian|<a target="_blank" href="https://paperswithcode.com/paper/perlex-a-bilingual-persian-english-gold" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Focused Open Biology Information Extraction (FOBIE)](https://github.com/rubenkruiper/FOBIE "Dataset contains 1,500 manually-annotated sentences that express domain-independent relations between central concepts in a scientific biology text, such as trade-offs and correlations.")|1,500|JSON|[2020](https://arxiv.org/abs/2005.07753)|English|<a target="_blank" href="https://paperswithcode.com/paper/a-scientific-information-extraction-dataset" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[DialogRE](https://github.com/nlpdata/dialogre "Dataset contains human-annotated dialogue-based relation extraction containing 1,788 dialogues originating from the complete transcripts of a famous American television situation comedy "Friends". There are 36 possible relation types that exist between an argument pair in a dialogue.")|1,788|JSON|[2020](https://www.aclweb.org/anthology/2020.acl-main.444.pdf)|Chinese, English||

## Relation Link Prediction

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Wiki-CS](https://github.com/pmernyei/wiki-cs-dataset "Dataset consists of nodes corresponding to Computer Science articles, with edges based on hyperlinks and 10 classes representing different branches of the field.")|216,123 Edges, 11,701 Nodes|JSON|[2020](https://arxiv.org/abs/2007.02901)|English|<a target="_blank" href="https://paperswithcode.com/paper/wiki-cs-a-wikipedia-based-benchmark-for-graph" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Relation Prediction

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[FB15K-237 Knowledge Base Completion Dataset](https://github.com/villmow/datasets_knowledge_embedding "Dataset contains knowledge base relation triples and textual mentions of Freebase entity pairs.")|237 relations, 14,451 entities|Text|[2015](https://www.aclweb.org/anthology/D15-1174.pdf)|English||
|[WN18RR](https://github.com/villmow/datasets_knowledge_embedding "Dataset contains knowledge base relation triples from WordNet.")|11 relations, 40,943 entities|Text|[2018](https://arxiv.org/abs/1707.01476)|English|<a target="_blank" href="https://paperswithcode.com/paper/convolutional-2d-knowledge-graph-embeddings" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## SQL-to-Text

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Spider 1.0](https://github.com/taoyds/spider "Dataset consists of 10,181 questions and 5,693 unique complex SQL queries on 200 databases with multiple tables covering 138 different domains.")|10,181|JSON, SQL|[2018](https://arxiv.org/abs/1809.08887)|English|<a target="_blank" href="https://paperswithcode.com/paper/spider-a-large-scale-human-labeled-dataset" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Semantic Parsing in Context (SParC)](https://github.com/taoyds/sparc "Dataset consists of 4,298 coherent question sequences (12k+ unique individual questions annotated with SQL queries annotated byt. It is the context-dependent/multi-turn version of theÂ Spider task.")|4,298|JSON, SQL|[2019](https://arxiv.org/abs/1906.02285)|English|<a target="_blank" href="https://paperswithcode.com/paper/sparc-cross-domain-semantic-parsing-in" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Conversational Text-to-SQLÂ Systems (CoSQL)](https://yale-lily.github.io/cosql "Dataset consists of 30k+ turns plus 10k+ annotated SQL queries, obtained from aÂ Wizard-of-OzÂ collection of 3k dialogues querying 200 complex databases spanning 138 domains.It is the dilaogue version of the Spider and SParC tasks.")|3k|JSON, SQL|[2019](https://arxiv.org/abs/1909.05378)|English|<a target="_blank" href="https://paperswithcode.com/paper/cosql-a-conversational-text-to-sql-challenge" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Sarcasm Detection

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Self-Annotated Reddit Corpus (SARC)](https://nlp.cs.princeton.edu/SARC/ "Dataset contains 1.3 million sarcastic comments from the Internet commentary website Reddit. It contains statements, along with their responses as well as many non-sarcastic comments from the same source.")|1.3M|CSV|[2017](https://arxiv.org/abs/1704.05579)|English|<a target="_blank" href="https://paperswithcode.com/paper/a-large-self-annotated-corpus-for-sarcasm" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Scene Text Detection

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Total-Text-Dataset](https://github.com/cs-chan/Total-Text-Dataset "Dataset used to classify curved text in pictures.")|~1,500|JPG|[2019](https://arxiv.org/abs/1710.10400)|English|<a target="_blank" href="https://paperswithcode.com/paper/total-text-a-comprehensive-dataset-for-scene" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Scene Text Recognition

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Street View Text (SVT)](http://www.iapr-tc11.org/mediawiki/index.php/The_Street_View_Text_Dataset "Dataset contains images with textual content used for scene text recognition.")|-|XML, JPG|[2012](http://www.iapr-tc11.org/dataset/SVT/wang_eccv2010.pdf)|English||

## Scoring Classification

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Short Answer Scoring](https://www.kaggle.com/c/asap-sas/overview "Student-written short-answer responses.")|-|TSV|[2012]()|English||
|[Automated Essay Scoring](https://www.kaggle.com/c/asap-aes/overview "Dataset contains student-written essays with scores.")|-|TSV, xlsx|[2017](https://www.researchgate.net/publication/26415982_Automated_Essay_Scoring)|English||

## Semantic Parse Correction

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Semantic Parsing with Language Assistance from Humans (SPLASH)](https://github.com/MSR-LIT/Splash "Dataset enables text-to-SQL systems to seek and leverage human feedback to further improve the overall performance and user experience. Dataset contains 9,314 question-feedback pairs, 8,352 of which, correspond to questions in the Spider training split and 962 from the spider development split. ")|9,314|JSON|[2020](https://www.aclweb.org/anthology/2020.acl-main.187.pdf)|English||

## Semantic Parsing

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Restaurants](https://github.com/jkkummerfeld/text2sql-data "Dataset contains user questions about restaurants, their food types, and locations.")|378|JSON|[2012](https://www.researchgate.net/publication/270878355_Translating_Questions_to_SQL_Queries_with_Generative_Parsers_Discriminatively_Reranked)|English||
|[Academic](https://github.com/jkkummerfeld/text2sql-data "Questions about the Microsoft Academic Search (MAS) database, derived by enumerating every logical query that could be expressed using the search page of the MAS website and writing sentences to match them.")|196|JSON|[2014](http://www.vldb.org/pvldb/vol8/p73-li.pdf)|English||
|[WikiTablesQuestions](https://github.com/ppasupat/WikiTableQuestions "Dataset is for the task of question answering on semi-structured HTML tables.")|22,033|TSV|[2015](https://arxiv.org/abs/1508.00305)|English|<a target="_blank" href="https://paperswithcode.com/paper/compositional-semantic-parsing-on-semi" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Sequential Question Answering (SQA)](https://www.microsoft.com/en-us/download/details.aspx?id=54253 "Dataset was created to explore the task of answering sequences of inter-related questions on HTML tables. It has 6,066 sequences with 17,553 questions in total.")|17,553|TSV|[2016](https://people.cs.umass.edu/~miyyer/pubs/2017_acl_dynsp.pdf)|English||
|[WebQuestions Semantic Parses Dataset](https://www.microsoft.com/en-us/download/details.aspx?id=52763 "Dataset contains full semantic parses in SPARQL queries for 4,737 questions, and âpartialâ annotations for the remaining 1,073 questions for which a valid parse could not be formulated or where the question itself is bad or needs a descriptive answer.")|5,810|JSON|[2016](https://www.aclweb.org/anthology/P16-2033.pdf)|English||
|[WikiSQL](https://github.com/jkkummerfeld/text2sql-data "A large collection of automatically generated questions about individual tables from Wikipedia.")|80,654|JSON|[2017](https://arxiv.org/abs/1709.00103)|English|<a target="_blank" href="https://paperswithcode.com/paper/seq2sql-generating-structured-queries-from" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=wikisql" title="Open in Huggingface" target="_blank">ð¤</a>|
|[GeoQuery](https://github.com/jkkummerfeld/text2sql-data "Dataset contains utterances issued to a database of US geographical facts.")|877|JSON|[2017](https://pdfs.semanticscholar.org/1c9d/f99cce1903d34c53025e86e72331bbfbe08f.pdf?_ga=2.119839695.69779999.1583855679-45550878.1577737485)|English||
|[Scholar](https://github.com/jkkummerfeld/text2sql-data "User questions about academic publications, with automatically generated SQL that was checked by asking the user if the output was correct.")|817|JSON|[2017](https://www.aclweb.org/anthology/P17-1089.pdf)|English||
|[ATIS](https://github.com/jkkummerfeld/text2sql-data "Dataset is a collection of utterances to a flight booking system, accompanied by a relational database and SQL queries to answer the questions.")|877|JSON|[2017](https://www.aclweb.org/anthology/P18-1033.pdf)|English||
|[Advising](https://github.com/jkkummerfeld/text2sql-data "Dataset contains questions regarding course information at the University of Michigan, but with fictional student records.")|4,570|JSON|[2018](https://arxiv.org/abs/1806.09029)|English|<a target="_blank" href="https://paperswithcode.com/paper/improving-text-to-sql-evaluation-methodology" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Spider 1.0](https://github.com/taoyds/spider "Dataset consists of 10,181 questions and 5,693 unique complex SQL queries on 200 databases with multiple tables covering 138 different domains.")|10,181|JSON, SQL|[2018](https://arxiv.org/abs/1809.08887)|English|<a target="_blank" href="https://paperswithcode.com/paper/spider-a-large-scale-human-labeled-dataset" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[MSParS](https://github.com/msra-nlc/MSParS "Dataset for the open domain semantic parsing task.")|81,826|Satori|[2019](http://tcci.ccf.org.cn/conference/2019/papers/EV20.pdf)|English||
|[Semantic Parsing in Context (SParC)](https://github.com/taoyds/sparc "Dataset consists of 4,298 coherent question sequences (12k+ unique individual questions annotated with SQL queries annotated byt. It is the context-dependent/multi-turn version of theÂ Spider task.")|4,298|JSON, SQL|[2019](https://arxiv.org/abs/1906.02285)|English|<a target="_blank" href="https://paperswithcode.com/paper/sparc-cross-domain-semantic-parsing-in" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Web Demonstration and Explanation Dataset (Web-D-E)](https://msropendata.com/datasets/118a130f-cc09-4ede-a2b5-92d77b1feb93 "Dataset consists of 520 explanations and corresponding demonstrations of web-based tasks from the Mini Word-of-Bits.")|520|TSV|[2020](https://www.aclweb.org/anthology/2020.acl-main.684.pdf)|English||

## Semantic Role Labeling

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[QA-SRL Bank](http://qasrl.org/ "Dataset contains question answer pairs for 64,000 sentences. Dataset is used to train model for semantic role labeling")|64k|JSON|[2018](https://arxiv.org/abs/1805.05377v1)|English|<a target="_blank" href="https://paperswithcode.com/paper/large-scale-qa-srl-parsing" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Hebrew Parallel Movie Subtitles](https://github.com/bgunlp/hebrew_srl "Dataset derived from subtitles of movies and television shows for the purpose of semantic role labeling in Hebrew. It includes both FrameNet and PropBank annotations.")|30,789|-|[2020](https://arxiv.org/abs/2005.08206)|Hebrew|<a target="_blank" href="https://paperswithcode.com/paper/building-a-hebrew-semantic-role-labeling" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Abstract Meaning Respresentation (AMR) Bank](https://catalog.ldc.upenn.edu/LDC2020T02 "Dataset contains a sembank (semantic treebank) of over 59,255 English natural language sentences from broadcast conversations, newswire, weblogs, web discussion forums, fiction and web text.")|59,255|Text|[2020](https://www.aclweb.org/anthology/C18-1313.pdf)|English||

## Semantic Textual Similarity

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[SemEval-2014 Task 3](http://alt.qcri.org/semeval2014/task3/index.php?id=data-and-tools "Dataset is used for cross-level semantic similarity which measures the degree to which the meaning of a larger linguistic item, such as a paragraph, is captured by a smaller item, such as a sentence.")|2k|TSV|[2014](http://alt.qcri.org/semeval2014/task3/data/uploads/semeval2014-task3.pdf)|English||
|[Sentences Involving Compositional Knowledge (SICK)](https://zenodo.org/record/2787612 "Dataset contains sentence pairs, generated from two existing sets: theÂ 8K ImageFlickr data setÂ and theÂ SemEval 2012 STS MSR-Video Description.")|~10,000|Text|[2014](https://www.aclweb.org/anthology/S14-2001.pdf)|English||
|[A Novel Approach to a Semantically-Aware Representation of Items (NASARI)](http://lcl.uniroma1.it/nasari/ "Dataset contains semantic vector representations for BabelNet synsets and Wikipedia pages in several languages: English,Â Spanish,Â French,Â GermanÂ andÂ Italian. Currently available three vector types: lexical, unified and embedded.")|610K-4.4M depending on language|Text|[2016](https://www.aclweb.org/anthology/N15-1059.pdf)|Multi-Lingual||
|[Quora Question Pairs](https://www.quora.com/q/quoradata/First-Quora-Dataset-Release-Question-Pairs "The task is to determine whether a pair of questions are semantically equivalent.")|400k|TSV|[2017]()|English|<a href="https://huggingface.co/nlp/viewer/?dataset=quora" title="Open in Huggingface" target="_blank">ð¤</a>|
|[BIOSSES](https://tabilab.cmpe.boun.edu.tr/BIOSSES/DataSet.html "Dataset comprises 100 sentence pairs, in which each sentence was selected from the TAC (Text Analysis Conference) Biomedical Summarization Track Training Dataset containing articles from the biomedical domain. TAC dataset consists of 20 articles (reference articles) and citing articles that vary from 12 to 20 for each of the reference articles.")|100|Word Doc|[2017](https://academic.oup.com/bioinformatics/article/33/14/i49/3953954)|English||
|[Semantic Textual Similarity Benchmark](http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark "The task is to predict textual similarity between sentence pairs.")|8,628|CSV|[2017](https://www.aclweb.org/anthology/S17-2001.pdf)|English||
|[Danish-Similarity-Dataset](https://comparable.limsi.fr/bucc2018/bucc2018-task.html "Dataset consists of 99 word pairs rated by 38 human judges according to their semantic similarity.")|99|CSV|[2019]()|Danish||
|[ParaBank](http://decomp.io/projects/parabank/ "Dataset contains paraphrases with 79.5 million references and on average 4 paraphrases per reference.")|79.5M references|TSV|[2019](https://arxiv.org/abs/1901.03644)|English|<a target="_blank" href="https://paperswithcode.com/paper/parabank-monolingual-bitext-generation-and" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[KorSTS](https://github.com/kakaobrain/KorNLUDatasets "Dataset used for semantic textual similarity for the Korean language.")|8,628|TSV|[2020](https://arxiv.org/abs/2004.03289)|Korean|<a target="_blank" href="https://paperswithcode.com/paper/kornli-and-korsts-new-benchmark-datasets-for" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=kor_nli" title="Open in Huggingface" target="_blank">ð¤</a>|

## Sentence Fusion

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[DiscoFuse](https://github.com/google-research-datasets/discofuse "Dataset contains examples for training sentence fusion models. Sentence fusion is the task of joining several independent sentences into a single coherent text. The data has been collected from Wikipedia and from Sports articles.")|~60M|TSV|[2019](https://arxiv.org/abs/1902.10526)|English|<a target="_blank" href="https://paperswithcode.com/paper/discofuse-a-large-scale-dataset-for-discourse" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=discofuse" title="Open in Huggingface" target="_blank">ð¤</a>|

## Sentence Level Cloze Completion

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[SCDE](https://github.com/shawnkx/SCDE "Dataset of sentence-level cloze questions sourced from public school examinations. Each instance consists of a passage with multiple sentence-level blanks and a shared set of candidates. Besides the right answer to each cloze in the passage, the candidate set also contains ones which donât answer any cloze, called distractors. [requires contacting authors for data]")|14,062|-|[2020](https://www.aclweb.org/anthology/2020.acl-main.502.pdf)|English||

## Sentence Simplification

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[WikiSplit](https://github.com/google-research-datasets/wiki-split "Dataset contains 1 million English sentences, each split into two sentences that together preserve the original meaning, extracted from Wikipedia edits.")|1M|TSV|[2018](https://arxiv.org/abs/1808.09468)|English|<a target="_blank" href="https://paperswithcode.com/paper/learning-to-split-and-rephrase-from-wikipedia" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Abstractive Sentence Simplification Evaluation and Tuning (ASSET)](https://github.com/facebookresearch/asset "Dataset consists of 23,590 human simplifications associated with the 2,359 original sentences from TurkCorpus (10 simplifications per original sentence).")|23,590|Text|[2020](https://arxiv.org/abs/2005.00481)|English|<a target="_blank" href="https://paperswithcode.com/paper/asset-a-dataset-for-tuning-and-evaluation-of" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Sentiment Analysis

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[NYSK Dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/00260/ "English news articles about the case relating to allegations of sexual assault against the formerÂ IMFÂ directorÂ Dominique Strauss-Kahn.")|10,421|XML|[2013]()|English||
|[Yelp Polarity Reviews](https://s3.amazonaws.com/fast-ai-nlp/yelp_review_full_csv.tgz "Dataset contains 1,569,264 samples from the Yelp Dataset Challenge 2015. This subset has 280,000 training samples and 19,000 test samples in each polarity. Dataset from FastAI's website.")|1,569,264|CSV|[2015](https://arxiv.org/abs/1509.01626)|English|<a target="_blank" href="https://paperswithcode.com/paper/character-level-convolutional-networks-for" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=yelp_polarity" title="Open in Huggingface" target="_blank">ð¤</a>|
|[MPQA Opinion Corpus](https://mpqa.cs.pitt.edu/corpora/mpqa_corpus/ "Dataset contains news articles and other text documents manually annotated for opinions and other private states (i.e., beliefs, emotions, sentiments, speculations, etc.).")|70|XML|[2015](https://www.aclweb.org/anthology/N15-1146.pdf)|English||
|[ExaminerÂ Pseudo-News Corpus](https://www.kaggle.com/therohk/examine-the-examiner "Clickbait, spam, crowd-sourced headlines from 2010 to 2015.")|3,089,781|CSV|[2017]()|English||
|[Emoter Dataset](https://github.com/jddunn/emoter/tree/master/emoter/data "Dataset contains 8,000 quotes (sentences to short paragraphs) collected and manually annotated for emotions from literature, film, and some online articles for sentiment analysis.")|8k|Text|[2018]()|English||
|[Vietnamese Studentsâ Feedback Corpus (UIT-VSFC)](https://drive.google.com/drive/folders/1xclbjHHK58zk2X6iqbvMPS2rcy9y9E0X "Dataset contains over 16,000 sentences which are human-annotated with two different tasks: sentiment-based and topic-based classifications.")|16,000+|Text|[2018](https://ieeexplore.ieee.org/document/8573337)|Vietnamese||
|[CMU Multimodal Opinion Sentiment and Emotion Intensity (CMU-MOSEI)](https://github.com/A2Zadeh/CMU-MultimodalSDK "Dataset contains more than 23,500 sentence utterance videos from more than 1000 online YouTube speakers. The dataset is gender balanced. All the sentences utterance are randomly chosen from various topics and monologue videos.")|23,500|-|[2018](https://www.aclweb.org/anthology/P18-1208.pdf)|English||
|[Clash of Clans](https://www.kaggle.com/moradnejad/clash-of-clans-50000-user-comments "Dataset contains 50K user comments, both from the iTunes App Store and Google Play. The dataset spans from Oct 18, 2018 to Feb 1, 2019.")|50k|CSV|[2019]()|English||
|[PolEmo2.0-IN & OUT](https://klejbenchmark.com/tasks/ "Dataset contains online reviews from medicine and hotels domains. The task is to predict the sentiment of a review.")|8,216|TSV|[2019](https://www.aclweb.org/anthology/K19-1092.pdf)|Polish||
|[MalayalamMixSentiment](https://github.com/bharathichezhiyan/MalayalamMixSentiment "Dataset contains 6,739 comments and 7,743 distinct sentences. There are 5 classes: Positive, Negative,  Mixed feelings,  Neutral, and Non-Malayalam. Requires to email author for dataset download.")|6,739|-|[2020]()|Malayalam||

## Speech Corpora

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Arabic Speech Corpus](http://en.arabicspeechcorpus.com/ "Dataset was recorded in south Levantine Arabic (Damascian accent) using a professional studio. Synthesized speech as an output using this corpus has produced a high quality, natural voice.")|-|WAV, LAB|[2016](http://en.arabicspeechcorpus.com/Nawar%20Halabi%20PhD%20Thesis%20Revised.pdf)|Arabic||
|[Ljspeech](https://keithito.com/LJ-Speech-Dataset/ "Dataset consisting of 13,100 short audio clips of a single speaker reading passages from 7 non-fiction books. A transcription is provided for each clip. Clips vary in length from 1 to 10 seconds and have a total length of approximately 24 hours.")|~24 Hours|Wav|[2017]()|English||
|[VoxForge](http://www.voxforge.org/home/downloads "Dataset consisting of speech audio clips submitted by the community involving several different languages. Dataset is constantly updated.")|-|Wav, MFC|[2020]()|Multi-Lingual||
|[Multilingual Corpus of Sentence-Aligned Spoken Utterances (MaSS)](https://github.com/getalp/mass-dataset "Dataset of 8,130 parallel spoken utterances across 8 languages (56 language pairs). Languages: Basque, English, Finnish, French. Hungarian, Romanian, Russian, Spanish.")|8,130|-|[2020](https://arxiv.org/abs/1907.12895)|Multi-Lingual|<a target="_blank" href="https://paperswithcode.com/paper/mass-a-large-and-clean-multilingual-corpus-of" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[FT Speech](https://ftspeech.github.io/ "Dataset contains recorded meetings of the Danish Parliament, otherwise known as the Folketing (FT). The corpus contains over 1,800 hours of transcribed speech by a total of 434 speakers.")|1800 Hours|-|[2020](https://arxiv.org/abs/2005.12368)|Danish|<a target="_blank" href="https://paperswithcode.com/paper/ft-speech-danish-parliament-speech-corpus" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Speech Question Answering

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Open-Domain Spoken Question Ansswering Dataset (ODSQA)](https://github.com/chiahsuan156/ODSQA "Dataset contains questions in both text and spoken forms, a multi-sentence spoken-form document and a word span answer based from the document.")|3,000+|JSON|[2018](https://arxiv.org/abs/1808.02280)|Chinese|<a target="_blank" href="https://paperswithcode.com/paper/odsqa-open-domain-spoken-question-answering" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Speech Recognition

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[CMU_ARCTIC](http://festvox.org/cmu_arctic/ "Dataset contains 1,150 utterances carefully selected from out-of-copyright texts from Project Gutenberg. The databases include US English male (bdl) and female (slt) speakers (both experinced voice talent) as well as other accented speakers.")|1,150|WAV|[2004](http://festvox.org/cmu_arctic/cmu_arctic_report.pdf)|English||
|[LibriSpeech ASR](http://www.openslr.org/12/ "Large-scale (1000 hours) corpus of read English speech.")|-|FLAC|[2015](http://www.danielpovey.com/files/2015_icassp_librispeech.pdf)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=librispeech_lm" title="Open in Huggingface" target="_blank">ð¤</a>|
|[VoxCeleb](http://www.robots.ox.ac.uk/~vgg/data/voxceleb/ "An audio-visual dataset consisting of short clips of human speech, extracted from interview videos uploaded to YouTube.")|-|MD5, URL|[2017](https://arxiv.org/abs/1706.08612)|Multi-Lingual|<a target="_blank" href="https://paperswithcode.com/paper/voxceleb-a-large-scale-speaker-identification" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[AudioSet](https://research.google.com/audioset/download.html "Dataset consists of an expanding ontology of 632 audio event classes and a collection of 2,084,320 human-labeled 10-second sound clips drawn from YouTube videos.")|-|CSV, TFR|[2017](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/45857.pdf)|Multi-Lingual||
|[Microsoft Speech Language Translation Corpus (MSLT)](https://www.microsoft.com/en-us/download/details.aspx?id=55951 "Dataset contains conversational, bilingual speech test and tuning data for English, Chinese, and Japanese. It includes audio data, transcripts, and translations; and allows end-to-end testing of spoken language translation systems on real-world data.")|-|Wav|[2017](https://workshop2016.iwslt.org/downloads/IWSLT_2016_paper_12.pdf)|Multi-Lingual||
|[Argentinian Spanish [es-ar] Speech Multi-Speaker Dataset](http://openslr.org/61/ "Speech dataset containing about 5,900 transcribed high-quality audio from Argentinian Spanish [es-ar] sentences recorded by volunteers.")|~5,900|Wav|[2018]()|Spanish (Argentinan)||
|[Voices Obscured in Complex Environmental Settings (VOiCES)](https://voices18.github.io/downloads/ "Dataset contains a total of 15 hours (3,903 audio files) in male and female read speech.")|-|Wav|[2018](https://arxiv.org/abs/1804.05053)|English||
|[Microsoft Information-Seeking Conversation (MISC) dataset](https://www.microsoft.com/en-us/download/details.aspx?id=55594 "Dataset contains recordings of information-seeking conversations between human âseekersâ and âintermediariesâ. It includes audio and video signals; transcripts of conversation; affectual and physiological signals; recordings of search and other computer use; and post-task surveys on emotion, success, and effort.")|-|various|[2018](https://arxiv.org/abs/1804.08759)|English|<a target="_blank" href="https://paperswithcode.com/paper/analyzing-and-characterizing-user-intent-in" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[L2-ARTIC](https://psi.engr.tamu.edu/l2-arctic-corpus/ "Dataset includes recordings from twenty-four (24) non-native speakers of English whose first languages (L1s) are Hindi, Korean, Mandarin, Spanish, Arabic and Vietnamese, each L1 containing recordings from two male and two female speakers. Each speaker recorded approximately one hour of read speech from CMUâsÂ ARCTICÂ prompts.")|-|WAV|[2018](https://pdfs.semanticscholar.org/db89/3917bc12fc2c6273b1f382819987aa5f68e1.pdf)|English (Non-Native)||
|[Microsoft Speech Corpus](https://msropendata.com/datasets/7230b4b1-912d-400e-be58-f84e0512985e "Dataset contains conversational and phrasal speech training and test data for Telugu, Tamil and Gujarati languages.")|-|Wav|[2019]()|Indian||
|[Common Voice](https://voice.mozilla.org/en/datasets "Dataset containing audio in 29 languages and 2,454 recorded hours .")|-|MP3|[2019](https://arxiv.org/abs/1912.06670)|Multi-Lingual|<a target="_blank" href="https://paperswithcode.com/paper/common-voice-a-massively-multilingual-speech" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Libri-Light](https://github.com/facebookresearch/libri-light "Dataset contains 60K hours of unlabelled speech from audiobooks in English and a small labelled data set (10h, 1h, and 10 min).")|60,000 Hours|FLAC, JSON|[2019](https://arxiv.org/abs/1912.07875)|English|<a target="_blank" href="https://paperswithcode.com/paper/libri-light-a-benchmark-for-asr-with-limited" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Speech Seperation

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[WSJ0 Hipster Ambient Mixtures (WHAM!)](http://wham.whisper.ai/ "Dataset consists of two speaker mixtures from the wsj0-2mix dataset combined with real ambient noise samples. The samples were collected in coffee shops, restaurants, and bars in the San Francisco Bay Area.")|81 Hours|Wav|[2019](https://arxiv.org/abs/1907.01160)|English|<a target="_blank" href="https://paperswithcode.com/paper/wham-extending-speech-separation-to-noisy" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[LibriMix](https://github.com/JorisCos/LibriMix "Dataset is used for speech source separation in noisy environments. It is derived from LibriSpeech signals (clean subset) and WHAM noise. It offers a free alternative to the WHAM dataset and complements it.")|400+ Hours|-|[2020](https://arxiv.org/abs/2005.11262)|English|<a target="_blank" href="https://paperswithcode.com/paper/librimix-an-open-source-dataset-for" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Speech Translation

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Translation-Augmented-LibriSpeech-Corpus (Libri-Trans)](https://github.com/alicank/Translation-Augmented-LibriSpeech-Corpus "DatasetÂ is an augmentation ofÂ LibriSpeech ASR and contains English utterances (from audiobooks) automatically aligned with French text. It offers ~236h of speech aligned to translated text.")|~236 Hours|Text, WAV|[2018](https://www.aclweb.org/anthology/L18-1001.pdf)|French, English||
|[LibriVoxDeEn](https://heidata.uni-heidelberg.de/dataset.xhtml?persistentId=doi:10.11588/data/TMEDTX "Dataset contains sentence-aligned triples of German audio, German text, and English translation, based on German audio books. The corpus consists of over 100 hours of audio material and over 50k parallel sentences.")|50,000+|Text, TSV|[2019](https://arxiv.org/abs/1910.07924)|German, English|<a target="_blank" href="https://paperswithcode.com/paper/librivoxdeen-a-corpus-for-german-to-english" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[MuST-C](https://ict.fbk.eu/must-c/ "Dataset is a speech translation corpus containing 385 hours from Ted talks for speech translation from English into several languages: Dutch, French, German, Italian, Portuguese, Romanian, Russian, & Spanish. Requires filling request form.")|385 Hours|-|[2019](https://www.aclweb.org/anthology/N19-1202.pdf)|Multi-Lingual||
|[Europarl-ST](https://www.mllp.upv.es/europarl-st/ "Dataset contains paired audio-text samples for speech translation, constructed using the debates carried out in the European Parliament in the period between 2008 and 2012. Contains 6 Euro languages: German, English, Spanish, French, Italian and Portuguese.")|-|-|[2020](https://arxiv.org/abs/1911.03167)|Multi-Lingual|<a target="_blank" href="https://paperswithcode.com/paper/europarl-st-a-multilingual-corpus-for-speech" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Speech-To-Text

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[How2](https://github.com/srvk/how2-dataset "Dataset of instructional videos covering a wide variety of topics across video clips (about 2,000 hours), with word-level time alignments to the ground-truth English subtitles. And 300 hours was translated into Portuguese subtitles.")|~2,000 Hours|-|[2018](https://arxiv.org/abs/1811.00347)|Portuguese, English|<a target="_blank" href="https://paperswithcode.com/paper/how2-a-large-scale-dataset-for-multimodal" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[CoVoST](https://github.com/facebookresearch/covost "Dataset is a multilingual speech-to-text translation corpus covering translations from 21 languages into English and from English into 15 languages. The overall speech duration is 2,880 hours. The total number of speakers is 78K.")|2,880 Hours|TSV, MP3|[2020](https://arxiv.org/abs/2007.10310)|Multi-Lingual|<a target="_blank" href="https://paperswithcode.com/paper/covost-2-a-massively-multilingual-speech-to" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Stance Detection

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[X-Stance](https://github.com/ZurichNLP/xstance "Dataset contains more thanÂ 150 political questions, andÂ 67k commentsÂ written by candidates on those questions. The questions are available in German,  French, Italian and English.")|67k|JSON|[2020](https://arxiv.org/abs/2003.08385)|Multi-Lingual|<a target="_blank" href="https://paperswithcode.com/paper/x-stance-a-multilingual-multi-target-dataset" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=x_stance" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Will-They-Won't-They (WT-WT)](https://github.com/cambridge-wtwt/acl2020-wtwt-tweets "Dataset of English tweets targeted at stance detection for the rumor verification task.")|51,284|JSON|[2020](https://arxiv.org/abs/2005.00388)|English|<a target="_blank" href="https://paperswithcode.com/paper/will-they-won-t-they-a-very-large-dataset-for" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Suggestion Mining

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[SemEval-2019 Task 9 - Subtask A](https://github.com/Semeval2019Task9/Subtask-A "Suggestion Mining from Online Reviews and Forums: Dataset contains corpora of unstructured text with the intent for mining it for suggestions.")|~6,300|CSV|[2019](https://www.aclweb.org/anthology/S19-2151.pdf)|English||
|[SemEval-2019 Task 9 - Subtask B](https://github.com/Semeval2019Task9/Subtask-B "Suggestion Mining from Hotel Reviews: Dataset contains corpora of unstructured text with the intent for mining it for suggestions.")|~800|CSV|[2019](https://www.aclweb.org/anthology/S19-2151.pdf)|English||

## Summarization

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[The New York Times Annotated Corpus](https://catalog.ldc.upenn.edu/LDC2008T19 "Dataset contains over 1.8 million articles written and published by the New York Times between January 1, 1987 and June 19, 2007 with article metadata provided by the New York Times Newsroom.")|1.8M|XML|[2008]()|English||
|[Opinosis](http://kavita-ganesan.com/opinosis-opinion-dataset/#.Xuz61UVKiUk "Dataset contains sentences extracted from reviews for 51 topics. Topics and opinions are obtained from Tripadvisor, Edmunds.com and Amazon.com.")|-|Jar|[2010](https://www.aclweb.org/anthology/C10-1039.pdf)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=opinosis" title="Open in Huggingface" target="_blank">ð¤</a>|
|[MultiLing Pilot 2011 Dataset](https://github.com/ayushoriginal/Multi-Document-Summarization/tree/master/TAC%202011%20MultiLing%20Pilot%20Dataset "Dataset is derived from publicly available WikiNews English texts and translated into 7 languages: Arabic, Czech, English, French, Greek, Hebrew, Hindi.")|-|Text|[2011](https://pdfs.semanticscholar.org/634a/1db729f005052dff40016fabcc60b7c2fc84.pdf?_ga=2.264263951.1631655770.1585325522-45550878.1577737485)|Multi-Lingual||
|[Essex Arabic Summaries Corpus (EASC)](https://sourceforge.net/projects/easc-corpus/ "Dataset contains 153 Arabic articles and 765 human-generated extractive summaries of those articles. These summaries were generated using Mechanical Turk.")|153|Text|[2013]()|Arabic||
|[KALIMAT Multipurpose Arabic Corpus](https://sourceforge.net/projects/kalimat/ "Dataset contains 20,291 Arabic articles collected from the Omani newspaper Alwatan. Extractive Single-document and multi-document system summaries.  Named Entity Recognised articles. The data has 6 categories: culture, economy, local-news, international-news, religion, and sports.")|20,291|Text|[2013](https://eprints.lancs.ac.uk/id/eprint/71282/1/KALIMAT_ELHAJ_KOULALI.pdf)|Arabic||
|[Polish Summaries Corpus (PSC)](https://klejbenchmark.com/tasks/ "Dataset contains news articles and their summaries.")|723|TSV|[2014](https://pdfs.semanticscholar.org/1413/4b7bc842235a86d3c9264b7f2ba7b563f7e8.pdf)|Polish||
|[Gigaword](https://github.com/harvardnlp/sent-summary "Dataset contains headline-generation on a corpus of article pairs from Gigaword consisting of around 4 million articles.")|4M|Text|[2015]()|English|<a href="https://huggingface.co/nlp/viewer/?dataset=gigaword" title="Open in Huggingface" target="_blank">ð¤</a>|
|[LCSTS](http://icrc.hitsz.edu.cn/Article/show/139.html "Dataset constructed from the Chinese microblogging website Sina Weibo. It consists of over 2 million real Chinese short texts with short summaries given by the author of each text. Requires application.")|2M+|-|[2015](https://arxiv.org/abs/1506.05865)|Chinese|<a target="_blank" href="https://paperswithcode.com/paper/lcsts-a-large-scale-chinese-short-text" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Webis-TLDR-17 Corpus](https://zenodo.org/record/1168855#.XoD8i4hKiUk "DatasetÂ contains 3 Million pairs of content and self-written summaries mined from Reddit. It is one of the first large-scale summarization dataset from the social media domain.")|3,084,410|JSON|[2017](https://www.aclweb.org/anthology/W17-4508.pdf)|English||
|[X-Sum](https://github.com/EdinburghNLP/XSum "The XSum dataset consists ofÂ 226,711Â Wayback archived BBC articles (2010 to 2017) and covering a wide variety of domains: News, Politics, Sports, Weather, Business, Technology, Science, Health, Family, Education, Entertainment and Arts.")|226,711|JSON|[2018](https://arxiv.org/abs/1808.08745)|English|<a target="_blank" href="https://paperswithcode.com/paper/dont-give-me-the-details-just-the-summary" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[WikiHow](https://github.com/mahnazkoupaee/WikiHow-Dataset "Dataset contains article and summary pairs extracted and constructed from an online knowledge base written by different human authors.")|230,000+|Text|[2018](https://arxiv.org/abs/1810.09305)|English|<a target="_blank" href="https://paperswithcode.com/paper/wikihow-a-large-scale-text-summarization" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=wikihow" title="Open in Huggingface" target="_blank">ð¤</a>|
|[How2](https://github.com/srvk/how2-dataset "Dataset of instructional videos covering a wide variety of topics across video clips (about 2,000 hours), with word-level time alignments to the ground-truth English subtitles. And 300 hours was translated into Portuguese subtitles.")|~2,000 Hours|-|[2018](https://arxiv.org/abs/1811.00347)|Portuguese, English|<a target="_blank" href="https://paperswithcode.com/paper/how2-a-large-scale-dataset-for-multimodal" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Cornell Newsroom](https://summari.es/download/ "Dataset contains 1.3 million articles and summaries written by authors and editors in the newsrooms of 38Â major publications. The summaries are obtained from search and social metadata between 1998 and 2017.")|1.3M|JSON|[2018](https://www.aclweb.org/anthology/N18-1065.pdf)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=newsroom" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Multi-News](https://github.com/Alex-Fabbri/Multi-News "Dataset consists of news articles and human-written summaries of these articles from the site newser.com. Each summary is professionally written by editors and includes links to the original articles cited.")|56,216|SRC|[2019](https://arxiv.org/abs/1906.01749)|English|<a target="_blank" href="https://paperswithcode.com/paper/multi-news-a-large-scale-multi-document" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=multi_news" title="Open in Huggingface" target="_blank">ð¤</a>|
|[BigPatent](https://evasharma.github.io/bigpatent/ "Dataset consists of 1.3 million records of U.S. patent documents along with human written abstractive summaries.")|1.3M|-|[2019](https://arxiv.org/abs/1906.03741)|English|<a target="_blank" href="https://paperswithcode.com/paper/bigpatent-a-large-scale-dataset-for" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[BillSum](https://github.com/FiscalNote/BillSum "Dataset contains a summarization of US Congressional and California state bills.")|22,218|JSON|[2019](https://arxiv.org/abs/1910.00523)|English|<a target="_blank" href="https://paperswithcode.com/paper/billsum-a-corpus-for-automatic-summarization" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=billsum" title="Open in Huggingface" target="_blank">ð¤</a>|
|[SAMSum](https://arxiv.org/src/1911.12237v2/anc/corpus.7z "Dataset contains over 16K chat dialogues with manually annotated summaries.")|16k|JSON|[2019](https://www.aclweb.org/anthology/D19-5409.pdf)|English||
|[Annotated Enron Subject Line Corpus (AESLC)](https://github.com/ryanzhumich/AESLC "Dataset contains email messages of employees in the Enron Corporation.")|18,302|Text|[2019](https://www.aclweb.org/anthology/P19-1043.pdf)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=aeslc" title="Open in Huggingface" target="_blank">ð¤</a>|
|[CASS](https://github.com/euranova/CASS-dataset "Dataset is composed of decisions made by the French Court of cassation and summaries of these decisions made by lawyer.")|129,445|XML|[2019](https://www.data.gouv.fr/fr/datasets/cass/)|French||
|[NewSHead](https://github.com/tensorflow/models/tree/master/official/nlp/nhnet "Dataset contains 369,940 English stories with 932,571 unique URLs, among which we have 359,940 stories for training, 5,000 for validation, and 5,000 for testing, respectively. Each news story contains at least three (and up to five) articles.")|369,940|JSON|[2020](https://arxiv.org/abs/2001.09386)|English|<a target="_blank" href="https://paperswithcode.com/paper/generating-representative-headlines-for-news" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Webis-Snippet-20 Corpus](https://zenodo.org/record/3653834#.XoD9aIhKiUk "Dataset comprises four abstractive snippet dataset from ClueWeb09, Clueweb12, and DMOZ descriptions. More than 10 million <webpage, abstractive snippet> pairs / 3.5 million <query, webpage, abstractive snippet> pairs were collected.")|3.5M|JSON|[2020](https://arxiv.org/abs/2002.10782)|English|<a target="_blank" href="https://paperswithcode.com/paper/abstractive-snippet-generation" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[MLSUM](https://github.com/recitalAI/MLSUM "Dataset was collected from online newspapers, it contains 1.5M+ article/summary pairs in 5 languages: French, German, Spanish, Russian, & Turkish.")|1.5M+|-|[2020](https://arxiv.org/abs/2004.14900)|Multi-Lingual|<a target="_blank" href="https://paperswithcode.com/paper/mlsum-the-multilingual-summarization-corpus" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=mlsum" title="Open in Huggingface" target="_blank">ð¤</a>|
|[SCITLDR](https://github.com/allenai/scitldr "Dataset of a combination of TLDRs written by human experts and author written TLDRs of computer science papers from OpenReview.")|3,900|JSON|[2020](https://arxiv.org/abs/2004.15011)|English|<a target="_blank" href="https://paperswithcode.com/paper/tldr-extreme-summarization-of-scientific" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[MEDIQA-Answer Summarization](https://github.com/saverymax/qdriven-chiqa-summarization "Dataset containing question-driven summaries of answers to consumer health questions.")|156|JSON|[2020](https://arxiv.org/abs/2005.09067)|English|<a target="_blank" href="https://paperswithcode.com/paper/question-driven-summarization-of-answers-to" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Wikipedia Current Events Portal (WCEP) Dataset](https://github.com/complementizer/wcep-mds-dataset "Dataset is used for multi-document summarization (MDS) and consists of short, human-written summaries about news events, obtained from the Wikipedia Current Events Portal (WCEP), each paired with a cluster of news articles associated with an event.")|10,200|JSON|[2020](https://arxiv.org/abs/2005.10070)|English|<a target="_blank" href="https://paperswithcode.com/paper/a-large-scale-multi-document-summarization" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Syntactic Parsing

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[OntoNotes 5.0](https://catalog.ldc.upenn.edu/LDC2013T19 "Dataset contains various genres of text (news, conversational telephone speech, weblogs, usenet newsgroups, broadcast, talk shows) in three languages (English, Chinese, and Arabic) with structural information (syntax and predicate argument structure) and shallow semantics (word sense linked to an ontology and coreference).")|-|Text, SQL|[2013](https://catalog.ldc.upenn.edu/docs/LDC2013T19/OntoNotes-Release-5.0.pdf)|Multi-Lingual||

## Table Segmentation

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[SegmentedTables & LinkedResults](https://colab.research.google.com/github/paperswithcode/axcell/blob/master/notebooks/datasets.ipynb?authuser=1#scrollTo=Qf9sdQWqwQFf "Dataset mentions in captions, the type of table (leaderboard, ablation, irrelevant) and ground truth cell annotations into classes: dataset, metric, paper model, cited model, meta and task.")|~2,000|JSON|[2020](https://arxiv.org/abs/2004.14356)|English|<a target="_blank" href="https://paperswithcode.com/paper/axcell-automatic-extraction-of-results-from" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Table Type Classification

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[SegmentedTables & LinkedResults](https://colab.research.google.com/github/paperswithcode/axcell/blob/master/notebooks/datasets.ipynb?authuser=1#scrollTo=Qf9sdQWqwQFf "Dataset mentions in captions, the type of table (leaderboard, ablation, irrelevant) and ground truth cell annotations into classes: dataset, metric, paper model, cited model, meta and task.")|~2,000|JSON|[2020](https://arxiv.org/abs/2004.14356)|English|<a target="_blank" href="https://paperswithcode.com/paper/axcell-automatic-extraction-of-results-from" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Table-to-Text

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[ToTTo](https://github.com/google-research-datasets/totto "Dataset is used for the controlled generation of descriptions of tabular data comprising over 100,000 examples. Each example is a aligned pair of a highlighted table and the description of the highlighted content.")|120,000+|JSON|[2020](https://arxiv.org/abs/2004.14373)|English|<a target="_blank" href="https://paperswithcode.com/paper/totto-a-controlled-table-to-text-generation" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Text Classification

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Content-Based Categorized Dataset](https://sites.google.com/view/arabicweb16/download/labelled-datasets?authuser=0 "Dataset contains 996 Web pages from the ArabicWeb16 dataset were extracted and labeled.")|996|Text|[2016](https://www.ischool.utexas.edu/~ml/papers/sigir16-arabicweb.pdf)|Arabic||
|[SFU Opinion and Comments Corpus (SOCC)](https://github.com/sfu-discourse-lab/SOCC "Dataset contains 10,339 opinion articles (editorials, columns, and op-eds) together with their 663,173 comments from 303,665 comment threads, from the main Canadian daily in English, The Globe and Mail, from January 2012 to December 2016.  In addition there's a subset annotated corpus measuring toxicity, negation and its scope, and appraisal containing 1,043 annotated comments in responses to 10 different articles covering a variety of subjects: technology, immigration, terrorism, politics, budget, social issues, religion, property, and refugees.")|663,173|CSV|[2018](http://www.sfu.ca/~mtaboada/docs/publications/Kolhatkar_Taboada_WiNLP_2018_paper.pdf)|English||
|[Intonation-Aided Intention Identification for Korean (3i4K)](https://github.com/warnikchow/3i4k "Dataset contains seven class annotated corpus of single text utterances/intents in conversation.")|61k|Text|[2018](https://arxiv.org/abs/1811.04231)|Korean|<a target="_blank" href="https://paperswithcode.com/paper/speech-intention-understanding-in-a-head" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Vietnamese Studentsâ Feedback Corpus (UIT-VSFC)](https://drive.google.com/drive/folders/1xclbjHHK58zk2X6iqbvMPS2rcy9y9E0X "Dataset contains over 16,000 sentences which are human-annotated with two different tasks: sentiment-based and topic-based classifications.")|16,000+|Text|[2018](https://ieeexplore.ieee.org/document/8573337)|Vietnamese||
|[Offensive Language Identification Dataset (OLID)](https://sites.google.com/site/offensevalsharedtask/olid "Dataset contains a collection of 14,200 annotated English tweets using an annotation model that encompasses three levels: offensive language detection, categorization of offensive language, and offensive language target identification.")|14,200|TSV|[2019](https://www.aclweb.org/anthology/N19-1144.pdf)|English||
|[TRACT: Tweets Reporting Abuse Classification Task Corpus](https://github.com/Saichethan/TRACT "Dataset used for multi-class classification task involving three classes of tweets that mention abuse reportings: "report" (annotated as 1); "empathy" (annotated as 2); and "general" (annotated as 3).")|4,500|TSV|[2020]()|English||
|[Constructive Comments Corpus (C3)](https://www.kaggle.com/mtaboada/c3-constructive-comments-corpus "Dataset is a subset of comments from the SFU Opinion and Comments Corpus. This subset, the Constructive Comments Corpus (C3) consists of 12,000 comments annotated by crowdworkers.")|12k|CSV|[2020](https://arxiv.org/abs/2004.05476)|English|<a target="_blank" href="https://paperswithcode.com/paper/classifying-constructive-comments" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[English Possible Idiomatic Expressions (EPIE)](https://github.com/prateeksaxena2809/EPIE_Corpus "Dataset containing 25,206 sentences labelled with lexical instances of 717 idiomatic expressions.")|25,506|Text|[2020](https://arxiv.org/abs/2006.09479)|English|<a target="_blank" href="https://paperswithcode.com/paper/epie-dataset-a-corpus-for-possible-idiomatic" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[NatCat](https://github.com/ZeweiChu/NatCat "Dataset contains naturally annotated category-text pairs for training text classifiers derived from 3 sources: Wikipedia, Reddit, and Stack Exchange.")|12M+|-|[2020](https://arxiv.org/abs/2009.14335)|English|<a target="_blank" href="https://paperswithcode.com/paper/natcat-weakly-supervised-text-classification" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Text Corpora

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Guttenberg Book Corpus](http://www.gutenberg.org/wiki/Gutenberg:Offline_Catalogs "Dataset contains 60,000 eBooks.")|60k|Text|[1996-2019](https://arxiv.org/abs/1812.08092)|Multi-Lingual|<a target="_blank" href="https://paperswithcode.com/paper/a-standardized-project-gutenberg-corpus-for" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Hansards Canadian Parliament](https://www.isi.edu/natural-language/download/hansard/ "Dataset contains pairs of aligned text chunks (sentences or smaller fragments) from the official records (Hansards) of the 36thÂ Canadian Parliament.")|1.3M|Text|[2001]()|English|<a href="https://huggingface.co/nlp/viewer/?dataset=hansards" title="Open in Huggingface" target="_blank">ð¤</a>|
|[European Parliament Proceedings (Europarl)](http://statmt.org/europarl/ "The Europarl parallel corpus is extracted from the proceedings of theÂ European Parliament. It includes versions in 21 European languages.")|10M+|XML|[2002](http://www.lrec-conf.org/proceedings/lrec2012/pdf/463_Paper.pdf)|Multi-Lingual||
|[Enron Email Dataset](https://www.cs.cmu.edu/~enron/ "Emails from employees atÂ EnronÂ organized into folders.")|~500,000|Text|[2004 (2015)](http://nyc.lti.cs.cmu.edu/yiming/Publications/klimt-ecml04.pdf)|English||
|[Khaleej-2004 Corpus](https://sites.google.com/site/mouradabbas9/corpora "DatasetÂ contains more than 5,000 articles which correspond to nearly 3 millions words across 4 topics:  International News, Local News, Economy, and Sports.")|5,690|HTML|[2004]()|Arabic||
|[Watan-2004 Corpus](https://sites.google.com/site/mouradabbas9/corpora "Dataset contains about 20,000 articles talking about 6 topics: culture, religion, economy, local news, international news and sports.")|20k|HTML|[2004]()|Arabic||
|[arXiv Bulk Data](https://arxiv.org/help/bulk_data_s3 "A collection of research papers on arXiv.")|-|Tar|[2011](https://www.researchgate.net/publication/332799542_On_the_Use_of_ArXiv_as_a_Dataset)|English||
|[WikiLinks](http://www.iesl.cs.umass.edu/data/data-wiki-links "Dataset contains 40 million mentions over 3 million entities based on hyperlinks from Wikipedia.")|~10M|Text|[2012](http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=25C910ACB8DEEFFD224AE2FF7B9C86AE?doi=10.1.1.385.826&rep=rep1&type=pdf)|English||
|[Leipzig Corpora Collection](https://wortschatz.uni-leipzig.de/en/download/ "Dataset containing 252 languages of web crawled news corpora.")|-|Text|[2012](http://www.lrec-conf.org/proceedings/lrec2012/pdf/327_Paper.pdf)|Multi-Lingual||
|[Finlex](http://opus.nlpl.eu/Finlex.php "Dataset is a collection of legislative and other judicial information of Finland, which is available in Finnish and Swedish.")|7.98M|XML|[2012](http://www.lrec-conf.org/proceedings/lrec2012/pdf/463_Paper.pdf)|Finnish, Swedish||
|[ECB Corpus](http://opus.nlpl.eu/ECB.php "Website and documentation from the European Central Bank. Contains 19 languages.")|30.55M|XML|[2012](http://www.lrec-conf.org/proceedings/lrec2012/pdf/463_Paper.pdf)|Multi-Lingual||
|[DOGC](http://opus.nlpl.eu/DOGC.php "A collection of documents from the official journal of the Catalan Goverment in Catalan and Spanish.")|21.87M|XML|[2012](http://www.lrec-conf.org/proceedings/lrec2012/pdf/463_Paper.pdf)|Catalan, Spanish||
|[Eubookshop](http://opus.nlpl.eu/EUbookshop.php "Corpus of documents from the EU bookshop. Contains 48 languages.")|173.20M|XML|[2012](http://www.lrec-conf.org/proceedings/lrec2012/pdf/463_Paper.pdf)|Multi-Lingual||
|[CommonCrawl](http://commoncrawl.org/the-data/get-started/ "Dataset contains data from 25 billion web pages.")|25B|WET|[2013-2019](https://docs.google.com/file/d/1_9698uglerxB9nAglvaHkEgU-iZNm1TvVGuCW7245-WGvZq47teNpb_uL5N9/edit)|Multi-Lingual||
|[Parallel Arabic DIalectal Corpus (PADIC)](https://sites.google.com/site/torjmanepnr/6-corpus "Dataset is a multi-dialectal corpus -  contains six dialects in addition to MSA in Buckwalter format.")|6,000+|HTML|[2013]()|Arabic||
|[Groningen Meaning Bank](https://gmb.let.rug.nl/data.php "Datasets contains texts in raw and tokenised format, tags for part of speech, named entities and lexical categories, and discourse representation structures compatible with first-order logic.")|10k|XML|[2014]()|English||
|[Customer Interaction Data of German Emails and Online Requests](http://www.dfki.de/~neumann/resources/omqdata.html "Dataset is used to evaluate the task of automatically categorizing German customer requests. The dataset consists of a set emails and online requests sent to the support center of a multimedia software company.")|627|XML|[2014](http://www.dfki.de/~neumann/publications/new-ps/starsem2014-FINAL.pdf)|German||
|[ACL Anthology Reference Corpus (ACL ARC)](https://web.eecs.umich.edu/~lahiri/acl_arc.html "Dataset contains 10,921 articles from the February 2007 snapshot of the Anthology; text and metadata for the articles were extracted, consisting of BibTeX records derived either from the headers of each paper or from metadata taken from the Anthology website.")|10,921|Text|[2014](http://www.lrec-conf.org/proceedings/lrec2008/pdf/445_paper.pdf)|English||
|[Saudi Newspapers Corpus](https://github.com/ParallelMazen/SaudiNewsNet/tree/master/dataset "Dataset contains 31,030 Arabic newspaper articles.")|31,030|JSON|[2015]()|Arabic||
|[Ubuntu Dialogue Corpus](https://www.kaggle.com/rtatman/ubuntu-dialogue-corpus "Dialogues extracted from Ubuntu chat stream on IRC.")|930,000Â |CSV|[2015](https://www.aclweb.org/anthology/W15-4640.pdf)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=ubuntu_dialogs_corpus" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Arabic in Business and Management Corpora (ABMC)](https://sourceforge.net/projects/arabic-business-copora/ "Dataset contains 400 Arab companies chairman and chief executive manager statements, 400 Arabic economic news articles, 400 Arabic stock market news articles.")|1,200|Text|[2016]()|Arabic||
|[Wikipedia](https://dl.fbaipublicfiles.com/drqa/docs.db.gz "The 2016-12-21 dump of English Wikipedia.")|5,075,182|SQL|[2016]()|English|<a href="https://huggingface.co/nlp/viewer/?dataset=wikipedia" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Portuguese Newswire Corpus](http://mann.cmpe.boun.edu.tr/folha_data/ "Dataset contains x number of newswire articles collected between years 1994-2016. Requires preprocesing of HTML pages, found in GitHub in the download link.")|-|HTML|[2016]()|Portuguese (Brazil)||
|[Plaintext Jokes](https://github.com/taivop/joke-dataset "208,000 jokes in this database scraped from three sources.")|208k|JSON|[2016]()|English||
|[1.5 billion Words Arabic Corpus](http://www.abuelkhair.net/index.php/en/arabic/abu-el-khair-corpus "The data were collected from newspaper articles in ten major news sources from eight Arabic countries, over a period of fourteen years.")|5M|XML|[2016](https://arxiv.org/ftp/arxiv/papers/1611/1611.04033.pdf)|Arabic||
|[ArabicWeb16](https://sites.google.com/view/arabicweb16/download/arabicweb16?authuser=0 "Dataset contains 150,211,934 Arabic Web pages with high coverage of dialectal Arabic as well as Modern Standard Arabic (MSA).")|150M|WARC|[2016](https://www.ischool.utexas.edu/~ml/papers/sigir16-arabicweb.pdf)|Arabic||
|[UIT-SPC](https://sites.google.com/uit.edu.vn/uit-nlp/datasets-projects "Dataset contains 1,565 papers of top NLP/CL conferences such as ACL, CoNLL , EACL  NAACL  and EMNLP. They are pre-processed by removing unnecessary information (e.g formula, table, etc). Then, they were formatted to .xml that includes the title paper, sections, and sub-sections according to the paper's structure. [requires contacting author for corpus]")|1,565|-|[2017]()|Vietnamese||
|[NIPS Papers](https://www.kaggle.com/benhamner/nips-papers?select=papers.csv "Dataset contains the title, authors, abstracts, and extracted text for all NIPS papers between 1987-2016.")|~3,000|CSV|[2017]()|English||
|[Reddit All Comments Corpus](https://www.reddit.com/r/datasets/comments/6mvrb5/reddit_june_2017_comments_are_now_available/ "All Reddit comments (as of 2017).")|3,329,219,008|JSON|[2017]()|English||
|[Self-Annotated Reddit Corpus (SARC)](https://nlp.cs.princeton.edu/SARC/ "Dataset contains 1.3 million sarcastic comments from the Internet commentary website Reddit. It contains statements, along with their responses as well as many non-sarcastic comments from the same source.")|1.3M|CSV|[2017](https://arxiv.org/abs/1704.05579)|English|<a target="_blank" href="https://paperswithcode.com/paper/a-large-self-annotated-corpus-for-sarcasm" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Historical Newspapers Daily Word Time Series Dataset](https://datadryad.org/stash/dataset/doi:10.5061/dryad.nh775 "Dataset contains daily contents of newspapers published in the US and UK from 1836 to 1922.")|25k|-|[2017](https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0165736&type=printable)|English||
|[Coarse Discourse](https://github.com/google-research-datasets/coarse-discourse "Dataset contains discourse annotations and relations on threads from Reddit during 2016. Requires merging using Reddit API.")|9,473|JSON|[2017](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/60e5f386a058bb5b0b706dc5ff34746ee7ec8fab.pdf)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=coarse_discourse" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Parallel Meaning Bank](https://pmb.let.rug.nl/data.php "Dataset contains sentences and texts in raw and tokenised format, syntactic analysis, word senses, thematic roles, reference resolution, and formal meaning representations. The annotated parallel corpus inclues English, German, Dutch and Italian languages.")|8,705|XML|[2017](https://www.aclweb.org/anthology/E17-2039.pdf)|Multi-Lingual||
|[EmoBank](https://github.com/JULIELab/EmoBank "Dataset is a large-scale text corpus manually annotated with emotion according to the psychological Valence-Arousal-Dominance scheme.")|10k|CSV|[2017](https://www.aclweb.org/anthology/E17-2092.pdf)|English||
|[News Headlines Of India](https://www.kaggle.com/therohk/india-headlines-news-dataset "Dataset contains archive of noteable events in India during 2001-2018, recorded by the Times of India.")|2,969,922|CSV|[2017](https://www.kaggle.com/therohk/india-headlines-news-dataset/version/2)|English||
|[Stack Overlow BigQuery Dataset](https://www.kaggle.com/stackoverflow/stackoverflow "BigQuery dataset includes an archive of Stack Overflow content, including posts, votes, tags, and badges.")|-|-|[2018]()|English||
|[Yoruba Text](https://github.com/Niger-Volta-LTI/yoruba-text "Multiple datasets scraped together for the Yoruba language.")|-|Text|[2018]()|Yoruba||
|[Polish Parliamentary Corpus (PPC)](http://clip.ipipan.waw.pl/PPC "Dataset is a collection of linguistically analysed documents from the proceedings of Polish Parliament, Sejm and Senate. It is based on the Polish Sejm Corpus.")|3,000+|XML|[2018](http://lrec-conf.org/workshops/lrec2018/W2/pdf/11_W2.pdf)|Polish||
|[SFU Opinion and Comments Corpus (SOCC)](https://github.com/sfu-discourse-lab/SOCC "Dataset contains 10,339 opinion articles (editorials, columns, and op-eds) together with their 663,173 comments from 303,665 comment threads, from the main Canadian daily in English, The Globe and Mail, from January 2012 to December 2016.  In addition there's a subset annotated corpus measuring toxicity, negation and its scope, and appraisal containing 1,043 annotated comments in responses to 10 different articles covering a variety of subjects: technology, immigration, terrorism, politics, budget, social issues, religion, property, and refugees.")|663,173|CSV|[2018](http://www.sfu.ca/~mtaboada/docs/publications/Kolhatkar_Taboada_WiNLP_2018_paper.pdf)|English||
|[Open Research Corpus](https://api.semanticscholar.org/corpus/ "Dataset contains over 39 million published research papers in Computer Science, Neuroscience, and Biomedical.")|39M|JSON|[2018](https://arxiv.org/abs/1804.09635)|English|<a target="_blank" href="https://paperswithcode.com/paper/a-dataset-of-peer-reviews-peerread-collection" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[EBM PICO](https://github.com/bepnye/EBM-NLP "Dataset contains ~5,000 medical abstracts describing clinical trials, annotated in detail with respect to characteristics of the underlying trial Populations (e.g., diabetics), Interventions (insulin), Comparators (placebo) and Outcomes (blood glucose levels).")|~5,000|Text|[2018](https://arxiv.org/abs/1806.04185)|English|<a target="_blank" href="https://paperswithcode.com/paper/a-corpus-with-multi-level-annotations-of" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[WikiHow](https://github.com/mahnazkoupaee/WikiHow-Dataset "Dataset contains article and summary pairs extracted and constructed from an online knowledge base written by different human authors.")|230,000+|Text|[2018](https://arxiv.org/abs/1810.09305)|English|<a target="_blank" href="https://paperswithcode.com/paper/wikihow-a-large-scale-text-summarization" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=wikihow" title="Open in Huggingface" target="_blank">ð¤</a>|
|[One Week of Global News Feeds](https://www.kaggle.com/therohk/global-news-week "Dataset contains most of the new news content published online over one week in 2017 and 2018.")|3.3M|CSV|[2018](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/ILAT5B)|Multi-Lingual||
|[Cornell Newsroom](https://summari.es/download/ "Dataset contains 1.3 million articles and summaries written by authors and editors in the newsrooms of 38Â major publications. The summaries are obtained from search and social metadata between 1998 and 2017.")|1.3M|JSON|[2018](https://www.aclweb.org/anthology/N18-1065.pdf)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=newsroom" title="Open in Huggingface" target="_blank">ð¤</a>|
|[WMT 19 Multiple Datasets](http://www.statmt.org/wmt19/translation-task.html "Multiple text corpora in multiple languages.")|-|Text|[2019]()|Multi-Lingual|<a href="https://huggingface.co/nlp/viewer/?dataset=wmt19" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Igbo Text](https://github.com/Niger-Volta-LTI/igbo-text "Dataset is a parallel dataset for the Urhobo language.")|10.3M|Text, XML|[2019]()|Igbo, English||
|[Urhobo Text](https://github.com/Niger-Volta-LTI/urhobo-text/tree/master/JW300 "Dataset is a parallel dataset containing 10.3M tokens.")|-|Text, XML|[2019]()|Urhobo, English||
|[Wikipedia News Corpus](https://gist.github.com/pncnmnp/3321df2e82eb9b8b1b2f59131c7144b2 "Text from Wikipedia's current events page with dates.")|~25,000|Text|[2019]()|English||
|[ABCÂ Australia News Corpus](https://www.kaggle.com/therohk/million-headlines "Entire news corpus of ABC Australia from 2003 to 2019.")|1,186,018|CSV|[2019]()|English||
|[Classify Emotional Relationships of Fictional Characters](https://www.ims.uni-stuttgart.de/forschung/ressourcen/korpora/relationalemotions/ "Dataset contains 19 short stories that are shorter than 1,500 words, and depict at least four different characters.")|19|Text|[2019](https://arxiv.org/abs/1903.12453)|English|<a target="_blank" href="https://paperswithcode.com/paper/frowning-frodo-wincing-leia-and-a-seriously" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Event-focused Emotion Corpora for German and English](https://www.ims.uni-stuttgart.de/forschung/ressourcen/korpora/deisear/ "German and English emotion corpora for emotion classification, annotated with crowdsourcing in the style of the ISEAR resources.")|2,002|TSV|[2019](https://arxiv.org/abs/1905.13618)|German, English|<a target="_blank" href="https://paperswithcode.com/paper/crowdsourcing-and-validating-event-focused" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[WikiText-TL-39](https://github.com/jcblaisecruz02/Filipino-Text-Benchmarks "Dataset is a large scale, unlabeled text dataset with 39M tokens in the training set.")|-|Text|[2019](https://arxiv.org/abs/1907.00409)|Filipino|<a target="_blank" href="https://paperswithcode.com/paper/evaluating-language-model-finetuning" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[CodeSearchNet Corpus](https://github.blog/2019-09-26-introducing-the-codesearchnet-challenge/ "Dataset contains functions with associated documentation written in Go, Java, JavaScript, PHP, Python, and Ruby from open source projects on GitHub.")|6M|JSON|[2019](https://arxiv.org/abs/1909.09436)|English|<a target="_blank" href="https://paperswithcode.com/paper/codesearchnet-challenge-evaluating-the-state" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[CC Net](https://github.com/facebookresearch/cc_net "Dataset of the common crawl corpus that has been cleaned and deduplicated. This pipeline preserves the structure of documents and filter the data based on their distance to Wikipedia.")|A LOT!|JSON|[2019](https://arxiv.org/abs/1911.00359)|Multi-Lingual|<a target="_blank" href="https://paperswithcode.com/paper/ccnet-extracting-high-quality-monolingual" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[PG-19](https://github.com/deepmind/pg19 "Dataset contains a set of books extracted rom the Project Gutenberg books library, that were published before 1919. It also contains metadata of book titles and publication dates.")|28,752|Text|[2019](https://arxiv.org/abs/1911.05507)|English|<a target="_blank" href="https://paperswithcode.com/paper/compressive-transformers-for-long-range-1" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=pg19" title="Open in Huggingface" target="_blank">ð¤</a>|
|[NLP Chinese Corpus](https://github.com/brightmart/nlp_chinese_corpus "Large text corpora in Chinese.")|10M+|JSON|[2019](https://bmcmedinformdecismak.biomedcentral.com/track/pdf/10.1186/s12911-019-0770-7)|Chinese||
|[OpenÂ Super-LargeÂ CrawledÂ AlmanachÂ Corpus (OSCAR)](https://traces1.inria.fr/oscar/ "Multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.166 different languages available.")|-|Text|[2019](https://hal.inria.fr/hal-02148693/document)|Multi-Lingual||
|[OpenWebTextCorpus](https://skylion007.github.io/OpenWebTextCorpus/ "Dataset contains millions of webpages text stemming from reddit urls totalling 38Gb of text data.")|8,013,769|-|[2019](https://skylion007.github.io/OpenWebTextCorpus/)|English|<a href="https://huggingface.co/nlp/viewer/?dataset=openwebtext" title="Open in Huggingface" target="_blank">ð¤</a>|
|[Ten Thousand German News Articles Dataset (10kGNAD)](https://github.com/tblock/10kGNAD "Dataset consists of 10273 german language news articles from an austrian online newspaper categorized into nine topics.")|10,273|CSV|[2019](https://tblock.github.io/10kGNAD/)|German||
|[Aesthetics Text Corpus](https://github.com/gayatrivenugopal/Hindi-Aesthetics-Corpus "Dataset consists of novels and short stories written in Hindi language. Novels and stories were scraped from http://hindisamay.com, http://premchand.co.in, a website dedicated to the popular novelist Premchandâs stories, and Bhandarkar Oriental Research Instituteâs Digital Library (http://borilib.com). As a preprocessing step, the text was split into sentences and special characters, English tokens and Latin numbers were deleted.")|978|Text|[2019](https://thesai.org/Downloads/Volume11No1/Paper_30-Novel_Language_Resources_for_Hindi.pdf)|Hindi||
|[Kensho Derived Wikimedia Dataset (KDWD)](https://www.kaggle.com/kenshoresearch/kensho-derived-wikimedia-data "Dataset containsÂ two main components - a link annotated corpus of English Wikipedia pages and a compact sample of the Wikidata knowledge base.")|-|CSV, JSON|[2020]()|English||
|[Hong Kong Stock Exchange, the Securities and Futures Commission of Hong Kong](https://www.translatefx.com/resources/corpora "Dataset contains aligned sentence pairs from bilingual texts, covering the financial and legal domains in Hong Kong. The sources include government legislations and regulations, stock exchange announcements, financial offering documents, regulatory filings, regulatory guidelines, corporate constitutional documents and others.")|350,000+|TSV|[2020]()|Chinese, English||
|[All the News 2.0](https://components.one/datasets/all-the-news-2-news-articles-dataset/ "Dataset contains 2.7 million articles from 26 different publications from January 2016 to April 1, 2020.")|2.7M|CSV|[2020]()|English||
|[COVID-19 Open Research Dataset (CORD-19)](https://pages.semanticscholar.org/coronavirus-research "Dataset contains 44,000 scholarly articles, including over 29,000 with full text, about COVID-19 and the coronavirus family of viruses for use by the global research community.")|44k|JSON|[2020]()|English||
|[Curation Corpus](https://github.com/CurationCorp/curation-corpus "Dataset is a collection of 40,000 professionally-written summaries of news articles, with links to the articles themselves.")|40k|CSV|[2020]()|English||
|[Hippocorpus](https://msropendata.com/datasets/0a83fb6f-a759-4a17-aaa2-fbac84577318 "Dataset of 6,854 English diary-like short stories about recalled and imagined events.")|6,854|CSV|[2020](http://erichorvitz.com/cognitive_studies_narrative.pdf)|English||
|[The Semantic Scholar Open Research Corpus (S2ORC)](https://github.com/allenai/s2orc/ "Dataset contains 136M+ paper nodes with 12.7M+ full text papers and connected by 467M+ citation edges.")|467M edges, 136M nodes|JSON|[2020](https://arxiv.org/abs/1911.02782)|English|<a target="_blank" href="https://paperswithcode.com/paper/gorc-a-large-contextual-citation-graph-of" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[PoKi](https://github.com/whipson/PoKi-Poems-by-Kids "Dataset is a corpus of 61,330 poems written by children from grades 1 to 12.")|61,330|CSV|[2020](https://arxiv.org/abs/2004.06188)|English|<a target="_blank" href="https://paperswithcode.com/paper/poki-a-large-dataset-of-poems-by-children" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[HJDataset](https://dell-research-harvard.github.io/HJDataset/ "Dataset contains over 250,000 layout element annotations of seven types in Japanese documents.")|250,000+|JSON|[2020](https://arxiv.org/abs/2004.08686)|Japanese|<a target="_blank" href="https://paperswithcode.com/paper/a-large-dataset-of-historical-japanese" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[ArxivPapers](https://colab.research.google.com/github/paperswithcode/axcell/blob/master/notebooks/datasets.ipynb?authuser=1#scrollTo=Qf9sdQWqwQFf "Dataset is a corpus of over 100,000 scientific papers related to machine learning.")|104,723|CSV|[2020](https://arxiv.org/abs/2004.14356)|English|<a target="_blank" href="https://paperswithcode.com/paper/axcell-automatic-extraction-of-results-from" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Statutory Reasoning Assessment (SARA)](https://nlp.jhu.edu/law/ "Dataset contains a set of rules extracted from the statutes of the US Internal Revenue Code (IRC), together with a set of natural language questions which may only be answered correctly by referring to the rules.")|100|Text|[2020](https://arxiv.org/abs/2005.05257)|English|<a target="_blank" href="https://paperswithcode.com/paper/a-dataset-for-statutory-reasoning-in-tax-law" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[COVID-19 Twitter Chatter Dataset](https://zenodo.org/record/3902855#.XvOWFmhKiUk "Dataset contains over 152 million tweets, growing daily, related to COVID-19 chatter generated from January 1st, 2020 to present.")|152M+|TSV|[2020](https://arxiv.org/ftp/arxiv/papers/2004/2004.03688.pdf)|Multi-Lingual||
|[BuGL](https://github.com/muvvasandeep/BuGL "Dataset consists of 54 GitHub projects of four different programming languages namely C, C++, Java and Python with around 10,187 issues.")|10,187|JSON, Xlsx|[2020](https://github.com/muvvasandeep/BuGL/blob/master/Documentation%20of%20BuGL.pdf)|English||
|[Harvard Library](https://wiki.harvard.edu/confluence/display/LibraryStaffDoc/LibraryCloud "Dataset contains books, journals, electronic resources, manuscripts, archival materials, scores, audio, video and other materials.")|12.7M|MODS, Dublin Core|[n/a]()|English||

## Text Generation

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[WikiBio](https://github.com/DavidGrangier/wikipedia-biography-dataset "Dataset contains 728,321 biographies from wikipedia. For each article, it provides the first paragraph and the infobox (both tokenized).")|728,321|-|[2016](https://arxiv.org/abs/1603.07771)|English|<a target="_blank" href="https://paperswithcode.com/paper/neural-text-generation-from-structured-data" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Dataset for Fill-in-the-Blank Humor](https://www.microsoft.com/en-us/download/details.aspx?id=55593 "Dataset contains 50 fill-in-the-blank stories similar in style to Mad Libs. The blanks in these stories include the original word and the hint type (e.g. animal, food, noun, adverb).")|50|JSON|[2017](https://www.aclweb.org/anthology/D17-1067.pdf)|English||
|[WebNLG (Enriched)](https://github.com/ThiagoCF05/webnlg "Dataset consists of 25,298 (data,text) pairs and 9,674 distinct data units. The data units are sets of RDF triples extracted from DBPedia and the texts are sequences of one or more sentences verbalising these data units.")|25,298|XML|[2017](https://www.aclweb.org/anthology/W17-3518.pdf)|German, English||
|[CommonGen](http://inklab.usc.edu/CommonGen/ "Dataset consists of 30k concept-sets with humanwritten sentences as references.")|30k|JSON|[2019](http://inklab.usc.edu/CommonGen/commongen_acl20.pdf)|English||
|[E2E](http://www.macs.hw.ac.uk/InteractionLab/E2E/ "Dataset contains 50k combinations of a dialogue-act-based meaning representation and 8.1 references on average in the restaurant domain.")|50k|xlsx|[2019](https://arxiv.org/abs/1706.09254)|English|<a target="_blank" href="https://paperswithcode.com/paper/the-e2e-dataset-new-challenges-for-end-to-end" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Text-to-Code Generation

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[CodeXGLUE: CONCODE](https://github.com/microsoft/CodeXGLUE/tree/main/Text-Code/text-to-code "Dataset is used for when a model is given the task to generate a code given natural language description.")|104k|JSON|[2018](https://www.aclweb.org/anthology/D18-1192.pdf)|Coding Lang: Java||

## Text-to-Image

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[GeNeVA](https://github.com/Maluuba/GeNeVA_datasets "Data contains the CoDraw and i-CLEVR datasets used for the Generative Neural Visual Artist (GeNeVA) task.")|-|RaR|[2018](https://arxiv.org/abs/1811.09845)|English|<a target="_blank" href="https://paperswithcode.com/paper/keep-drawing-it-iterative-language-based" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Text-to-SQL

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Restaurants](https://github.com/jkkummerfeld/text2sql-data "Dataset contains user questions about restaurants, their food types, and locations.")|378|JSON|[2012](https://www.researchgate.net/publication/270878355_Translating_Questions_to_SQL_Queries_with_Generative_Parsers_Discriminatively_Reranked)|English||
|[Academic](https://github.com/jkkummerfeld/text2sql-data "Questions about the Microsoft Academic Search (MAS) database, derived by enumerating every logical query that could be expressed using the search page of the MAS website and writing sentences to match them.")|196|JSON|[2014](http://www.vldb.org/pvldb/vol8/p73-li.pdf)|English||
|[WikiSQL](https://github.com/jkkummerfeld/text2sql-data "A large collection of automatically generated questions about individual tables from Wikipedia.")|80,654|JSON|[2017](https://arxiv.org/abs/1709.00103)|English|<a target="_blank" href="https://paperswithcode.com/paper/seq2sql-generating-structured-queries-from" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=wikisql" title="Open in Huggingface" target="_blank">ð¤</a>|
|[GeoQuery](https://github.com/jkkummerfeld/text2sql-data "Dataset contains utterances issued to a database of US geographical facts.")|877|JSON|[2017](https://pdfs.semanticscholar.org/1c9d/f99cce1903d34c53025e86e72331bbfbe08f.pdf?_ga=2.119839695.69779999.1583855679-45550878.1577737485)|English||
|[Scholar](https://github.com/jkkummerfeld/text2sql-data "User questions about academic publications, with automatically generated SQL that was checked by asking the user if the output was correct.")|817|JSON|[2017](https://www.aclweb.org/anthology/P17-1089.pdf)|English||
|[ATIS](https://github.com/jkkummerfeld/text2sql-data "Dataset is a collection of utterances to a flight booking system, accompanied by a relational database and SQL queries to answer the questions.")|877|JSON|[2017](https://www.aclweb.org/anthology/P18-1033.pdf)|English||
|[Advising](https://github.com/jkkummerfeld/text2sql-data "Dataset contains questions regarding course information at the University of Michigan, but with fictional student records.")|4,570|JSON|[2018](https://arxiv.org/abs/1806.09029)|English|<a target="_blank" href="https://paperswithcode.com/paper/improving-text-to-sql-evaluation-methodology" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Text-to-Speech

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[CSTR VCTK Corpus](https://datashare.is.ed.ac.uk/handle/10283/2651 "Dataset contains speech data uttered by 109 native speakers of English with various accents. Each speaker reads out about 400 sentences, most of which were selected from a newspaper plus the Rainbow Passage and an elicitation paragraph intended to identify the speaker's accent.")|-|-|[2017]()|English||
|[Korean Single Speaker Dataset (KSS)](https://www.kaggle.com/bryanpark/korean-single-speaker-speech-dataset "Dataset consists of audio files recorded by a professional female voice actress and their aligned text extracted from books.")|12,853|WAV|[2019]()|Korean||
|[LibriTTS](http://www.openslr.org/60 "Dataset is a multi-speaker English corpus of approximately 585 hours of read English speech at 24kHz sampling rate.")|585 Hours|MP3|[2019](https://arxiv.org/abs/1904.02882)|English|<a target="_blank" href="https://paperswithcode.com/paper/libritts-a-corpus-derived-from-librispeech" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Topic Extraction

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[NYSK Dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/00260/ "English news articles about the case relating to allegations of sexual assault against the formerÂ IMFÂ directorÂ Dominique Strauss-Kahn.")|10,421|XML|[2013]()|English||

## Translation

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[How2](https://github.com/srvk/how2-dataset "Dataset of instructional videos covering a wide variety of topics across video clips (about 2,000 hours), with word-level time alignments to the ground-truth English subtitles. And 300 hours was translated into Portuguese subtitles.")|~2,000 Hours|-|[2018](https://arxiv.org/abs/1811.00347)|Portuguese, English|<a target="_blank" href="https://paperswithcode.com/paper/how2-a-large-scale-dataset-for-multimodal" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Triple Classification

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[CoDExÂ ](https://github.com/tsafavi/codex "Three graph datasets containing positive and hard negative triples, entity types, entity and relation descriptions, and Wikipedia page extracts for entities.")|1,156,222|JSON|[2020](https://arxiv.org/abs/2009.07810)|English|<a target="_blank" href="https://paperswithcode.com/paper/codex-a-comprehensive-knowledge-graph" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Video Question Answering

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[MovieQA](https://github.com/makarandtapaswi/MovieQA_benchmark "Dataset used to evaluate automatic story comprehension from both video and text. The data set consists of almost 15,000 multiple choice question answers obtained from over 400 movies.")|14,944|JSON|[2016](https://arxiv.org/abs/1512.02902)|English|<a target="_blank" href="https://paperswithcode.com/paper/movieqa-understanding-stories-in-movies" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[TGIF-QA](https://github.com/YunseokJANG/tgif-qa "Dataset consists of 165K QA pairs from 72K animated GIFs. Used for video question answering.")|165k|CSV|[2017](https://arxiv.org/abs/1704.04497)|English|<a target="_blank" href="https://paperswithcode.com/paper/tgif-qa-toward-spatio-temporal-reasoning-in" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[TVQA](http://tvqa.cs.unc.edu/download_tvqa.html "Dataset is used for video question answering and consists of 152,545 QA pairs from 21,793 clips, spanning over 460 hours of video. ")|460+ Hours|HDF5, JSON|[2018](https://arxiv.org/abs/1809.01696)|English|<a target="_blank" href="https://paperswithcode.com/paper/tvqa-localized-compositional-video-question" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Audio Visual Scene-Aware Dialog (AVSD)](https://video-dialog.com/ "Dataset consists of text-based human conversations about short videos from the Charades dataset.")|11,816|JSON|[2019](https://arxiv.org/abs/1901.09107)|English|<a target="_blank" href="https://paperswithcode.com/paper/audio-visual-scene-aware-dialog" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Visual

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning (CLEVR & CoGenT)](https://cs.stanford.edu/people/jcjohns/clevr/ "Visual question answering dataset contains 100,000 images and 999,968 questions.")|999,968 questions; 100,000 images|JSON|[2016](http://vision.stanford.edu/pdf/johnson2017cvpr.pdf)|English||
|[Textbook Question Answering](http://data.allenai.org/tqa/ "The M3C task builds on the popular Visual Question Answering (VQA) and Machine Comprehension (MC) paradigms by framing question answering as a machine comprehension task, where the context needed to answer questions is provided and composed of both text and images.")|26,620|JSON, PNG|[2017](http://ai2-website.s3.amazonaws.com/publications/CVPR17_TQA.pdf)|English||
|[Fact-based Visual Question Answering (FVQA)](https://www.dropbox.com/s/iyz6l7jhbt6jb7q/new_dataset_release.zip?dl=0 "Dataset contains image question anwering triples")|5,826 questions; 2,190 images|JSON|[2017](https://arxiv.org/abs/1606.05433)|English|<a target="_blank" href="https://paperswithcode.com/paper/fvqa-fact-based-visual-question-answering" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[VisDial](https://visualdialog.org/data "Dataset contains images from COCO training set, and dialogues. Meant to be used for model to be trained in answering questions about images during conversation. Contains 1.2M dialog question-answers.")|1.2M|JSON|[2017](https://arxiv.org/abs/1703.06585)|English|<a target="_blank" href="https://paperswithcode.com/paper/learning-cooperative-visual-dialog-agents" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[VoxCeleb](http://www.robots.ox.ac.uk/~vgg/data/voxceleb/ "An audio-visual dataset consisting of short clips of human speech, extracted from interview videos uploaded to YouTube.")|-|MD5, URL|[2017](https://arxiv.org/abs/1706.08612)|Multi-Lingual|<a target="_blank" href="https://paperswithcode.com/paper/voxceleb-a-large-scale-speaker-identification" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[AudioSet](https://research.google.com/audioset/download.html "Dataset consists of an expanding ontology of 632 audio event classes and a collection of 2,084,320 human-labeled 10-second sound clips drawn from YouTube videos.")|-|CSV, TFR|[2017](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/45857.pdf)|Multi-Lingual||
|[DVQA](https://github.com/kushalkafle/DVQA_dataset "Dataset containing data visualizations and natural language questions.")|3,487,194|JSON, PNG|[2018](https://arxiv.org/abs/1801.08163)|English|<a target="_blank" href="https://paperswithcode.com/paper/dvqa-understanding-data-visualizations-via" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Microsoft Information-Seeking Conversation (MISC) dataset](https://www.microsoft.com/en-us/download/details.aspx?id=55594 "Dataset contains recordings of information-seeking conversations between human âseekersâ and âintermediariesâ. It includes audio and video signals; transcripts of conversation; affectual and physiological signals; recordings of search and other computer use; and post-task surveys on emotion, success, and effort.")|-|various|[2018](https://arxiv.org/abs/1804.08759)|English|<a target="_blank" href="https://paperswithcode.com/paper/analyzing-and-characterizing-user-intent-in" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[How2](https://github.com/srvk/how2-dataset "Dataset of instructional videos covering a wide variety of topics across video clips (about 2,000 hours), with word-level time alignments to the ground-truth English subtitles. And 300 hours was translated into Portuguese subtitles.")|~2,000 Hours|-|[2018](https://arxiv.org/abs/1811.00347)|Portuguese, English|<a target="_blank" href="https://paperswithcode.com/paper/how2-a-large-scale-dataset-for-multimodal" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Video Commonsense Reasoning (VCR)](https://visualcommonsense.com/download/ "Dataset contains 290K multiple-choice questions on 110K images.")|290k|JSON, JPG|[2018](https://arxiv.org/abs/1811.10830)|English|<a target="_blank" href="https://paperswithcode.com/paper/from-recognition-to-cognition-visual" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[CMU Multimodal Opinion Sentiment and Emotion Intensity (CMU-MOSEI)](https://github.com/A2Zadeh/CMU-MultimodalSDK "Dataset contains more than 23,500 sentence utterance videos from more than 1000 online YouTube speakers. The dataset is gender balanced. All the sentences utterance are randomly chosen from various topics and monologue videos.")|23,500|-|[2018](https://www.aclweb.org/anthology/P18-1208.pdf)|English||
|[Social-IQ Dataset](https://github.com/A2Zadeh/Social-IQ "Dataset containing videos and natural language questions for visual reasoning.")|7,500|-|[2019](http://openaccess.thecvf.com/content_CVPR_2019/papers/Zadeh_Social-IQ_A_Question_Answering_Benchmark_for_Artificial_Social_Intelligence_CVPR_2019_paper.pdf)|English||
|[Cornell Natural Language for Visual Reasoning (NLVR and NLVR2)](http://lil.nlp.cornell.edu/nlvr/ "Dataset contains two language grounding datasets containing natural language sentences grounded in images. The task is to determine whether a sentence is true about a visual input.")|NLVR2 107,292; NLVR 92,244|JSON|[2019](https://arxiv.org/abs/1811.00491)|English|<a target="_blank" href="https://paperswithcode.com/paper/a-corpus-for-reasoning-about-natural-language" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[GQA](https://cs.stanford.edu/people/dorarad/gqa/download.html "Question answering on imageÂ scene graphs.")|22M|JSON, H5|[2019](https://arxiv.org/abs/1902.09506)|English|<a target="_blank" href="https://paperswithcode.com/paper/gqa-a-new-dataset-for-compositional-question" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[TextVQA](https://textvqa.org/dataset "TextVQA requires models to read and reason about text in images to answer questions about them. Specifically, models need to incorporate a new modality of text present in the images and reason over it to answer TextVQA questions.")|36,602|JSON, PNG|[2019](https://arxiv.org/abs/1904.08920)|English|<a target="_blank" href="https://paperswithcode.com/paper/towards-vqa-models-that-can-read" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Activitynet-QA](https://github.com/MILVLG/activitynet-qa "Dataset contains 58,000 human-annotated QA pairs on 5,800 videos derived from the popular ActivityNet dataset. The dataset provides a benckmark for testing the performance of VideoQA models on long-term spatio-temporal.")|58k|JSON|[2019](https://arxiv.org/abs/1906.02467)|English|<a target="_blank" href="https://paperswithcode.com/paper/activitynet-qa-a-dataset-for-understanding" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[DramaQA](https://dramaqa.snu.ac.kr/Dataset "Dataset contains 16,191 question answer pairs from 23,928 various length video clips, with each question answer pair belonging to one of four difficulty levels.")|23,928|JSON|[2020](https://arxiv.org/abs/2005.03356)|English|<a target="_blank" href="https://paperswithcode.com/paper/dramaqa-character-centered-video-story" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[CompGuessWhat?!](https://compguesswhat.github.io/download/ "Dataset contains 65,700 dialogues based on GuessWhat?! dataset dialogues and enhanced by including object attributes coming from resources such as VISA attributes, VisualGenome and ImSitu.")|65,700|JSON|[2020](https://arxiv.org/abs/2006.02174)|English|<a target="_blank" href="https://paperswithcode.com/paper/compguesswhat-a-multi-task-evaluation" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a><a href="https://huggingface.co/nlp/viewer/?dataset=compguesswhat" title="Open in Huggingface" target="_blank">ð¤</a>|
|[VQA-Introspect](https://www.microsoft.com/en-us/research/project/vqa-introspect/ "Dataset consists of 238K new perception questions from the VQA dataset which serve as sub questions corresponding to the set of perceptual tasks needed to answer complex reasoning questions.")|238k|JSON|[2020](https://www.microsoft.com/en-us/research/uploads/prod/2020/06/SQuINT_CVPR.pdf)|English||

## Visual Question Answering

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Visual QA (VQA)](https://visualqa.org/download.html "Dataset containing open-ended questions about images. These questions require an understanding of vision, language and commonsense to answer.")|265,016 images|JSON|[2015](https://arxiv.org/abs/1505.00468)|English|<a target="_blank" href="https://paperswithcode.com/paper/vqa-visual-question-answering" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Visual Genome](https://visualgenome.org/api/v0/api_home.html "Dataset contains over 100K images where each image has an average of 21 objects, 18 attributes, and 18 pairwise relationships between objects.")|100,000+|JSON|[2016](https://visualgenome.org/static/paper/Visual_Genome.pdf)|English||
|[FigureQA](https://msropendata.com/datasets/85596452-0fe3-4335-bc00-ae83ee8ffcfd "Dataset is a visual reasoning corpus of over one million question answer pairs grounded in over 100,000 images. The images are synthetic, scientific-style figures from five classes: line plots, dot-line plots, vertical and horizontal bar graphs, and pie charts.")|~1.3M|Tar|[2018](https://arxiv.org/abs/1710.07300)|English|<a target="_blank" href="https://paperswithcode.com/paper/figureqa-an-annotated-figure-dataset-for" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
|[Visual Commonsense Graphs](https://visualcomet.xyz/dataset "Dataset consists of over 1.4 million textual descriptions of visual commonsense inferences carefully annotated over a diverse set of 59,000 images, each paired with short video summaries of before and after.")|59k|JSON, JPG|[2020](https://arxiv.org/abs/2004.10796)|English|<a target="_blank" href="https://paperswithcode.com/paper/visual-commonsense-graphs-reasoning-about-the" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Visualization

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[Quda](https://freenli.github.io/quda/ "Dataset contains 14,035 diverse user queries annotated with 10 low-level analytic tasks that assist in the deployment of state-of-the-art machine/deep learning techniques for parsing complex human language.")|14,035|Text|[2020](https://arxiv.org/abs/2005.03257)|English|<a target="_blank" href="https://paperswithcode.com/paper/quda-natural-language-queries-for-visual-data" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|

## Word Sense Disambiguation

|Dataset|Size|Format|Year|Language|External|
|---|---|---|---|---|---|
|[WSD English All-Words Fine-GrainedÂ Datasets](http://lcl.uniroma1.it/wsdeval/data/WSD_Evaluation_Framework.zip "Unified five standard all-words Word Sense Disambiguation datasets.")|7,000+|XML|[2017]()|English||
|[Train-O-Matic Small](http://trainomatic.org/data/train-o-matic-data.tar.gz "Automatically-generated corpora in multiple languages with sense annotations for nouns using WordNet for English and BabelNet for all other languages as inventories of senses.")|1M+|XML|[2017](https://www.aclweb.org/anthology/D17-1008.pdf)|Multi-Lingual||
|[Train-O-Matic Large](http://trainomatic.org/data/train-o-matic_lrec2018.tar.gz "Automatically-generated corpora in multiple languages with sense annotations for nouns using WordNet for English and BabelNet for all other languages as inventories of senses.")|10M+|XML|[2018](https://www.aclweb.org/anthology/D17-1008.pdf)|Multi-Lingual||
|[OneSeC Small](http://trainomatic.org/data/onesec.tar.gz "Automatically-generated corpora in multiple languages with sense annotations for nouns using WordNet for English and BabelNet for all other languages as inventories of senses.")|1M+|XML|[2019](http://www.trainomatic.org/data/ACL_2019_Scarlinietal.pdf)|Multi-Lingual||
|[Words in Context](https://pilehvar.github.io/wic/ "Dataset for evaluating contextualized word representations.")|2,400|Text|[2019](https://arxiv.org/abs/1808.09121)|English|<a target="_blank" href="https://paperswithcode.com/paper/wic-10000-example-pairs-for-evaluating" title="Open in Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon pwc-icon-primary" viewBox="0 0 512 512"><path stroke="#21cbce" fill="#21cbce" d="M88 128h48v256H88zM232 128h48v256h-48zM160 144h48v224h-48zM304 144h48v224h-48zM376 128h48v256h-48z"></path><path stroke="#21cbce" fill="#21cbce" d="M104 104V56H16v400h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"></path></svg></a>|
